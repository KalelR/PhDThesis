@article{halekotte2020minimal, 
year = {2020}, 
title = {{Minimal fatal shocks in multistable complex networks}}, 
author = {Halekotte, Lukas and Feudel, Ulrike}, 
journal = {Scientific Reports}, 
doi = {10.1038/s41598-020-68805-6}, 
pmid = {32678252}, 
abstract = {{Multistability is a common phenomenon which naturally occurs in complex networks. Often one of the coexisting stable states can be identified as being the desired one for a particular application. We present here a global approach to identify the minimal perturbation which will instantaneously kick the system out of the basin of attraction of its desired state and hence induce a critical or fatal transition we call shock-tipping. The corresponding Minimal Fatal Shock is a vector whose length can be used as a global stability measure and whose direction in state space allows us to draw conclusions on weaknesses of the network corresponding to critical network motifs. We demonstrate this approach in plant–pollinator networks and the power grid of Great Britain. In both system classes, tree-like substructures appear to be the most vulnerable with respect to the minimal shock perturbation.}}, 
pages = {11783}, 
number = {1}, 
volume = {10}, 
keywords = {}
}
@article{peter2018transition, 
year = {2018}, 
title = {{Transition to collective oscillations in finite Kuramoto ensembles}}, 
author = {Peter, Franziska and Pikovsky, Arkady}, 
journal = {Physical Review E}, 
issn = {2470-0045}, 
doi = {10.1103/physreve.97.032310}, 
pmid = {29776135}, 
abstract = {{We present an alternative approach to finite-size effects around the synchronization transition in the standard Kuramoto model. Our main focus lies on the conditions under which a collective oscillatory mode is well defined. For this purpose, the minimal value of the amplitude of the complex Kuramoto order parameter appears as a proper indicator. The dependence of this minimum on coupling strength varies due to sampling variations and correlates with the sample kurtosis of the natural frequency distribution. The skewness of the frequency sample determines the frequency of the resulting collective mode. The effects of kurtosis and skewness hold in the thermodynamic limit of infinite ensembles. We prove this by integrating a self-consistency equation for the complex Kuramoto order parameter for two families of distributions with controlled kurtosis and skewness, respectively.}}, 
pages = {032310}, 
number = {3}, 
volume = {97}, 
keywords = {}
}
@article{stender2021bstab, 
year = {2021}, 
title = {{bSTAB: an open-source software for computing the basin stability of multi-stable dynamical systems}}, 
author = {Stender, Merten and Hoffmann, Norbert}, 
journal = {Nonlinear Dynamics}, 
issn = {0924-090X}, 
doi = {10.1007/s11071-021-06786-5}, 
abstract = {{The pervasiveness of multi-stability in nonlinear dynamical systems calls for novel concepts of stability and a consistent quantification of long-term behavior. The basin stability is a global stability metric that builds on estimating the basin of attraction volumes by Monte Carlo sampling. The computation involves extensive numerical time integrations, attractor characterization, and clustering of trajectories. We introduce bSTAB, an open-source software project that aims at enabling researchers to efficiently compute the basin stability of their dynamical systems with minimal efforts and in a highly automated manner. The source code, available at https://github.com/TUHH-DYN/bSTAB/, is available for the programming language Matlab featuring parallelization for distributed computing, automated sensitivity and bifurcation analysis as well as plotting functionalities. We illustrate the versatility and robustness of bSTAB for four canonical dynamical systems from several fields of nonlinear dynamics featuring periodic and chaotic dynamics, complicated multi-stability, non-smooth dynamics, and fractal basins of attraction. The bSTAB projects aims at fostering interdisciplinary scientific collaborations in the field of nonlinear dynamics and is driven by the interaction and contribution of the community to the software package.}}, 
pages = {1--18}, 
keywords = {}
}
@article{rodrigues2016the, 
year = {2016}, 
title = {{The Kuramoto model in complex networks}}, 
author = {Rodrigues, Francisco A. and Peron, Thomas K.D.M. and Ji, Peng and Kurths, Jürgen}, 
journal = {Physics Reports}, 
issn = {0370-1573}, 
doi = {10.1016/j.physrep.2015.10.008}, 
url = {https://abdn.pure.elsevier.com/en/publications/the-kuramoto-model-in-complex-networks}, 
abstract = {{Synchronization of an ensemble of oscillators is an emergent phenomenon present in several complex systems, ranging from social and physical to biological and technological systems. The most successful approach to describe how coherent behavior emerges in these complex systems is given by the paradigmatic Kuramoto model. This model has been traditionally studied in complete graphs. However, besides being intrinsically dynamical, complex systems present very heterogeneous structure, which can be represented as complex networks. This report is dedicated to review main contributions in the field of synchronization in networks of Kuramoto oscillators. In particular, we provide an overview of the impact of network patterns on the local and global dynamics of coupled phase oscillators. We cover many relevant topics, which encompass a description of the most used analytical approaches and the analysis of several numerical results. Furthermore, we discuss recent developments on variations of the Kuramoto model in networks, including the presence of noise and inertia. The rich potential for applications is discussed for special fields in engineering, neuroscience, physics and Earth science. Finally, we conclude by discussing problems that remain open after the last decade of intensive research on the Kuramoto model and point out some promising directions for future research.}}, 
pages = {1--98}, 
volume = {610}, 
keywords = {}
}
@article{recanatesi2021metastable, 
year = {2021}, 
title = {{Metastable attractors explain the variable timing of stable behavioral action sequences}}, 
author = {Recanatesi, Stefano and Pereira-Obilinovic, Ulises and Murakami, Masayoshi and Mainen, Zachary and Mazzucato, Luca}, 
journal = {Neuron}, 
issn = {0896-6273}, 
abstract = {{The timing of self-initiated actions shows large variability even when they are executed in stable, well-learned sequences. Could this mix of reliability and stochasticity arise within the same neural circuit? We trained rats to perform a stereotyped sequence of self-initiated actions and recorded neural ensemble activity in secondary motor cortex (M2), which is known to reflect trial-by-trial action-timing fluctuations. Using hidden Markov models, we established a dictionary between activity patterns and actions. We then showed that metastable attractors, representing activity patterns with a reliable sequential structure and large transition timing variability, could be produced by reciprocally coupling a high-dimensional recurrent network and a low-dimensional feedforward one. Transitions between attractors relied on correlated variability in this mesoscale feedback loop, predicting a specific structure of low-dimensional correlations that were empirically verified in M2 recordings. Our results suggest a novel mesoscale network motif based on correlated variability supporting naturalistic animal behavior.}}, 
keywords = {}
}
@book{lai2009transient, 
year = {2009}, 
title = {{Transient Chaos: Complex Dynamics on Finite-TIme Scales}}, 
author = {Lai, Ying-Cheng and Tél, Tamás}, 
isbn = {978-1-4614-2816-9}, 
series = {Applied Mathematical Sciences}, 
publisher = {Springer New York, NY}, 
keywords = {}, 
doi = {10.1007/978-1-4419-6987-3}
}
@article{halekotte2021transient, 
year = {2021}, 
title = {{Transient chaos enforces uncertainty in the British power grid}}, 
author = {Halekotte, Lukas and Vanselow, Anna and Feudel, Ulrike}, 
journal = {Journal of Physics: Complexity}, 
doi = {10.1088/2632-072x/ac080f}, 
pages = {035015}, 
number = {3}, 
volume = {2}, 
keywords = {}
}
@article{milnor1985on, 
year = {1985}, 
title = {{On the concept of attractor}}, 
author = {Milnor, John}, 
journal = {Communications in Mathematical Physics}, 
issn = {0010-3616}, 
doi = {10.1007/bf01212280}, 
abstract = {{This note proposes a definition for the concept of “attractor,” based on the probable asymptotic behavior of orbits. The definition is sufficiently broad so that every smooth compact dynamical system has at least one attractor.}}, 
pages = {177--195}, 
number = {2}, 
volume = {99}, 
keywords = {}
}
@article{brunton2016discovering, 
year = {2016}, 
title = {{Discovering governing equations from data by sparse identification of nonlinear dynamical systems}}, 
author = {Brunton, Steven L. and Proctor, Joshua L. and Kutz, J. Nathan}, 
journal = {Proceedings of the National Academy of Sciences}, 
issn = {0027-8424}, 
doi = {10.1073/pnas.1517384113}, 
pmid = {27035946}, 
pmcid = {PMC4839439}, 
eprint = {1509.03580}, 
abstract = {{Extracting governing equations from data is a central challenge in many diverse areas of science and engineering. Data are abundant whereas models often remain elusive, as in climate science, neuroscience, ecology, finance, and epidemiology, to name only a few examples. In this work, we combine sparsity-promoting techniques and machine learning with nonlinear dynamical systems to discover governing equations from noisy measurement data. The only assumption about the structure of the model is that there are only a few important terms that govern the dynamics, so that the equations are sparse in the space of possible functions; this assumption holds for many physical systems in an appropriate basis. In particular, we use sparse regression to determine the fewest terms in the dynamic governing equations required to accurately represent the data. This results in parsimonious models that balance accuracy with model complexity to avoid overfitting. We demonstrate the algorithm on a wide range of problems, from simple canonical systems, including linear and nonlinear oscillators and the chaotic Lorenz system, to the fluid vortex shedding behind an obstacle. The fluid example illustrates the ability of this method to discover the underlying dynamics of a system that took experts in the community nearly 30 years to resolve. We also show that this method generalizes to parameterized systems and systems that are time-varying or have external forcing.}}, 
pages = {3932--3937}, 
number = {15}, 
volume = {113}, 
keywords = {}
}
@article{ansmann2016selfinduced, 
year = {2016}, 
title = {{Self-induced switchings between multiple space-time patterns on complex networks of excitable units}}, 
author = {Ansmann, Gerrit and Lehnertz, Klaus and Feudel, Ulrike}, 
journal = {Physical Review X}, 
doi = {10.1103/physrevx.6.011030}, 
url = {https://journals.aps.org/prx/abstract/10.1103/PhysRevX.6.011030}, 
abstract = {{We report on self-induced switchings between multiple distinct space-time patterns in the dynamics of a spatially extended excitable system. These switchings between low-amplitude oscillations, nonlinear waves, and extreme events strongly resemble a random process, although the system is deterministic. We show that a chaotic saddle-which contains all the patterns as well as channel-like structures that mediate the transitions between them-is the backbone of such a pattern-switching dynamics. Our analyses indicate that essential ingredients for the observed phenomena are that the system behaves like an inhomogeneous oscillatory medium that is capable of self-generating spatially localized excitations and that is dominated by short-range connections but also features long-range connections. With our findings, we present an alternative to the well-known ways to obtain self-induced pattern switching, namely, noise-induced attractor hopping, heteroclinic orbits, and adaptation to an external signal. This alternative way can be expected to improve our understanding of pattern switchings in spatially extended natural dynamical systems like the brain and the heart.}}, 
pages = {011030}, 
number = {1}, 
volume = {6}, 
keywords = {}
}
@article{Tomasz.1999, 
year = {1999}, 
title = {{Blowout bifurcation of chaotic saddles}}, 
author = {Tomasz, Kapitaniak and Ying-Cheng, Lai and Celso, Grebogi}, 
journal = {Discrete Dynamics in Nature and Society}, 
issn = {1026-0226}, 
doi = {10.1155/s1026022699000023}, 
abstract = {{Chaotic saddles are nonattracting dynamical invariant sets that can lead to a variety of physical phenomena. We describe the blowout bifurcation of chaotic saddles located in the symmetric invariant manifold of coupled systems and discuss dynamical phenomena associated with this bifurcation.}}, 
pages = {9--13}, 
number = {1}, 
volume = {3}, 
keywords = {}
}
@article{hellmann2020network, 
year = {2020}, 
title = {{Network-induced multistability through lossy coupling and exotic solitary states}}, 
author = {Hellmann, Frank and Schultz, Paul and Jaros, Patrycja and Levchenko, Roman and Kapitaniak, Tomasz and Kurths, Jürgen and Maistrenko, Yuri}, 
journal = {Nature Communications}, 
doi = {10.1038/s41467-020-14417-7}, 
pmid = {32001705}, 
pmcid = {PMC6992754}, 
abstract = {{The stability of synchronised networked systems is a multi-faceted challenge for many natural and technological fields, from cardiac and neuronal tissue pacemakers to power grids. For these, the ongoing transition to distributed renewable energy sources leads to a proliferation of dynamical actors. The desynchronisation of a few or even one of those would likely result in a substantial blackout. Thus the dynamical stability of the synchronous state has become a leading topic in power grid research. Here we uncover that, when taking into account physical losses in the network, the back-reaction of the network induces new exotic solitary states in the individual actors and the stability characteristics of the synchronous state are dramatically altered. These effects will have to be explicitly taken into account in the design of future power grids. We expect the results presented here to transfer to other systems of coupled heterogeneous Newtonian oscillators. The design of future power grids with decentral control calls for a better understanding of the stability of synchronized networked systems. Here, Hellmann et al. show that the energy losses in coupled oscillators can significantly alter power grid dynamics by introducing solitary states in the network.}}, 
pages = {592}, 
number = {1}, 
volume = {11}, 
keywords = {}
}
@article{gross2021not, 
year = {2021}, 
title = {{Not One, but Many Critical States: A Dynamical Systems Perspective}}, 
author = {Gross, Thilo}, 
journal = {Frontiers in Neural Circuits}, 
doi = {10.3389/fncir.2021.614268}, 
pmid = {33737868}, 
abstract = {{The past decade has seen growing support for the critical brain hypothesis, i.e., the possibility that the brain could operate at or very near a critical state between two different dynamical regimes. Such critical states are well-studied in different disciplines, therefore there is potential for a continued transfer of knowledge. Here, I revisit foundations of bifurcation theory, the mathematical theory of transitions. While the mathematics is well-known it's transfer to neural dynamics leads to new insights and hypothesis.}}, 
pages = {614268}, 
volume = {15}, 
keywords = {}
}
@article{Tsuda.2003, 
year = {2003}, 
keywords = {chaos,convergence,fluctuations,Lyapunov methods,random processes}, 
title = {{Chaotic itinerancy generated by coupling of Milnor attractors}}, 
author = {Tsuda, Ichiro and Umemura, Toshiya}, 
journal = {Chaos}, 
issn = {10541500}, 
doi = {10.1063/1.1599131}, 
pmid = {12946186}, 
url = {http://aip.scitation.org/doi/10.1063/1.1599131}, 
abstract = {{We report the existence of chaotic itinerancy in a coupled Milnor attractor system. The attractor ruins consist of tori or local chaos generated from the original Milnor attractors. The chaotic behavior exhibited by a single orbit can be considered a "nonstationary" state, due to the extremely slow convergence of the Lyapunov exponents, but the behavior averaged over randomly chosen initial conditions is consistent with the limit theorem. We present as a possibly new indication of chaotic itinerancy the presence of slow decay of large fluctuations of the largest Lyapunov exponent.}}, 
pages = {937--946}, 
number = {3}, 
volume = {13}, 
note = {Publisher: American Institute of Physics Inc.}
}
@article{feudel2018multistability, 
year = {2018}, 
title = {{Multistability and tipping: From mathematics and physics to climate and brain - Minireview and preface to the focus issue}}, 
author = {Feudel, Ulrike and Pisarchik, Alexander N. and Showalter, Kenneth}, 
journal = {Chaos}, 
doi = {10.1063/1.5027718}, 
pmid = {29604626}, 
url = {https://doi.org/10.1063/1.5027718}, 
abstract = {{Multistability refers to the coexistence of different stable states in nonlinear dynamical systems. This phenomenon has been observed in laboratory experiments and in nature. In this introduction, we briefly introduce the classes of dynamical systems in which this phenomenon has been found and discuss the extension to new system classes. Furthermore, we introduce the concept of critical transitions and discuss approaches to distinguish them according to their characteristics. Finally, we present some specific applications in physics, neuroscience, biology, ecology, and climate science.}}, 
pages = {33501}, 
number = {3}, 
volume = {28}, 
keywords = {}
}
@article{kaneko2003chaotic, 
year = {2003}, 
title = {{Chaotic itinerancy}}, 
author = {Kaneko, Kunihiko and Tsuda, Ichiro}, 
journal = {Chaos}, 
issn = {1054-1500}, 
doi = {10.1063/1.1607783}, 
pmid = {12946185}, 
url = {https://doi.org/10.1063/1.1607783}, 
abstract = {{Chaotic itinerancy is universal dynamics in high-dimensional dynamical systems, showing itinerant motion among varieties of low-dimensional ordered states through high-dimensional chaos. Discovery, basic features, characterization, examples, and significance of chaotic itinerancy are surveyed.}}, 
pages = {926}, 
number = {3}, 
volume = {13}, 
keywords = {}
}
@article{menck2014how, 
year = {2014}, 
title = {{How dead ends undermine power grid stability}}, 
author = {Menck, Peter J. and Heitzig, Jobst and Kurths, Jürgen and Schellnhuber, Hans Joachim}, 
journal = {Nature Communications}, 
doi = {10.1038/ncomms4969}, 
pmid = {24910217}, 
abstract = {{The cheapest and thus widespread way to add new generators to a high-voltage power grid is by a simple tree-like connection scheme. However, it is not entirely clear how such locally cost-minimizing connection schemes affect overall system performance, in particular the stability against blackouts. Here we investigate how local patterns in the network topology influence a power grid’s ability to withstand blackout-prone large perturbations. Employing basin stability, a nonlinear concept, we find in numerical simulations of artificially generated power grids that tree-like connection schemes—so-called dead ends and dead trees—strongly diminish stability. A case study of the Northern European power system confirms this result and demonstrates that the inverse is also true: repairing dead ends by addition of a few transmission lines substantially enhances stability. This may indicate a topological design principle for future power grids: avoid dead ends. The cheapest way to add new power stations to a domestic power grid is by tree-like connections to the network. A numerical basin stability analysis of Menck et al.suggests that this undermines a grid’s stability against blackouts but can be fixed with extra transmission lines to these otherwise ‘dead ends’.}}, 
pages = {3969}, 
number = {1}, 
volume = {5}, 
keywords = {}
}
@article{Shanahan.2008, 
year = {2008}, 
title = {{Dynamical complexity in small-world networks of spiking neurons}}, 
author = {Shanahan, Murray}, 
journal = {Physical Review E}, 
issn = {1539-3755}, 
doi = {10.1103/physreve.78.041924}, 
pmid = {18999472}, 
eprint = {0808.0088}, 
abstract = {{A computer model is described which is used to assess the dynamical complexity of a class of networks of spiking neurons with small-world properties. Networks are constructed by forming an initially segregated set of highly intraconnected clusters and then applying a probabilistic rewiring method reminiscent of the Watts-Strogatz procedure to make intercluster connections. Causal density, which counts the number of independent significant interactions among a system’s components, is used to assess dynamical complexity. This measure was chosen because it employs lagged observations, and is therefore more sensitive to temporally smeared evidence of segregation and integration than its alternatives. The results broadly support the hypothesis that small-world topology promotes dynamical complexity, but reveal a narrow parameter range within which this occurs for the network topology under investigation, and suggest an inverse correlation with phase synchrony inside this range.}}, 
pages = {041924}, 
number = {4}, 
volume = {78}, 
keywords = {}
}
@article{Graben.2013, 
year = {2013}, 
title = {{Detecting Recurrence Domains of Dynamical Systems by Symbolic Dynamics}}, 
author = {Graben, Peter beim and Hutt, Axel}, 
journal = {Physical Review Letters}, 
issn = {0031-9007}, 
doi = {10.1103/physrevlett.110.154101}, 
pmid = {25167271}, 
eprint = {1211.5906}, 
abstract = {{We propose an algorithm for the detection of recurrence domains of complex dynamical systems from time series. Our approach exploits the characteristic checkerboard texture of recurrence domains exhibited in recurrence plots. In phase space, recurrence plots yield intersecting balls around sampling points that could be merged into cells of a phase space partition. We construct this partition by a rewriting grammar applied to the symbolic dynamics of time indices. A maximum entropy principle defines the optimal size of intersecting balls. The final application to high-dimensional brain signals yields an optimal symbolic recurrence plot revealing functional components of the signal.}}, 
pages = {154101}, 
number = {15}, 
volume = {110}, 
keywords = {}
}
@article{kraut1999preference, 
year = {1999}, 
title = {{Preference of attractors in noisy multistable systems}}, 
author = {Kraut, Suso and Feudel, Ulrike and Grebogi, Celso}, 
journal = {Physical Review E}, 
issn = {1539-3755}, 
doi = {10.1103/physreve.59.5253}, 
pmid = {11969483}, 
abstract = {{A model system exhibiting a large number of attractors is investigated under the influence of noise. Several methods for discriminating two qualitatively different regions of the noise intensity are presented, and the phenomenon of noise-induced preference of attractors is reported. Finally, the relevance of our findings for detection of multiple stable states of systems occurring in nature or in the laboratory is pointed out.}}, 
pages = {5253--5260}, 
number = {5}, 
volume = {59}, 
keywords = {}
}
@article{kraut2002multistability, 
year = {2002}, 
title = {{Multistability, noise, and attractor hopping: The crucial role of chaotic saddles}}, 
author = {Kraut, Suso and Feudel, Ulrike}, 
journal = {Physical Review E}, 
doi = {10.1103/physreve.66.015207}, 
pmid = {12241417}, 
url = {https://journals.aps.org/pre/abstract/10.1103/PhysRevE.66.015207}, 
abstract = {{We investigate the hopping dynamics between different attractors in a multistable system under the influence of noise. Using symbolic dynamics we find a sudden increase of dynamical entropies, when a system parameter is varied. This effect is explained by a bifurcation involving two chaotic saddles. We also demonstrate that the transient lifetimes on the saddle obey a scaling law in analogy to crisis. © 2002 The American Physical Society.}}, 
pages = {015207}, 
number = {1}, 
volume = {66}, 
keywords = {}
}
@article{kraut2003enhancement, 
year = {2003}, 
title = {{Enhancement of noise-induced escape through the existence of a chaotic saddle}}, 
author = {Kraut, Suso and Feudel, Ulrike}, 
journal = {Physical Review E}, 
doi = {10.1103/physreve.67.015204}, 
pmid = {12636550}, 
url = {https://journals.aps.org/pre/abstract/10.1103/PhysRevE.67.015204}, 
abstract = {{We study the noise-induced escape process in a prototype dissipative nonequilibrium system, the Ikeda map. In the presence of a chaotic saddle embedded in the basin of attraction of the metastable state, we find the novel phenomenon of a strong enhancement of noise-induced escape. This result is established by employing the theory of quasipotentials. Our finding is of general validity and should be experimentally observable. © 2003 The American Physical Society.}}, 
pages = {4}, 
number = {1}, 
volume = {67}, 
keywords = {}
}
@article{brede2008synchrony, 
year = {2008}, 
title = {{Synchrony-optimized networks of non-identical Kuramoto oscillators}}, 
author = {Brede, Markus}, 
journal = {Physics Letters, Section A: General, Atomic and Solid State Physics}, 
doi = {10.1016/j.physleta.2007.11.069}, 
abstract = {{In this Letter we discuss a method for generating synchrony-optimized coupling architectures of Kuramoto oscillators with a heterogeneous distribution of native frequencies. The method allows us to relate the properties of the coupling network to its synchronizability. These relations were previously only established from a linear stability analysis of the identical oscillator case. We further demonstrate that the heterogeneity in the oscillator population produces heterogeneity in the optimal coupling network as well. Two rules for enhancing the synchronizability of a given network by a suitable placement of oscillators are given: (i) native frequencies of adjacent oscillators must be anti-correlated and (ii) frequency magnitudes should positively correlate with the degree of the node they are placed at. Crown Copyright © 2007.}}, 
pages = {2618--2622}, 
number = {15}, 
volume = {372}, 
keywords = {}
}
@article{hong2002synchronization, 
year = {2002}, 
title = {{Synchronization on small-world networks}}, 
author = {Hong, H. and Choi, M. Y. and Kim, Beom Jun}, 
journal = {Physical Review E}, 
doi = {10.1103/physreve.65.026139}, 
pmid = {11863619}, 
abstract = {{We investigate collective synchronization in a system of coupled oscillators on small-world networks. The order parameters that measure synchronization of phases and frequencies are introduced and analyzed by means of dynamic simulations and finite-size scaling. Phase synchronization is observed to emerge in the presence of even a tiny fraction P of shortcuts and to display saturated behavior for [formula presented] This indicates that the same synchronizability as the random network [formula presented] can be achieved with relatively small number of shortcuts. The transient behavior of the synchronization, obtained from the measurement of the relaxation time, is also discussed. © 2002 The American Physical Society.}}, 
pages = {1--5}, 
number = {2}, 
volume = {65}, 
keywords = {}
}
@article{hong2015finite, 
year = {2015}, 
title = {{Finite-size scaling, dynamic fluctuations, and hyperscaling relation in the Kuramoto model}}, 
author = {Hong, Hyunsuk and Chaté, Hugues and Tang, Lei Han and Park, Hyunggyu}, 
journal = {Physical Review E}, 
doi = {10.1103/physreve.92.022122}, 
pmid = {26382359}, 
abstract = {{We revisit the Kuramoto model to explore the finite-size scaling (FSS) of the order parameter and its dynamic fluctuations near the onset of the synchronization transition, paying particular attention to effects induced by the randomness of the intrinsic frequencies of oscillators. For a population of size N, we study two ways of sampling the intrinsic frequencies according to the same given unimodal distribution g(\textbackslash\$ømega\textbackslash\$). In the "random" case, frequencies are generated independently in accordance with g(\textbackslash\$ømega\textbackslash\$), which gives rise to oscillator number fluctuation within any given frequency interval. In the "regular" case, the N frequencies are generated in a deterministic manner that minimizes the oscillator number fluctuations, leading to quasiuniformly spaced frequencies in the population. We find that the two samplings yield substantially different finite-size properties with clearly distinct scaling exponents. Moreover, the hyperscaling relation between the order parameter and its fluctuations is valid in the regular case, but it is violated in the random case. In this last case, a self-consistent mean-field theory that completely ignores dynamic fluctuations correctly predicts the FSS exponent of the order parameter but not its critical amplitude.}}, 
pages = {1--8}, 
number = {2}, 
volume = {92}, 
keywords = {}
}
@article{hong2013link, 
year = {2013}, 
title = {{Link-disorder fluctuation effects on synchronization in random networks}}, 
author = {Hong, Hyunsuk and Um, Jaegon and Park, Hyunggyu}, 
journal = {Physical Review E - Statistical, Nonlinear, and Soft Matter Physics}, 
doi = {10.1103/physreve.87.042105}, 
pmid = {23679371}, 
eprint = {1304.0610}, 
abstract = {{We consider one typical system of oscillators coupled through disordered link configurations in networks, i.e., a finite population of coupled phase oscillators with distributed intrinsic frequencies on a random network. We investigate the collective synchronization behavior, paying particular attention to link-disorder fluctuation effects on the synchronization transition and its finite-size scaling (FSS). Extensive numerical simulations as well as the mean-field analysis have been performed. We find that link-disorder fluctuations effectively induce uncorrelated random fluctuations in frequency, resulting in the FSS exponent ν̄=5/2, which is identical to that in the globally coupled case (no link disorder) with frequency-disorder fluctuations. © 2013 American Physical Society.}}, 
pages = {1--5}, 
number = {4}, 
volume = {87}, 
keywords = {}
}
@article{hong2007entrainment, 
year = {2007}, 
title = {{Entrainment transition in populations of random frequency oscillators}}, 
author = {Hong, Hyunsuk and Chaté, Hugues and Park, Hyunggyu and Tang, Lei Han}, 
journal = {Physical Review Letters}, 
doi = {10.1103/physrevlett.99.184101}, 
pmid = {17995410}, 
abstract = {{The entrainment transition of coupled random frequency oscillators is revisited. The Kuramoto model (global coupling) is shown to exhibit unusual sample-dependent finite-size effects leading to a correlation size exponent ν̄=5/2. Simulations of locally coupled oscillators in d dimensions reveal two types of frequency entrainment: mean-field behavior at d>4 and aggregation of compact synchronized domains in three and four dimensions. In the latter case, scaling arguments yield a correlation length exponent ν=2/(d-2), in good agreement with numerical results. © 2007 The American Physical Society.}}, 
pages = {1--4}, 
number = {18}, 
volume = {99}, 
keywords = {}
}
@article{carareto2009optimized, 
year = {2009}, 
keywords = {Complex networks,Coupled oscillators,Kuramoto oscillators,Optimization}, 
title = {{Optimized network structure for full-synchronization}}, 
author = {Carareto, R. and Orsatti, F. M. and Piqueira, J. R.C.}, 
journal = {Communications in Nonlinear Science and Numerical Simulation}, 
doi = {10.1016/j.cnsns.2008.09.032}, 
abstract = {{A network of Kuramoto oscillators with different natural frequencies is optimized for enhanced synchronizability. All node inputs are normalized by the node connectivity and some important properties of the network structure are determined in this case: (i) optimized networks present a strong anti-correlation between natural frequencies of adjacent nodes; (ii) this anti-correlation should be as high as possible since the average path length between nodes is maintained as small as in random networks; and (iii) high anti-correlation is obtained without any relation between nodes natural frequencies and the degree of connectivity. We also propose a network construction model with which it is shown that high anti-correlation and small average paths may be achieved by randomly rewiring a fraction of the links of a totally anti-correlated network, and that these networks present optimal synchronization properties. © 2008 Elsevier B.V. All rights reserved.}}, 
pages = {2536--2541}, 
number = {6}, 
volume = {14}
}
@article{tang2011finite, 
year = {2011}, 
keywords = {Dynamical heterogeneities (theory),Finite-size scaling,Network dynamics,Nonlinear dynamics}, 
title = {{To synchronize or not to synchronize, that is the question: Finite-size scaling and fluctuation effects in the Kuramoto model}}, 
author = {Tang, Lei Han}, 
journal = {Journal of Statistical Mechanics: Theory and Experiment}, 
doi = {10.1088/1742-5468/2011/01/p01034}, 
eprint = {1011.5823}, 
abstract = {{The entrainment transition of coupled random frequency oscillators presents a long-standing problem in nonlinear physics. The onset of entrainment in populations of large but finite size exhibits strong sensitivity to fluctuations in the oscillator density at the synchronizing frequency. This is the source for the unusual values assumed by the correlation size exponent ν′. Locally coupled oscillators on a d-dimensional lattice exhibit two types of frequency entrainment in the thermodynamic limit: symmetry-breaking at d > 4 and aggregation of compact synchronized domains in three and four dimensions. Various critical properties of the transition are well captured by finite-size scaling relations with simple yet unconventional exponent values. © 2011 IOP Publishing Ltd and SISSA.}}, 
pages = {P01034}, 
number = {1}, 
volume = {2011}
}
@article{hong2007finitesizescalingpre, 
year = {2007}, 
title = {{Finite-size scaling of synchronized oscillation on complex networks}}, 
author = {Hong, Hyunsuk and Park, Hyunggyu and Tang, Lei Han}, 
journal = {Physical Review E}, 
doi = {10.1103/physreve.76.066104}, 
pmid = {18233895}, 
abstract = {{The onset of synchronization in a system of random frequency oscillators coupled through a random network is investigated. Using a mean-field approximation, we characterize sample-to-sample fluctuations for networks of finite size, and derive the corresponding scaling properties in the critical region. For scale-free networks with the degree distribution P (k) ∼ k-γ at large k, we found that the finite-size exponent ν̄ takes on the value 5/2 when γ>5, the same as in the globally coupled Kuramoto model. For highly heterogeneous networks (3<γ\textbackslashtextless5), ν̄ and the order parameter exponent β depend on γ. The analytical expressions for these exponents obtained from the mean-field theory are shown to be in excellent agreement with data from extensive numerical simulations. © 2007 The American Physical Society.}}, 
pages = {1--7}, 
number = {6}, 
volume = {76}, 
keywords = {}
}
@article{datseris2018dynamical, 
year = {2018}, 
title = {{DynamicalSystems.jl: A Julia software library for chaos and nonlinear dynamics}}, 
author = {Datseris, George}, 
journal = {Journal of Open Source Software}, 
issn = {2475-9066}, 
doi = {10.21105/joss.00598}, 
url = {https://doi.org/10.21105/joss.00598}, 
pages = {598}, 
number = {23}, 
volume = {3}, 
note = {Publisher: The Open Journal}, 
keywords = {}
}
@article{schoner1988dynamic, 
year = {1988}, 
title = {{A dynamic pattern theory of behavioral change}}, 
author = {Schöner, G. and Kelso, J. A.S.}, 
journal = {Journal of Theoretical Biology}, 
doi = {10.1016/s0022-5193(88)80273-x}, 
abstract = {{Intentional change of behavior is an essential phenomenon that theoretical biology cannot fail to address. Often, theoretical attempts to understand the problem and experimental study of behavioral change are quite unrelated to each other. Recent progress in formulating a strictly operational dynamic theory of behavioral patterns, however, offers a link between theory and experiment. Here the understanding of intentional change of behavioral pattern in this theoretical language is shown. The general formulation provides predictions on the relation between the dynamics of behavioral patterns and the nature of the process of behavioral change. Theoretically founded measures, including switching time and first exit time, are introduced that allow a characterization of this process. A concrete system involving temporally ordered behavior is modelled explictly on two experimentally accessible levels of observation. Switching time and first passage time measures are calculated from the theory and the results compared to recent experimental observations. We discuss the potential of the switching time measures for the more general study of behavioral patterns and their dynamics. © 1988 Academic Press Limited.}}, 
pages = {501--524}, 
number = {4}, 
volume = {135}, 
note = {Publisher: Academic Press}, 
keywords = {}
}
@incollection{kelso1995mulltistability, 
year = {1995}, 
title = {{Multistability and Metastability in Perceptual and Brain Dynamics}}, 
author = {Kelso, J. A. S. and Case, P. and Holroyd, T. and Horvath, E. and aczaszek, J. Ŗ and Tuller, B. and Ding, M.}, 
isbn = {9783642784132}, 
url = {https://link.springer.com/chapter/10.1007/978-3-642-78411-8\_9}, 
abstract = {{In this paper we demonstrate that vision, speech and language may exhibit self-organizing dynamic properties including transitions between perceptual states, multistability, instability, and hysteresis. Theses features illustrate a crucial characteristic of perpecptual organization, namely, the ability to function coherently yet retain some degree of flexibility. We propose the generic dynamical mechanism of intermittency as a way to flexibly enter and exit perceptual states, and suggest that this mechanism is exploited in coordinated perceptual and neural behavior. 1}}, 
pages = {159--184}, 
series = {Springer Series in Synergetics}, 
publisher = {Springer, Berlin, Heidelberg}, 
keywords = {}, 
doi = {10.1007/978-3-642-78411-8\_9}
}
@article{kelso2007toward, 
year = {2007}, 
keywords = {Brain,Consciousness,Coordination indexCoordinationbreak dynamics,Metastability,The complementary nature}, 
title = {{Toward a complementary neuroscience: Metastable coordination dynamics of the brain}}, 
author = {Kelso, J. A.Scott and Tognoli, Emmanuelle}, 
journal = {Understanding Complex Systems}, 
doi = {10.1007/978-3-540-73267-9\_3}, 
url = {https://link.springer.com/chapter/10.1007/978-3-540-73267-9\_3}, 
abstract = {{Metastability has been proposed as a new principle of behavioral and brain function and may point the way to a truly complementary neuroscience. From elementary coordination dynamics we show explicitly that metastability is a result of a symmetry breaking caused by the subtle interplay of two forces: the tendency of the components to couple together and the tendency of the components to express their intrinsic independent behavior. The metastable regime reconciles the well-known tendencies of specialized brain regions to express their autonomy (segregation) and the tendencies for those regions to work together as a synergy (integration). Integration ∼ segregation is just one of the complementary pairs (denoted by the tilde (∼) symbol) to emerge from the science of coordination dynamics. We discuss metastability in the brain by describing the favorable conditions existing for its emergence and by deriving some predictions for its empirical characterization in neurophysiological recordings. © 2007 Springer-Verlag Berlin Heidelberg.}}, 
pages = {39--59}, 
volume = {2007}, 
note = {ISBN: 3540732667 Publisher: Springer, Berlin, Heidelberg}
}
@article{kelso2013outline, 
year = {2013}, 
keywords = {Behavior,Brain,Complementarity,Coordination dynamics,Multiscale}, 
title = {{Outline of a general theory of behavior and brain coordination}}, 
author = {Kelso, J. A.Scott and Dumas, Guillaume and Tognoli, Emmanuelle}, 
journal = {Neural Networks}, 
doi = {10.1016/j.neunet.2012.09.003}, 
pmid = {23084845}, 
abstract = {{Much evidence suggests that dynamic laws of neurobehavioral coordination are sui generis: they deal with collective properties that are repeatable from one system to another and emerge from microscopic dynamics but may not (even in principle) be deducible from them. Nevertheless, it is useful to try to understand the relationship between different levels while all the time respecting the autonomy of each. We report a program of research that uses the theoretical concepts of coordination dynamics and quantitative measurements of simple, well-defined experimental model systems to explicitly relate neural and behavioral levels of description in human beings. Our approach is both top-down and bottom-up and aims at ending up in the same place: top-down to derive behavioral patterns from neural fields, and bottom-up to generate neural field patterns from bidirectional coupling between astrocytes and neurons. Much progress can be made by recognizing that the two approaches-reductionism and emergentism-are complementary. A key to understanding is to couch the coordination of very different things-from molecules to thoughts-in the common language of coordination dynamics. © 2012 Elsevier Ltd.}}, 
pages = {120--131}, 
volume = {37}, 
note = {Publisher: Elsevier Ltd}
}
@article{acebron2005kuramoto, 
year = {2005}, 
title = {{The Kuramoto model: A simple paradigm for synchronization phenomena}}, 
author = {Acebrón, Juan A. and Bonilla, L. L. and Vicente, Conrad J.Pérez and Ritort, Félix and Spigler, Renato}, 
journal = {Reviews of Modern Physics}, 
doi = {10.1103/revmodphys.77.137}, 
abstract = {{Synchronization phenomena in large populations of interacting elements are the subject of intense research efforts in physical, biological, chemical, and social systems. A successful approach to the problem of synchronization consists of modeling each member of the population as a phase oscillator. In this review, synchronization is analyzed in one of the most representative models of coupled phase oscillators, the Kuramoto model. A rigorous mathematical treatment, specific numerical methods, and many variations and extensions of the original model that have appeared in the last few years are presented. Relevant applications of the model in different contexts are also included. © 2005 The American Physical Society.}}, 
pages = {137--185}, 
number = {1}, 
volume = {77}, 
keywords = {}
}
@article{fingelkurts2017information, 
year = {2017}, 
keywords = {Circular causality,EEG,Information,Metastability,Operational architectonics,Operational modules,Operational synchrony,Rapid transitional periods,Self-organisation}, 
title = {{Information flow in the brain: Ordered sequences of metastable states}}, 
author = {Fingelkurts, Andrew A. and Fingelkurts, Alexander A.}, 
journal = {Information (Switzerland)}, 
doi = {10.3390/info8010022}, 
abstract = {{In this brief overview paper, we analyse information flow in the brain. Although Shannon's information concept, in its pure algebraic form, has made a number of valuable contributions to neuroscience, information dynamics within the brain is not fully captured by its classical description. These additional dynamics consist of self-organisation, interplay of stability/instability, timing of sequential processing, coordination of multiple sequential streams, circular causality between bottom-up and top-down operations, and information creation. Importantly, all of these processes are dynamic, hierarchically nested and correspond to continuous brain state change, even if the external environment remains constant. This is where metastable coordination comes into play. In a metastable regime of brain functioning, as a result of the simultaneous co-existence of tendencies for independence and cooperation, information is continuously created, preserved for some time and then dissipated through the formation of dynamical and nested spatio-temporal coalitions among simple neuronal assemblies and larger coupled conglomerates of them-so-called delocalised operational modules.}}, 
pages = {1--9}, 
number = {1}, 
volume = {8}
}
@book{Fingelkurts.2009, 
year = {2009}, 
keywords = {Brain research,Cognition,Consciousness,Isomorphism,Metastability,Multivariability,Neural networks,Operational architectonics,Self-organization}, 
title = {{Making complexity simpler: Multivariability and metastability in the brain}}, 
author = {Fingelkurts, Andrew A. and Fingelkurts, Alexander A.}, 
url = {https://www.tandfonline.com/doi/abs/10.1080/00207450490450046}, 
abstract = {{This article provides a retrospective, current, and prospective overview on developments in brain research and neuroscience. Both theoretical and empirical studies are considered, with emphasis in the concept of multivariability and metastability in the brain. In this new view on the human brain, the potential multivariability of the neuronal networks appears to be far from continuous in time, but confined by the dynamics of short-term local and global metastable brain states. The article closes by suggesting some of the implications of this view in future multidisciplinary brain research.}}, 
volume = {114}, 
series = {International Journal of Neuroscience}, 
number = {7}, 
publisher = {Taylor \& Francis}, 
note = {ISSN: 00207454 Publication Title: International Journal of Neuroscience}, 
doi = {10.1080/00207450490450046}
}
@article{poncealvarez2015restingstate, 
year = {2015}, 
title = {{Resting-State Temporal Synchronization Networks Emerge from Connectivity Topology and Heterogeneity}}, 
author = {Ponce-Alvarez, Adrián and Deco, Gustavo and Hagmann, Patric and Romani, Gian Luca and Mantini, Dante and Corbetta, Maurizio}, 
journal = {PLOS Computational Biology}, 
issn = {1553-7358}, 
doi = {10.1371/journal.pcbi.1004100}, 
pmid = {25692996}, 
pmcid = {PMC4333573}, 
url = {https://dx.plos.org/10.1371/journal.pcbi.1004100}, 
abstract = {{Spatial patterns of coherent activity across different brain areas have been identified during the resting-state fluctuations of the brain. However, recent studies indicate that resting-state activity is not stationary, but shows complex temporal dynamics. We were interested in the spatiotemporal dynamics of the phase interactions among resting-state fMRI BOLD signals from human subjects. We found that the global phase synchrony of the BOLD signals evolves on a characteristic ultra-slow (<0.01Hz) time scale, and that its temporal variations reflect the transient formation and dissolution of multiple communities of synchronized brain regions. Synchronized communities reoccurred intermittently in time and across scanning sessions. We found that the synchronization communities relate to previously defined functional networks known to be engaged in sensory-motor or cognitive function, called resting-state networks (RSNs), including the default mode network, the somato-motor network, the visual network, the auditory network, the cognitive control networks, the self-referential network, and combinations of these and other RSNs. We studied the mechanism originating the observed spatiotemporal synchronization dynamics by using a network model of phase oscillators connected through the brain's anatomical connectivity estimated using diffusion imaging human data. The model consistently approximates the temporal and spatial synchronization patterns of the empirical data, and reveals that multiple clusters that transiently synchronize and desynchronize emerge from the complex topology of anatomical connections, provided that oscillators are heterogeneous.}}, 
editor = {["C.\textbackslashtextbackslash"] and Claus"]}, 
pages = {e1004100}, 
number = {2}, 
volume = {11}, 
keywords = {}
}
@article{hellyer2014control, 
year = {2014}, 
title = {{The control of global brain dynamics: Opposing actions of frontoparietal control and default mode networks on attention}}, 
author = {Hellyer, Peter J. and Shanahan, Murray and Scott, Gregory and Wise, Richard J.S. and Sharp, David J. and Leech, Robert}, 
journal = {Journal of Neuroscience}, 
doi = {10.1523/jneurosci.1853-13.2014}, 
pmid = {24403145}, 
url = {https://www.jneurosci.org/content/34/2/451 https://www.jneurosci.org/content/34/2/451.abstract}, 
abstract = {{Understanding how dynamic changes in brain activity control behavior is a major challenge of cognitive neuroscience. Here, we consider the brain as a complex dynamic system and define two measures of brain dynamics: the synchrony of brain activity, measured by the spatial coherence of the BOLD signal across regions of the brain; and metastability, which we define as the extent to which synchrony varies over time. We investigate the relationship among brain network activity, metastability, and cognitive state in humans, testing the hypothesis that global metastability is "tuned" by network interactions. We study the following two conditions: (1) an attentionally demanding choice reaction time task (CRT); and (2) an unconstrained "rest" state. Functional MRI demonstrated increased synchrony, and decreased metastability was associated with increased activity within the frontoparietal control/dorsal attention network (FPCN/DAN) activity and decreased default mode network (DMN) activity during the CRT compared with rest. Using a computational model of neural dynamics that is constrained by white matter structure to test whether simulated changes in FPCN/DAN and DMN activity produce similar effects, we demonstate that activation of the FPCN/DAN increases global synchrony and decreases metastability. DMN activation had the opposite effects. These results suggest that the balance of activity in the FPCN/DAN and DMN might control global metastability, providing a mechanistic explanation of how attentional state is shifted between an unfocused/exploratory mode characterized by high metastability, and a focused/constrained mode characterized by low metastability. © 2014 the authors.}}, 
pages = {451--461}, 
number = {2}, 
volume = {34}, 
keywords = {}
}
@article{fingelkurts2001operational, 
year = {2001}, 
keywords = {Adaptive segmentation,Binding problem,Coherence,EEG microstructure,Functional integration,Metastability,Neocortical dynamics,Nonstationarity,Operational synchronization,Spatial scale}, 
title = {{Operational architectonics of the human brain biopotential field: Towards solving the mind-brain problem}}, 
author = {Fingelkurts, Andrew A. and Fingelkurts, Alexander A.}, 
journal = {Brain and Mind}, 
issn = {1389-1987}, 
doi = {10.1023/a:1014427822738}, 
url = {https://link.springer.com/article/10.1023/A:1014427822738}, 
abstract = {{The understanding of the interrelationship between brain and mind remains far from clear. It is well established that the brain's capacity to integrate information from numerous sources forms the basis for cognitive abilities. However, the core unresolved question is how information about the "objective" physical entities of the external world can be integrated, and how unified and coherent mental states (or Gestalts) can be established in the internal entities of distributed neuronal systems. The present paper offers a unified methodological and conceptual basis for a possible mechanism of how the transient synchronization of brain operations may construct the unified and relatively stable neural states, which underlie mental states. It was shown that the sequence of metastable spatial EEG mosaics does exist and probably reflects the rapid stabilization periods of the interrelation of large neuron systems. At the EEG level this is reflected in the stabilization of quasi-stationary segments on corresponding channels. Within the introduced framework, physical brain processes and psychological processes are considered as two basic aspects of a single whole informational brain state. The relations between operational process of the brain, mental states and consciousness are discussed.}}, 
pages = {261--296}, 
number = {3}, 
volume = {2}, 
note = {ISSN: 13891987 Publication Title: Brain and Mind}
}
@incollection{kelso1991an, 
year = {1991}, 
title = {{An Intermittency Mechanism for Coherent and Flexible Brain and Behavioral Function}}, 
author = {Kelso, J. A. S. and DeGuzman, G. C.}, 
booktitle = {Tutorials in Motor Neuroscience}, 
isbn = {9789401056090}, 
url = {https://link.springer.com/chapter/10.1007/978-94-011-3626-6\_25}, 
abstract = {{a little paper..}}, 
pages = {305--310}, 
publisher = {Springer Netherlands}, 
keywords = {}, 
doi = {10.1007/978-94-011-3626-6\_25}
}
@article{afraimovich2008winnerless, 
year = {2008}, 
keywords = {afra,ecology,nonlinear dynamical systems,Volterra equations}, 
title = {{Winnerless competition principle and prediction of the transient dynamics in a Lotka-Volterra model}}, 
author = {Afraimovich, Valentin and Tristan, Irma and Huerta, Ramon and Rabinovich, Mikhail I.}, 
journal = {Chaos}, 
doi = {10.1063/1.2991108}, 
pmid = {19123613}, 
url = {http://aip.scitation.org/doi/10.1063/1.2991108}, 
abstract = {{Predicting the evolution of multispecies ecological systems is an intriguing problem. A sufficiently complex model with the necessary predicting power requires solutions that are structurally stable. Small variations of the system parameters should not qualitatively perturb its solutions. When one is interested in just asymptotic results of evolution (as time goes to infinity), then the problem has a straightforward mathematical image involving simple attractors (fixed points or limit cycles) of a dynamical system. However, for an accurate prediction of evolution, the analysis of transient solutions is critical. In this paper, in the framework of the traditional Lotka-Volterra model (generalized in some sense), we show that the transient solution representing multispecies sequential competition can be reproducible and predictable with high probability. © 2008 American Institute of Physics.}}, 
pages = {043103}, 
number = {4}, 
volume = {18}, 
note = {Publisher: American Institute of Physics Inc.}
}
@article{taylor2011attractors, 
year = {2011}, 
title = {{Attractors: Nonstrange to Chaotic}}, 
author = {Taylor, Robert L.V.}, 
journal = {SIAM Undergraduate Research Online}, 
doi = {10.1137/10s01079x}, 
abstract = {{The theory of chaotic dynamical systems can̊\textbackslashtextbackslashnbe a tricky area of study for a non-expert to break into.\textbackslashtextbackslashr\textbackslashtextbackslashnBecause the theory is relatively recent, the new student finds\textbackslashtextbackslashr\textbackslashtextbackslashnhimself immersed in a subject with very few clear and\textbackslashtextbackslashr\textbackslashtextbackslashnintuitive definitions. This paper aims to carve out a small\textbackslashtextbackslashr\textbackslashtextbackslashnsection of the theory of chaotic dynamical systems – that\textbackslashtextbackslashr\textbackslashtextbackslashnof attractors – and outline its fundamental concepts from a\textbackslashtextbackslashr\textbackslashtextbackslashncomputational mathematics perspective. The motivation for\textbackslashtextbackslashr\textbackslashtextbackslashnthis paper is primarily to define what an attractor is and\textbackslashtextbackslashr\textbackslashtextbackslashnto clarify what distinguishes its various types (nonstrange,\textbackslashtextbackslashr\textbackslashtextbackslashnstrange nonchaotic, and strange chaotic). Furthermore, by\textbackslashtextbackslashr\textbackslashtextbackslashnproviding some examples of attractors and explaining how\textbackslashtextbackslashr\textbackslashtextbackslashnand why they are classified, we hope to provide the reader\textbackslashtextbackslashr\textbackslashtextbackslashnwith a good feel for the fundamental connection between\textbackslashtextbackslashr\textbackslashtextbackslashnfractal geometry and the existence of chaos.}}, 
pages = {72--80}, 
volume = {4}, 
note = {Publisher: Society for Industrial \& Applied Mathematics (SIAM)}, 
keywords = {}
}
@article{budzinski2020synchronization, 
year = {2020}, 
keywords = {doi:10.1103/PhysRevResearch.2.043309 url:https://d}, 
title = {{Synchronization malleability in neural networks under a distance-dependent coupling}}, 
author = {Budzinski, R. C. and Rossi, K. L. and Boaretto, B. R. R. and Prado, T. L. and Lopes, S. R.}, 
journal = {Physical Review Research}, 
issn = {2643-1564}, 
doi = {10.1103/physrevresearch.2.043309}, 
url = {https://link.aps.org/doi/10.1103/PhysRevResearch.2.043309}, 
abstract = {{We investigate the synchronization features of a network of spiking neurons under a distance-dependent coupling following a power-law model. The interplay between topology and coupling strength leads to the existence of different spatiotemporal patterns, corresponding to either nonsynchronized or phase-synchronized states. Particularly interesting is what we call synchronization malleability, in which the system depicts significantly different phase-synchronization degrees for the same parameters as a consequence of a different ordering of neural inputs. We analyze the functional connectivity of the network by calculating the mutual information between neuronal spike trains, allowing us to characterize the structures of synchronization in the network. We show that these structures are dependent on the ordering of the inputs for the parameter regions where the network presents synchronization malleability and we suggest that this is due to a complex interplay between coupling, connection architecture, and individual neural inputs.}}, 
pages = {043309}, 
number = {4}, 
volume = {2}
}
@article{Fingelkurts.2006, 
year = {2006}, 
title = {{MAPPING OF BRAIN OPERATIONAL ARCHITECTONICS}}, 
author = {Fingelkurts, A. and Fingelkurts, A.}, 
journal = {undefined}, 
keywords = {}
}
@article{vasa2015effects, 
year = {2015}, 
keywords = {Connectome,Graph theory,Kuramoto model,Metastability,Neural dynamics,Stroke}, 
title = {{Effects of lesions on synchrony and metastability in cortical networks}}, 
author = {Váša, František and Shanahan, Murray and Hellyer, Peter J. and Scott, Gregory and Cabral, Joana and Leech, Robert}, 
journal = {NeuroImage}, 
doi = {10.1016/j.neuroimage.2015.05.042}, 
pmid = {26049146}, 
url = {http://dx.doi.org/10.1016/j.neuroimage.2015.05.042}, 
abstract = {{At the macroscopic scale, the human brain can be described as a complex network of white matter tracts integrating grey matter assemblies - the human connectome. The structure of the connectome, which is often described using graph theoretic approaches, can be used to model macroscopic brain function at low computational cost. Here, we use the Kuramoto model of coupled oscillators with time-delays, calibrated with respect to empirical functional MRI data, to study the relation between the structure of the connectome and two aspects of functional brain dynamics - synchrony, a measure of general coherence, and metastability, a measure of dynamical flexibility. Specifically, we investigate the relationship between the local structure of the connectome, quantified using graph theory, and the synchrony and metastability of the model's dynamics. By removing individual nodes and all of their connections from the model, we study the effect of lesions on both global and local dynamics. Of the nine nodal graph-theoretical properties tested, two were able to predict effects of node lesion on the global dynamics. The removal of nodes with high eigenvector centrality leads to decreases in global synchrony and increases in global metastability, as does the removal of hub nodes joining topologically segregated network modules. At the level of local dynamics in the neighbourhood of the lesioned node, structural properties of the lesioned nodes hold more predictive power, as five nodal graph theoretical measures are related to changes in local dynamics following node lesions. We discuss these results in the context of empirical studies of stroke and functional brain dynamics.}}, 
pages = {456--467}, 
volume = {118}
}
@article{rabinovich2008transientcognitive, 
year = {2008}, 
keywords = {Brain metastasis,Cognition,Decision making,Dynamical systems,Games,Metastasis,Nonlinear dynamics,System instability}, 
title = {{Transient cognitive dynamics, metastability, and decision making}}, 
author = {Rabinovich, Mikhail I. and Huerta, Ramón and Varona, Pablo and Afraimovich, Valentin S.}, 
journal = {PLoS Computational Biology}, 
doi = {10.1371/journal.pcbi.1000072}, 
pmid = {18452000}, 
pmcid = {PMC2358972}, 
url = {www.ploscompbiol.org}, 
abstract = {{The idea that cognitive activity can be understood using nonlinear dynamics has been intensively discussed at length for the last 15 years. One of the popular points of view is that metastable states play a key role in the execution of cognitive functions. Experimental and modeling studies suggest that most of these functions are the result of transient activity of large-scale brain networks in the presence of noise. Such transients may consist of a sequential switching between different metastable cognitive states. The main problem faced when using dynamical theory to describe transient cognitive processes is the fundamental contradiction between reproducibility and flexibility of transient behavior. In this paper, we propose a theoretical description of transient cognitive dynamics based on the interaction of functionally dependent metastable cognitive states. The mathematical image of such transient activity is a stable heteroclinic channel, i.e., a set of trajectories in the vicinity of a heteroclinic skeleton that consists of saddles and unstable separatrices that connect their surroundings. We suggest a basic mathematical model, a strongly dissipative dynamical system, and formulate the conditions for the robustness and reproducibility of cognitive transients that satisfy the competing requirements for stability and flexibility. Based on this approach, we describe here an effective solution for the problem of sequential decision making, represented as a fixed time game: a player takes sequential actions in a changing noisy environment so as to maximize a cumulative reward. As we predict and verify in computer simulations, noise plays an important role in optimizing the gain. © 2008 Rabinovich et al.}}, 
pages = {1000072}, 
number = {5}, 
volume = {4}
}
@article{medeiros2019state, 
year = {2019}, 
title = {{State-dependent vulnerability of synchronization}}, 
author = {Medeiros, Everton S. and Medrano-T, Rene O. and Caldas, Iberê L. and Tél, Tamás and Feudel, Ulrike}, 
journal = {Physical Review E}, 
doi = {10.1103/physreve.100.052201}, 
pmid = {31869887}, 
eprint = {1904.11420}, 
url = {https://journals.aps.org/pre/abstract/10.1103/PhysRevE.100.052201}, 
abstract = {{A state-dependent vulnerability of synchronization is shown to exist in a complex network composed of numerically simulated electronic circuits. We demonstrate that disturbances to the local dynamics of network units can produce different outcomes to synchronization depending on the current state of its trajectory. We address such state dependence by systematically perturbing the synchronized system at states equally distributed along its trajectory. We find the states at which the perturbation desynchronizes the network to be complicatedly mixed with the ones that restore synchronization. Additionally, we characterize perturbation sets obtained for consecutive states by defining a safety index between them. Finally, we demonstrate that the observed vulnerability is due to the existence of an unstable chaotic set in the system's state space.}}, 
pages = {052201}, 
number = {5}, 
volume = {100}, 
note = {Publisher: American Physical Society}, 
keywords = {}
}
@article{manik2017network, 
year = {2017}, 
title = {{Network susceptibilities: Theory and applications}}, 
author = {Manik, Debsankha and Rohden, Martin and Ronellenfitsch, Henrik and Zhang, Xiaozhu and Hallerberg, Sarah and Witthaut, Dirk and Timme, Marc}, 
journal = {Physical Review E}, 
doi = {10.1103/physreve.95.012319}, 
pmid = {28208371}, 
eprint = {1609.04310}, 
url = {https://journals.aps.org/pre/abstract/10.1103/PhysRevE.95.012319}, 
abstract = {{We introduce the concept of network susceptibilities quantifying the response of the collective dynamics of a network to small parameter changes. We distinguish two types of susceptibilities: vertex susceptibilities and edge susceptibilities, measuring the responses due to changes in the properties of units and their interactions, respectively. We derive explicit forms of network susceptibilities for oscillator networks close to steady states and offer example applications for Kuramoto-type phase-oscillator models, power grid models, and generic flow models. Focusing on the role of the network topology implies that these ideas can be easily generalized to other types of networks, in particular those characterizing flow, transport, or spreading phenomena. The concept of network susceptibilities is broadly applicable and may straightforwardly be transferred to all settings where networks responses of the collective dynamics to topological changes are essential.}}, 
pages = {012319}, 
number = {1}, 
volume = {95}, 
keywords = {}
}
@incollection{Kelso.1990, 
year = {1990}, 
title = {{Phase Transitions: Foundations of Behavior}}, 
author = {Kelso and J., A. S.}, 
isbn = {9783642487811}, 
url = {https://link.springer.com/chapter/10.1007/978-3-642-48779-8\_15}, 
abstract = {{Synergetic phase transitions afford a special window into the principles of behavior at several levels of desciption. The reason is that instabilities serve to demarcate behavioral patterns, thereby allowing a precise identification of collective variables or order parameters for patterns and their (nonlinear) dynamics. Once the, order parameter dynamics are known for particular experimental model systems, not only can they be derived or synthesized, but a number of steps of generalization becomes possible. Certain essential psychological functions such as the perception of dynamic visual and speech patterns, intentional behavioral change and learning a novel behavioral pattern are addressed here. All observed phenomena may be expressed in dynamical language.}}, 
pages = {249--268}, 
series = {Springer Series in Synergetics}, 
publisher = {Springer, Berlin, Heidelberg}, 
keywords = {}, 
doi = {10.1007/978-3-642-48779-8\_15}
}
@book{Kringelbach.2015, 
year = {2015}, 
keywords = {Dynamical systems,Resting-state activity,Whole-brain modeling}, 
title = {{The Rediscovery of Slowness: Exploring the Timing of Cognition}}, 
author = {Kringelbach, Morten L. and McIntosh, Anthony R. and Ritter, Petra and Jirsa, Viktor K. and Deco, Gustavo}, 
url = {http://www.cell.com/article/S1364661315001758/fulltext http://www.cell.com/article/S1364661315001758/abstract https://www.cell.com/trends/cognitive-sciences/abstract/S1364-6613(15)00175-8}, 
abstract = {{Slowness of thought is not necessarily a handicap but could be a signature of optimal brain function. Emerging evidence shows that neuroanatomical and dynamical constraints of the human brain shape its functionality in optimal ways, characterized by slowness during task-based cognition in the context of spontaneous resting-state activity. This activity can be described mechanistically by whole-brain computational modeling that relates directly to optimality in the context of theories arguing for metastability in the brain. We discuss the role for optimal processing of information in the context of cognitive, task-related activity, and propose that combining multi-modal neuroimaging and explicit whole-brain models focused on the timing of functional dynamics can help to uncover fundamental rules of brain function in health and disease. The dynamics of the human brain exhibits 'slowness' during spontaneous activity and task-based cognition.Whole-brain computational modeling can account for the mechanisms underlying this slowness in terms of maximal metastability of the dynamical system.A better understanding of the balance between fast and slow brain processing could lead to fundamental new insights into the brain in health and disease.}}, 
volume = {19}, 
series = {Trends in Cognitive Sciences}, 
number = {10}, 
publisher = {Elsevier Ltd}, 
note = {ISSN: 1879307X Publication Title: Trends in Cognitive Sciences}, 
doi = {10.1016/j.tics.2015.07.011}
}
@article{Werner.2007, 
year = {2007}, 
keywords = {Dynamic core hypothesis,Global workspace,Metastability,Microstates,Non-linear dynamics,Operational architectonics,Phase transitions,Self-organized criticality}, 
title = {{Brain dynamics across levels of organization}}, 
author = {Werner, Gerhard}, 
journal = {Journal of Physiology Paris}, 
issn = {09284257}, 
doi = {10.1016/j.jphysparis.2007.12.001}, 
pmid = {18267356}, 
abstract = {{After initially presenting evidence that the electrical activity recorded from the brain surface can reflect metastable state transitions of neuronal configurations at the mesoscopic level, I will suggest that their patterns may correspond to the distinctive spatio-temporal activity in the dynamic core (DC) and the global neuronal workspace (GNW), respectively, in the models of the Edelman group on the one hand, and of Dehaene-Changeux, on the other. In both cases, the recursively reentrant activity flow in intra-cortical and cortical-subcortical neuron loops plays an essential and distinct role. Reasons will be given for viewing the temporal characteristics of this activity flow as signature of self-organized criticality (SOC), notably in reference to the dynamics of neuronal avalanches. This point of view enables the use of statistical physics approaches for exploring phase transitions, scaling and universality properties of DC and GNW, with relevance to the macroscopic electrical activity in EEG and EMG. © 2008 Elsevier Ltd. All rights reserved.}}, 
pages = {273--279}, 
number = {4-6}, 
volume = {101}, 
note = {Publisher: Elsevier}
}
@book{alligood1997book, 
year = {1996}, 
title = {{Chaos: An Introduction to Dynamical Systems}}, 
author = {Alligood, Kathleen T. and Sauer, Tim D. and Yorke, James A.}, 
isbn = {978-3-540-78036-6}, 
url = {http://link.springer.com/10.1007/978-3-642-59281-2}, 
series = {Textbooks in Mathematical Sciences}, 
publisher = {Springer Berlin Heidelberg}, 
address = {Berlin, Heidelberg}, 
keywords = {}, 
doi = {10.1007/978-3-642-59281-2}
}
@article{Wildie2012Metastability, 
year = {2012}, 
title = {{Metastability and chimera states in modular delay and pulse-coupled oscillator networks}}, 
author = {Wildie, Mark and Shanahan, Murray}, 
journal = {Chaos}, 
doi = {10.1063/1.4766592}, 
pmid = {23278066}, 
url = {http://dx.doi.org/10.1063/1.4766592}, 
abstract = {{Modular networks of delay-coupled and pulse-coupled oscillators are presented, which display both transient (metastable) synchronization dynamics and the formation of a large number of "chimera" states characterized by coexistent synchronized and desynchronized subsystems. We consider networks based on both community and small-world topologies. It is shown through simulation that the metastable behaviour of the system is dependent in all cases on connection delay, and a critical region is found that maximizes indices of both metastability and the prevalence of chimera states. We show dependence of phase coherence in synchronous oscillation on the level and strength of external connectivity between communities, and demonstrate that synchronization dynamics are dependent on the modular structure of the network. The long-term behaviour of the system is considered and the relevance of the model briefly discussed with emphasis on biological and neurobiological systems. © 2012 American Institute of Physics.}}, 
pages = {43131}, 
number = {4}, 
volume = {22}, 
keywords = {}
}
@book{quyen2003disentangling, 
year = {2003}, 
keywords = {Chaos,EEG,Non-gaussian statistics,Nonlinear dynamics,Phase synchronization}, 
title = {{Disentangling the dynamic core: A research program for a neurodynamics at the large scale}}, 
author = {Quyen and Van, Michel Le}, 
url = {https://pubmed.ncbi.nlm.nih.gov/12795207/}, 
abstract = {{My purpose in this paper is to sketch a research direction based on Francisco Varela's pioneering work in neurodynamics (see also Rudrauf et al. 2003, in this issue). Very early on he argued that the internal coherence of every mental-cognitive state lies in the global self-organization of the brain activities at the large-scale, constituting a fundamental pole of integration called here a "dynamic core". Recent neuroimaging evidence appears to broadly support this hypothesis and suggests that a global brain dynamics emerges at the large scale level from the cooperative interactions among widely distributed neuronal populations. Despite a growing body of evidence supporting this view, our understanding of these large-scale brain processes remains hampered by the lack of a theoretical language for expressing these complex behaviors in dynamical terms. In this paper, I propose a rough cartography of a comprehensive approach that offers a conceptual and mathematical framework to analyze spatio-temporal large-scale brain phenomena. I emphasize how these nonlinear methods can be applied, what property might be inferred from neuronal signals, and where one might productively proceed for the future. This paper is dedicated, with respect and affection, to the memory of Francisco Varela.}}, 
volume = {36}, 
series = {Biological Research}, 
number = {1}, 
publisher = {Society of Biology of Chile}, 
note = {ISSN: 07169760 Publication Title: Biological Research}, 
doi = {10.4067/s0716-97602003000100006}
}
@article{Shanahan.2010, 
year = {2010}, 
title = {{Metastable chimera states in community-structured oscillator networks}}, 
author = {Shanahan, Murray}, 
journal = {Chaos}, 
issn = {10541500}, 
doi = {10.1063/1.3305451}, 
pmid = {20370263}, 
eprint = {0908.3881}, 
url = {http://dx.doi.org/10.1063/1.3305451}, 
abstract = {{A system of symmetrically coupled identical oscillators with phase lag is presented, which is capable of generating a large repertoire of transient (metastable) "chimera" states in which synchronization and desynchronization coexist. The oscillators are organized into communities, such that each oscillator is connected to all its peers in the same community and to a subset of the oscillators in other communities. Measures are introduced for quantifying metastability, the prevalence of chimera states, and the variety of such states a system generates. By simulation, it is shown that each of these measures is maximized when the phase lag of the model is close, but not equal, to π/2. The relevance of the model to a number of fields is briefly discussed with particular emphasis on brain dynamics. © 2010 American Institute of Physics.}}, 
pages = {13108}, 
number = {1}, 
volume = {20}, 
keywords = {}
}
@book{kuramoto1984chemical, 
year = {1984}, 
title = {{Chemical Oscillations, Waves, and Turbulence}}, 
author = {Kuramoto, Yoshiki}, 
isbn = {978-3-642-69691-6}, 
url = {http://link.springer.com/10.1007/978-3-642-69689-3}, 
volume = {19}, 
series = {Springer Series in Synergetics}, 
publisher = {Springer Berlin Heidelberg}, 
address = {Berlin, Heidelberg}, 
keywords = {}, 
doi = {10.1007/978-3-642-69689-3}
}
@article{watts1998collective, 
year = {1998}, 
title = {{Collective dynamics of 'small-world' networks}}, 
author = {Watts, D J and Strogatz, S H}, 
journal = {Nature}, 
issn = {0028-0836}, 
doi = {10.1038/30918}, 
pmid = {9623998}, 
url = {http://dx.doi.org/10.1038/30918}, 
abstract = {{Networks of coupled dynamical systems have been used to model biological oscillators, Josephson junction arrays, excitable media, neural networks, spatial games, genetic control networks and many other self-organizing systems. Ordinarily, the connection topology is assumed to be either completely regular or completely random. But many biological, technological and social networks lie somewhere between these two extremes. Here we explore simple models of networks that can be tuned through this middle ground: regular networks 'rewired' to introduce increasing amounts of disorder. We find that these systems can be highly clustered, like regular lattices, yet have small characteristic path lengths, like random graphs. We call them 'small-world' networks, by analogy with the small-world phenomenon (popularly known as six degrees of separation. The neural network of the worm Caenorhabditis elegans, the power grid of the western United States, and the collaboration graph of film actors are shown to be small-world networks. Models of dynamical systems with small-world coupling display enhanced signal-propagation speed, computational power, and synchronizability. In particular, infectious diseases spread more easily in small-world networks than in regular lattices.}}, 
pages = {440--442}, 
number = {6684}, 
volume = {393}, 
keywords = {}
}
@article{hunter2007matplotlib, 
year = {2007}, 
title = {{Matplotlib: A 2D Graphics Environment}}, 
author = {Hunter, John D}, 
journal = {Computing in science \& engineering}, 
issn = {1521-9615}, 
doi = {10.1109/mcse.2007.55}, 
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4160265}, 
abstract = {{Matplotlib is a 2D graphics package used for Python for application development, interactive scripting,and publication-quality image generation across user interfaces and operating systems}}, 
pages = {90--95}, 
number = {3}, 
volume = {9}, 
keywords = {}
}
@article{rabinovich2012information, 
year = {2012}, 
title = {{Information flow dynamics in the brain.}}, 
author = {Rabinovich, Mikhail I and Afraimovich, Valentin S and Bick, Christian and Varona, Pablo}, 
journal = {Physics of life reviews}, 
issn = {1571-0645}, 
doi = {10.1016/j.plrev.2011.11.002}, 
pmid = {22119154}, 
url = {http://dx.doi.org/10.1016/j.plrev.2011.11.002}, 
abstract = {{Timing and dynamics of information in the brain is a hot field in modern neuroscience. The analysis of the temporal evolution of brain information is crucially important for the understanding of higher cognitive mechanisms in normal and pathological states. From the perspective of information dynamics, in this review we discuss working memory capacity, language dynamics, goal-dependent behavior programming and other functions of brain activity. In contrast with the classical description of information theory, which is mostly algebraic, brain flow information dynamics deals with problems such as the stability/instability of information flows, their quality, the timing of sequential processing, the top-down cognitive control of perceptual information, and information creation. In this framework, different types of information flow instabilities correspond to different cognitive disorders. On the other hand, the robustness of cognitive activity is related to the control of the information flow stability. We discuss these problems using both experimental and theoretical approaches, and we argue that brain activity is better understood considering information flows in the phase space of the corresponding dynamical model. In particular, we show how theory helps to understand intriguing experimental results in this matter, and how recent knowledge inspires new theoretical formalisms that can be tested with modern experimental techniques. Published by Elsevier B.V.}}, 
pages = {51--73}, 
number = {1}, 
volume = {9}, 
keywords = {}
}
@article{mazzucato2019expectation, 
year = {2019}, 
title = {{Expectation-induced modulation of metastable activity underlies faster coding of sensory stimuli.}}, 
author = {Mazzucato, L and Camera, G La and Fontanini, A}, 
journal = {Nature Neuroscience}, 
issn = {1097-6256}, 
doi = {10.1038/s41593-019-0364-9}, 
pmid = {30936557}, 
pmcid = {PMC6516078}, 
url = {http://www.nature.com/articles/s41593-019-0364-9}, 
abstract = {{Sensory stimuli can be recognized more rapidly when they are expected. This phenomenon depends on expectation affecting the cortical processing of sensory information. However, the mechanisms responsible for the effects of expectation on sensory circuits remain elusive. In the present study, we report a novel computational mechanism underlying the expectation-dependent acceleration of coding observed in the gustatory cortex of alert rats. We use a recurrent spiking network model with a clustered architecture capturing essential features of cortical activity, such as its intrinsically generated metastable dynamics. Relying on network theory and computer simulations, we propose that expectation exerts its function by modulating the intrinsically generated dynamics preceding taste delivery. Our model's predictions were confirmed in the experimental data, demonstrating how the modulation of ongoing activity can shape sensory coding. Altogether, these results provide a biologically plausible theory of expectation and ascribe an alternative functional role to intrinsically generated, metastable activity.}}, 
pages = {787--796}, 
number = {5}, 
volume = {22}, 
keywords = {}
}
@article{arenas2008synchronization, 
year = {2008}, 
title = {{Synchronization in complex networks}}, 
author = {Arenas, Alex and Díaz-Guilera, Albert and Kurths, Jurgen and Moreno, Yamir and Zhou, Changsong}, 
journal = {Physics Reports}, 
doi = {10.1016/j.physrep.2008.09.002}, 
eprint = {0805.2976}, 
url = {http://linkinghub.elsevier.com/retrieve/pii/S0370157308003384}, 
abstract = {{Synchronization processes in populations of locally interacting elements are the focus of intense research in physical, biological, chemical, technological and social systems. The many efforts devoted to understanding synchronization phenomena in natural systems now take advantage of the recent theory of complex networks. In this review, we report the advances in the comprehension of synchronization phenomena when oscillating elements are constrained to interact in a complex network topology. We also take an overview of the new emergent features coming out from the interplay between the structure and the function of the underlying patterns of connections. Extensive numerical work as well as analytical approaches to the problem are presented. Finally, we review several applications of synchronization in complex networks to different disciplines: biological systems and neuroscience, engineering and computer science, and economy and social sciences.}}, 
pages = {93--153}, 
number = {3}, 
volume = {469}, 
keywords = {}
}
@article{tognoli2014metastable, 
year = {2014}, 
title = {{The Metastable Brain}}, 
author = {Tognoli, Emmanuelle and Kelso, J. A.Scott}, 
journal = {Neuron}, 
doi = {10.1016/j.neuron.2013.12.022}, 
pmid = {24411730}, 
url = {http://dx.doi.org/10.1016/j.neuron.2013.12.022}, 
abstract = {{Neural ensembles oscillate across a broad range of frequencies and are transiently coupled or "bound" together when people attend to a stimulus, perceive, think, and act. This is a dynamic, self-assembling process, with parts of the brain engaging and disengaging in time. But how is it done? The theory of Coordination Dynamics proposes a mechanism called metastability, a subtle blend of integration and segregation. Tendencies for brain regions to express their individual autonomy and specialized functions (segregation, modularity) coexist with tendencies to couple and coordinate globally for multiple functions (integration). Although metastability has garnered increasing attention, it has yet to be demonstrated and treated within a fully spatiotemporal perspective. Here, we illustrate metastability in continuous neural and behavioral recordings, and we discuss theory and experiments at multiple scales, suggesting that metastable dynamics underlie the real-time coordination necessary for the brain's dynamic cognitive, behavioral, and social functions. How does the transient coupling of neural ensembles that supports cognitive function occur? Tognoli and Kelso consider a mechanism known as metastability, discussing theory and data at multiple scales that suggest that metastable dynamics underlies the coordination necessary for the brain's dynamic functions. © 2014 Elsevier Inc.}}, 
pages = {35--48}, 
number = {1}, 
volume = {81}, 
keywords = {}
}
@article{varela2001brainweb, 
year = {2001}, 
keywords = {Fundamental,Review,Synchronization}, 
title = {{The brainweb: phase synchronization and large-scale integration.}}, 
author = {Varela, F and Lachaux, J P and Rodriguez, E and Martinerie, J}, 
journal = {Nature Reviews. Neuroscience}, 
issn = {1471-003X}, 
doi = {10.1038/35067550}, 
pmid = {11283746}, 
url = {http://dx.doi.org/10.1038/35067550}, 
abstract = {{The emergence of a unified cognitive moment relies on the coordination of scattered mosaics of functionally specialized brain regions. Here we review the mechanisms of large-scale integration that counterbalance the distributed anatomical and functional organization of brain activity to enable the emergence of coherent behaviour and cognition. Although the mechanisms involved in large-scale integration are still largely unknown, we argue that the most plausible candidate is the formation of dynamic links mediated by synchrony over multiple frequency bands.}}, 
pages = {229--239}, 
number = {4}, 
volume = {2}
}
@article{cabral2011role, 
year = {2011}, 
title = {{Role of local network oscillations in resting-state functional connectivity.}}, 
author = {Cabral, Joana and Hugues, Etienne and Sporns, Olaf and Deco, Gustavo}, 
journal = {Neuroimage}, 
issn = {1053-8119}, 
doi = {10.1016/j.neuroimage.2011.04.010}, 
pmid = {21511044}, 
url = {http://dx.doi.org/10.1016/j.neuroimage.2011.04.010}, 
abstract = {{Spatio-temporally organized low-frequency fluctuations (<0.1 Hz), observed in BOLD fMRI signal during rest, suggest the existence of underlying network dynamics that emerge spontaneously from intrinsic brain processes. Furthermore, significant correlations between distinct anatomical regions-or functional connectivity (FC)-have led to the identification of several widely distributed resting-state networks (RSNs). This slow dynamics seems to be highly structured by anatomical connectivity but the mechanism behind it and its relationship with neural activity, particularly in the gamma frequency range, remains largely unknown. Indeed, direct measurements of neuronal activity have revealed similar large-scale correlations, particularly in slow power fluctuations of local field potential gamma frequency range oscillations. To address these questions, we investigated neural dynamics in a large-scale model of the human brain's neural activity. A key ingredient of the model was a structural brain network defined by empirically derived long-range brain connectivity together with the corresponding conduction delays. A neural population, assumed to spontaneously oscillate in the gamma frequency range, was placed at each network node. When these oscillatory units are integrated in the network, they behave as weakly coupled oscillators. The time-delayed interaction between nodes is described by the Kuramoto model of phase oscillators, a biologically-based model of coupled oscillatory systems. For a realistic setting of axonal conduction speed, we show that time-delayed network interaction leads to the emergence of slow neural activity fluctuations, whose patterns correlate significantly with the empirically measured FC. The best agreement of the simulated FC with the empirically measured FC is found for a set of parameters where subsets of nodes tend to synchronize although the network is not globally synchronized. Inside such clusters, the simulated BOLD signal between nodes is found to be correlated, instantiating the empirically observed RSNs. Between clusters, patterns of positive and negative correlations are observed, as described in experimental studies. These results are found to be robust with respect to a biologically plausible range of model parameters. In conclusion, our model suggests how resting-state neural activity can originate from the interplay between the local neural dynamics and the large-scale structure of the brain. Copyright ̧opyright 2011 Elsevier Inc. All rights reserved.}}, 
pages = {130--139}, 
number = {1}, 
volume = {57}, 
keywords = {}
}
@article{hudson2014recovery, 
year = {2014}, 
title = {{Recovery of consciousness is mediated by a network of discrete metastable activity states.}}, 
author = {Hudson, Andrew E and Calderon, Diany Paola and Pfaff, Donald W and Proekt, Alex}, 
journal = {Proceedings of the National Academy of Sciences of the United States of America}, 
issn = {0027-8424}, 
doi = {10.1073/pnas.1408296111}, 
pmid = {24927558}, 
url = {http://dx.doi.org/10.1073/pnas.1408296111}, 
abstract = {{It is not clear how, after a large perturbation, the brain explores the vast space of potential neuronal activity states to recover those compatible with consciousness. Here, we analyze recovery from pharmacologically induced coma to show that neuronal activity en route to consciousness is confined to a low-dimensional subspace. In this subspace, neuronal activity forms discrete metastable states persistent on the scale of minutes. The network of transitions that links these metastable states is structured such that some states form hubs that connect groups of otherwise disconnected states. Although many paths through the network are possible, to ultimately enter the activity state compatible with consciousness, the brain must first pass through these hubs in an orderly fashion. This organization of metastable states, along with dramatic dimensionality reduction, significantly simplifies the task of sampling the parameter space to recover the state consistent with wakefulness on a physiologically relevant timescale.}}, 
pages = {9283--9288}, 
number = {25}, 
volume = {111}, 
keywords = {}
}
@article{newman1999scaling, 
year = {1999}, 
title = {{Scaling and percolation in the small-world network model.}}, 
author = {Newman, M E and Watts, D J}, 
journal = {Physical Review E}, 
issn = {1539-3755}, 
doi = {10.1103/physreve.60.7332}, 
pmid = {11970678}, 
url = {http://dx.doi.org/10.1103/physreve.60.7332}, 
abstract = {{In this paper we study the small-world network model of Watts and Strogatz, which mimics some aspects of the structure of networks of social interactions. We argue that there is one nontrivial length-scale in the model, analogous to the correlation length in other systems, which is well-defined in the limit of infinite system size and which diverges continuously as the randomness in the network tends to zero, giving a normal critical point in this limit. This length-scale governs the crossover from large- to small-world behavior in the model, as well as the number of vertices in a neighborhood of given radius on the network. We derive the value of the single critical exponent controlling behavior in the critical region and the finite size scaling form for the average vertex-vertex distance on the network, and, using series expansion and Padé approximants, find an approximate analytic form for the scaling function. We calculate the effective dimension of small-world graphs and show that this dimension varies as a function of the length-scale on which it is measured, in a manner reminiscent of multifractals. We also study the problem of site percolation on small-world networks as a simple model of disease propagation, and derive an approximate expression for the percolation probability at which a giant component of connected vertices first forms (in epidemiological terms, the point at which an epidemic occurs). The typical cluster radius satisfies the expected finite size scaling form with a cluster size exponent close to that for a random graph. All our analytic results are confirmed by extensive numerical simulations of the model.}}, 
pages = {7332--7342}, 
number = {6 Pt B}, 
volume = {60}, 
keywords = {}
}
@article{deco2017dynamics, 
year = {2017}, 
title = {{The dynamics of resting fluctuations in the brain: Metastability and its dynamical cortical core}}, 
author = {Deco, Gustavo and Kringelbach, Morten L. and Jirsa, Viktor K. and Ritter, Petra}, 
journal = {Scientific Reports}, 
doi = {10.1038/s41598-017-03073-5}, 
pmid = {28596608}, 
pmcid = {PMC5465179}, 
url = {http://dx.doi.org/10.1038/s41598-017-03073-5}, 
abstract = {{In the human brain, spontaneous activity during resting state consists of rapid transitions between functional network states over time but the underlying mechanisms are not understood. We use connectome based computational brain network modeling to reveal fundamental principles of how the human brain generates large-scale activity observable by noninvasive neuroimaging. We used structural and functional neuroimaging data to construct whole-brain models. With this novel approach, we reveal that the human brain during resting state operates at maximum metastability, i.e. in a state of maximum network switching. In addition, we investigate cortical heterogeneity across areas. Optimization of the spectral characteristics of each local brain region revealed the dynamical cortical core of the human brain, which is driving the activity of the rest of the whole brain. Brain network modelling goes beyond correlational neuroimaging analysis and reveals non-trivial network mechanisms underlying non-invasive observations. Our novel findings significantly pertain to the important role of computational connectomics in understanding principles of brain function.}}, 
pages = {3095}, 
number = {1}, 
volume = {7}, 
keywords = {}
}
@article{Boaretto.2018, 
year = {2018}, 
title = {{Neuron dynamics variability and anomalous phase synchronization of neural networks.}}, 
author = {Boaretto, B R R and Budzinski, R C and Prado, T L and Kurths, Jürgen and Lopes, S R}, 
journal = {Chaos}, 
issn = {1054-1500}, 
doi = {10.1063/1.5023878}, 
pmid = {30384616}, 
url = {http://dx.doi.org/10.1063/1.5023878}, 
abstract = {{Anomalous phase synchronization describes a synchronization phenomenon occurring even for the weakly coupled network and characterized by a non-monotonous dependence of the synchronization strength on the coupling strength. Its existence may support a theoretical framework to some neurological diseases, such as Parkinson's and some episodes of seizure behavior generated by epilepsy. Despite the success of controlling or suppressing the anomalous phase synchronization in neural networks applying external perturbations or inducing ambient changes, the origin of the anomalous phase synchronization as well as the mechanisms behind the suppression is not completely known. Here, we consider networks composed of N=2000 coupled neurons in a small-world topology for two well known neuron models, namely, the Hodgkin-Huxley-like and the Hindmarsh-Rose models, both displaying the anomalous phase synchronization regime. We show that the anomalous phase synchronization may be related to the individual behavior of the coupled neurons; particularly, we identify a strong correlation between the behavior of the inter-bursting-intervals of the neurons, what we call neuron variability, to the ability of the network to depict anomalous phase synchronization. We corroborate the ideas showing that external perturbations or ambient parameter changes that eliminate anomalous phase synchronization and at the same time promote small changes in the individual dynamics of the neurons, such that an increasing individual variability of neurons implies a decrease of anomalous phase synchronization. Finally, we demonstrate that this effect can be quantified using a well known recurrence quantifier, the "determinism." Moreover, the results obtained by the determinism are based on only the mean field potential of the network, turning these measures more suitable to be used in experimental situations.}}, 
pages = {106304}, 
number = {10}, 
volume = {28}, 
keywords = {}
}
@book{ott2002chaos, 
year = {2022}, 
title = {{Chaos in Dynamical Systems}}, 
author = {Ott, Edward}, 
isbn = {978-0-521-01084-9}, 
url = {https://books.google.com.br/books?id=\%7BnOLx\%7D–\%7BzzHSgC\%7D}, 
publisher = {Cambridge University Press}, 
address = {Cambridge, U.K}, 
keywords = {}, 
edition = {2nd Edition}
}
@article{rosenblum1996phase, 
year = {1996}, 
title = {{Phase synchronization of chaotic oscillators.}}, 
author = {Rosenblum, M G and Pikovsky, A S and Kurths, J}, 
journal = {Physical Review Letters}, 
issn = {0031-9007}, 
doi = {10.1103/physrevlett.76.1804}, 
pmid = {10060525}, 
url = {http://dx.doi.org/10.1103/\%7BPhysRevLett\%7D.76.1804}, 
abstract = {{We present the new effect of phase synchronization of weakly coupled self-sustained chaotic oscillators. To characterize this phenomenon, we use the analytic signal approach based on the Hilbert transform and partial Poincaré maps. For coupled Rössler attractors, in the synchronous regime the phases are locked, while the amplitudes vary chaotically and are practically uncorrelated. Coupling a chaotic oscillator with a hyperchaotic one, we observe another new type of synchronization, where the frequencies are entrained, while the phase difference is unbounded. A relation between the phase synchronization and the properties of the Lyapunov spectrum is studied.}}, 
pages = {1804--1807}, 
number = {11}, 
volume = {76}, 
keywords = {}
}
@article{albert2002statistical, 
year = {2002}, 
title = {{Statistical mechanics of complex networks}}, 
author = {Albert, Réka and Barabási, Albert-László}, 
journal = {Reviews of Modern Physics}, 
issn = {0034-6861}, 
doi = {10.1103/revmodphys.74.47}, 
eprint = {cond-mat/0106096}, 
url = {http://link.aps.org/doi/10.1103/\%7BRevModPhys\%7D.74.47}, 
abstract = {{Complex networks describe a wide range of systems in nature and society. Frequently cited examples include the cell, a network of chemicals linked by chemical reactions, and the Internet, a network of routers and computers connected by physical links. While traditionally these systems have been modeled as random graphs, it is increasingly recognized that the topology and evolution of real networks are governed by robust organizing principles. This article reviews the recent advances in the field of complex networks, focusing on the statistical mechanics of network topology and dynamics. After reviewing the empirical data that motivated the recent interest in networks, the authors discuss the main models and analytical tools, covering random graphs, small-world and scale-free networks, the emerging theory of evolving networks, and the interplay between topology and the network’s robustness against failures and attacks.}}, 
pages = {47--97}, 
number = {1}, 
volume = {74}, 
keywords = {}
}
@article{roberts2019metastable, 
year = {2019}, 
rating = {5}, 
title = {{Metastable brain waves.}}, 
author = {Roberts, James A and Gollo, Leonardo L and Abeysuriya, Romesh G and Roberts, Gloria and Mitchell, Philip B and Woolrich, Mark W and Breakspear, Michael}, 
journal = {Nature Communications}, 
issn = {2041-1723}, 
doi = {10.1038/s41467-019-08999-0}, 
pmid = {30837462}, 
pmcid = {PMC6401142}, 
url = {http://www.nature.com/articles/s41467-019-08999-0}, 
abstract = {{Traveling patterns of neuronal activity-brain waves-have been observed across a breadth of neuronal recordings, states of awareness, and species, but their emergence in the human brain lacks a firm understanding. Here we analyze the complex nonlinear dynamics that emerge from modeling large-scale spontaneous neural activity on a whole-brain network derived from human tractography. We find a rich array of three-dimensional wave patterns, including traveling waves, spiral waves, sources, and sinks. These patterns are metastable, such that multiple spatiotemporal wave patterns are visited in sequence. Transitions between states correspond to reconfigurations of underlying phase flows, characterized by nonlinear instabilities. These metastable dynamics accord with empirical data from multiple imaging modalities, including electrical waves in cortical tissue, sequential spatiotemporal patterns in resting-state MEG data, and large-scale waves in human electrocorticography. By moving the study of functional networks from a spatially static to an inherently dynamic (wave-like) frame, our work unifies apparently diverse phenomena across functional neuroimaging modalities and makes specific predictions for further experimentation.}}, 
pages = {1056}, 
number = {1}, 
volume = {10}, 
keywords = {}
}
@article{lee2017linking, 
year = {2017}, 
title = {{Linking functional connectivity and dynamic properties of resting-state networks}}, 
author = {Lee, Won Hee and Frangou, Sophia}, 
journal = {Scientific Reports}, 
doi = {10.1038/s41598-017-16789-1}, 
pmid = {29192157}, 
pmcid = {PMC5709368}, 
url = {http://dx.doi.org/10.1038/s41598-017-16789-1}, 
abstract = {{Spontaneous brain activity is organized into resting-state networks (RSNs) involved in internally-guided, higher-order mental functions (default mode, central executive and salience networks) and externally-driven, specialized sensory and motor processing (auditory, visual and sensorimotor networks). RSNs are characterized by their functional connectivity in terms of within-network cohesion and between-network integration, and by their dynamic properties in terms of synchrony and metastability. We examined the relationship between functional connectivity and dynamic network features using fMRI data and an anatomically constrained Kuramoto model. Extrapolating from simulated data, synchrony and metastability across the RSNs emerged at coupling strengths of 5 ≤ k ≤ 12. In the empirical RSNs, higher metastability and synchrony were respectively associated with greater cohesion and lower integration. Consistent with their dual role in supporting both sustained and diverse mental operations, higher-order RSNs had lower metastability and synchrony. Sensory and motor RSNs showed greater cohesion and metastability, likely to respectively reflect their functional specialization and their greater capacity for altering network states in response to multiple and diverse external demands. Our findings suggest that functional and dynamic RSN properties are closely linked and expand our understanding of the neural architectures that support optimal brain function.}}, 
pages = {16610}, 
number = {1}, 
volume = {7}, 
keywords = {}
}
@article{hammer1994experimental, 
year = {1994}, 
title = {{Experimental observation of on-off intermittency.}}, 
author = {Hammer, P W and Platt, N and Hammel, S M and Heagy, J F and Lee, B D}, 
journal = {Physical Review Letters}, 
issn = {0031-9007}, 
doi = {10.1103/physrevlett.73.1095}, 
pmid = {10057623}, 
url = {http://dx.doi.org/10.1103/\%7BPhysRevLett\textbackslash\%7D.73.1095}, 
abstract = {{We observe on-off intermittency in a nonlinear electronic circuit tuned near a Hopf bifurcation point. The circuit is driven randomly through the bifurcation point, resulting in intermittent switching between a fixed point (laminar phase) and a limit cycle. The distribution of lengths of laminar phases exhibits -3/2 power law scaling for shorter phases, and an exponential drop for longer phases, due to noise in the system. These results agree with a theoretically predicted distribution. In addition, the crossover from power law to exponential decay obeys the predicted scaling law.}}, 
pages = {1095--1098}, 
number = {8}, 
volume = {73}, 
keywords = {}
}
@article{graben2019metastable, 
year = {2019}, 
keywords = {BOLD fMRI,brain hierarchical atlas,diffusion tensor imaging,metastability,recurrence structure analysis,resting state}, 
title = {{Metastable Resting State Brain Dynamics}}, 
author = {Graben, Peter beim and Jimenez-Marin, Antonio and Diez, Ibai and Cortes, Jesus M. and Desroches, Mathieu and Rodrigues, Serafim}, 
journal = {Frontiers in Computational Neuroscience}, 
doi = {10.3389/fncom.2019.00062}, 
pmid = {31551744}, 
pmcid = {PMC6743347}, 
url = {http://dx.doi.org/10.3389/fncom.2019.00062}, 
abstract = {{Metastability refers to the fact that the state of a dynamical system spends a large amount of time in a restricted region of its available phase space before a transition takes place, bringing the system into another state from where it might recur into the previous one. beim Graben and Hutt (2013) suggested to use the recurrence plot (RP) technique introduced by Eckmann et al. (1987) for the segmentation of system's trajectories into metastable states using recurrence grammars. Here, we apply this recurrence structure analysis (RSA) for the first time to resting-state brain dynamics obtained from functional magnetic resonance imaging (fMRI). Brain regions are defined according to the brain hierarchical atlas (BHA) developed by Diez et al. (2015), and as a consequence, regions present high-connectivity in both structure (obtained from diffusion tensor imaging) and function (from the blood-level dependent-oxygenation—BOLD—signal). Remarkably, regions observed by Diez et al. were completely time-invariant. Here, in order to compare this static picture with the metastable systems dynamics obtained from the RSA segmentation, we determine the number of metastable states as a measure of complexity for all subjects and for region numbers varying from 3 to 100. We find RSA convergence toward an optimal segmentation of 40 metastable states for normalized BOLD signals, averaged over BHA modules. Next, we build a bistable dynamics at population level by pooling 30 subjects after Hausdorff clustering. In link with this finding, we reflect on the different modeling frameworks that can allow for such scenarios: heteroclinic dynamics, dynamics with riddled basins of attraction, multiple-timescale dynamics. Finally, we characterize the metastable states both functionally and structurally, using templates for resting state networks (RSNs) and the automated anatomical labeling (AAL) atlas, respectively.}}, 
pages = {62}, 
volume = {13}
}
@article{kelso2012multistability, 
year = {2012}, 
keywords = {Complementarity,Coordination dynamics,Instability,Metastability,Multistability,Transitions}, 
title = {{Multistability and metastability: Understanding dynamic coordination in the brain}}, 
author = {Kelso and Scott, J. A.}, 
journal = {Philosophical Transactions of the Royal Society B: Biological Sciences}, 
doi = {10.1098/rstb.2011.0351}, 
pmid = {22371613}, 
pmcid = {PMC3282307}, 
url = {http://dx.doi.org/10.1098/rstb.2011.0351}, 
abstract = {{Multistable coordination dynamics exists at many levels, from multifunctional neural circuits in vertebrates and invertebrates to large-scale neural circuitry in humans. Moreover, multistability spans (at least) the domains of action and perception, and has been found to place constraints upon, even dictating the nature of, intentional change and the skill-learning process. This paper reviews some of the key evidence for multistability in the aforementioned areas, and illustrates how it has been measured, modelled and theoretically understood. It then suggests how multistability- when combined with essential aspects of coordination dynamics such as instability, transitions and (especially) metastability-provides a platform for understanding coupling and the creative dynamics of complex goal-directed systems, including the brain and the brain-behaviour relation. © 2012 The Royal Society.}}, 
pages = {906--918}, 
number = {1591}, 
volume = {367}
}
@article{mazzucato2015dynamics, 
year = {2015}, 
keywords = {Gustatory cortex,Hidden markov models,Network dynamics,Ongoing activity,Spiking network models}, 
title = {{Dynamics of multistable states during ongoing and evoked cortical activity}}, 
author = {Mazzucato, Luca and Fontanini, Alfredo and Camera, Giancarlo La}, 
journal = {Journal of Neuroscience}, 
pmid = {26019337}, 
pmcid = {PMC4444543}, 
eprint = {1508.00165}, 
abstract = {{Single-trial analyses of ensemble activity in alert animals demonstrate that cortical circuits dynamics evolve through temporal sequences of metastable states. Metastability has been studied for its potential role in sensory coding, memory, and decision-making. Yet, very little is known about the network mechanisms responsible for its genesis. It is often assumed that the onset of state sequences is triggered by an external stimulus. Here we show that state sequences can be observed also in the absence of overt sensory stimulation. Analysis of multielectrode recordings from the gustatory cortex of alert rats revealed ongoing sequences of states, where single neurons spontaneously attain several firing rates across different states. This single-neuron multistability represents a challenge to existing spiking network models, where typically each neuron is at most bistable. We present a recurrent spiking network model that accounts for both the spontaneous generation of state sequences and the multistability in single-neuron firing rates. Each state results from the activation of neural clusters with potentiated intracluster connections, with the firing rate in each cluster depending on the number of active clusters. Simulations show that the model's ensemble activity hops among the different states, reproducing the ongoing dynamics observed in the data. When probed with external stimuli, the model predicts the quenching of single-neuron multistability into bistability and the reduction of trial-by-trial variability. Both predictions were confirmed in the data. Together, these results provide a theoretical framework that captures both ongoing and evoked network dynamics in a single mechanistic model.}}, 
pages = {8214--8231}, 
number = {21}, 
volume = {35}
}
@article{cavanna2018dynamic, 
year = {2018}, 
keywords = {Brain dynamics,Consciousness,Dynamic core,fMRI,Metastability,Neuroimaging}, 
title = {{Dynamic functional connectivity and brain metastability during altered states of consciousness}}, 
author = {Cavanna, Federico and Vilas, Martina G. and Palmucci, Matías and Tagliazucchi, Enzo}, 
journal = {NeuroImage}, 
doi = {10.1016/j.neuroimage.2017.09.065}, 
pmid = {28986208}, 
url = {http://dx.doi.org/10.1016/j.neuroimage.2017.09.065}, 
abstract = {{The scientific study of human consciousness has greatly benefited from the development of non-invasive brain imaging methods. The quest to identify the neural correlates of consciousness combined psychophysical experimentation with neuroimaging tools such as functional magnetic resonance imaging (fMRI) to map the changes in neural activity associated with conscious vs. unconscious percepts. Different neuroimaging methods have also been applied to characterize spontaneous brain activity fluctuations during altered states of consciousness, and to develop quantitative metrics for the level of consciousness. Most of these studies, however, have not explored the dynamic nature of the whole-brain imaging data provided by fMRI. A series of empirical and computational studies strongly suggests that the temporal fluctuations observed in this data present a non-trivial structure, and that this structure is compatible with the exploration of a discrete repertoire of states. In this review we focus on how dynamic neuroimaging can be used to address theoretical accounts of consciousness based on the hypothesis of a dynamic core, i.e. a constantly evolving and transiently stable set of coordinated neurons that constitute an integrated and differentiated physical substrate for each conscious experience. We review work exploring the possibility that metastability in brain dynamics leads to a repertoire of dynamic core states, and discuss how it might be modified during altered states of consciousness. This discussion prompts us to review neuroimaging studies aimed to map the dynamic exploration of the repertoire of states as a function of consciousness. Complementary studies of the dynamic core hypothesis using perturbative methods are also discussed. Finally, we propose that a link between metastability in brain dynamics and the level of consciousness could pave the way towards a mechanistic understanding of altered states of consciousness using tools from dynamical systems theory and statistical physics.}}, 
pages = {383--395}, 
number = {Pt B}, 
volume = {180}
}
@article{friston1997transients, 
year = {1997}, 
title = {{Transients, metastability, and neuronal dynamics}}, 
author = {Friston and Karl, J.}, 
journal = {NeuroImage}, 
doi = {10.1006/nimg.1997.0259}, 
pmid = {9345546}, 
url = {http://dx.doi.org/10.1006/nimg.1997.0259}, 
abstract = {{This paper is about neuronal dynamics and how their special complexity can be understood in terms of nonlinear dynamics. There are many aspects of neuronal interactions and connectivity that engender the complexity of brain dynamics. In this paper we consider (i) the nature of this complexity and (ii) how it depends on connections between neuronal systems (e.g., neuronal populations or cortical areas). The main conclusion is that simulated neural systems show complex behaviors, reminiscent of neuronal dynamics, when these extrinsic connections are sparse. The patterns of activity that obtain, under these conditions, show a rich form of intermittency with the recurrent and self-limiting expression of stereotyped transient-like dynamics. Despite the fact that these dynamics conform to a single (complex) attractor this metastability gives the illusion of a dynamically changing attractor manifold (i.e., a changing surface upon which the dynamics unfold). This metastability is characterized using a measure that is based on the entropy of the time series' spectral density.}}, 
pages = {164--171}, 
number = {2}, 
volume = {5}, 
keywords = {}
}
@article{bhowmik2013metastability, 
year = {2013}, 
title = {{Metastability and Inter-Band Frequency Modulation in Networks of Oscillating Spiking Neuron Populations}}, 
author = {Bhowmik, David and Shanahan, Murray}, 
journal = {PLoS ONE}, 
doi = {10.1371/journal.pone.0062234}, 
pmid = {23614040}, 
pmcid = {PMC3628585}, 
url = {http://dx.doi.org/10.1371/journal.pone.0062234}, 
abstract = {{Groups of neurons firing synchronously are hypothesized to underlie many cognitive functions such as attention, associative learning, memory, and sensory selection. Recent theories suggest that transient periods of synchronization and desynchronization provide a mechanism for dynamically integrating and forming coalitions of functionally related neural areas, and that at these times conditions are optimal for information transfer. Oscillating neural populations display a great amount of spectral complexity, with several rhythms temporally coexisting in different structures and interacting with each other. This paper explores inter-band frequency modulation between neural oscillators using models of quadratic integrate-and-fire neurons and Hodgkin-Huxley neurons. We vary the structural connectivity in a network of neural oscillators, assess the spectral complexity, and correlate the inter-band frequency modulation. We contrast this correlation against measures of metastable coalition entropy and synchrony. Our results show that oscillations in different neural populations modulate each other so as to change frequency, and that the interaction of these fluctuating frequencies in the network as a whole is able to drive different neural populations towards episodes of synchrony. Further to this, we locate an area in the connectivity space in which the system directs itself in this way so as to explore a large repertoire of synchronous coalitions. We suggest that such dynamics facilitate versatile exploration, integration, and communication between functionally related neural areas, and thereby supports sophisticated cognitive processing in the brain. © 2013 Bhowmik, Shanahan.}}, 
pages = {e62234}, 
number = {4}, 
volume = {8}, 
keywords = {}
}
@article{Hansen.2015, 
year = {2015}, 
title = {{Functional connectivity dynamics: modeling the switching behavior of the resting state.}}, 
author = {Hansen, Enrique C A and Battaglia, Demian and Spiegler, Andreas and Deco, Gustavo and Jirsa, Viktor K}, 
journal = {Neuroimage}, 
issn = {1053-8119}, 
doi = {10.1016/j.neuroimage.2014.11.001}, 
pmid = {25462790}, 
url = {http://dx.doi.org/10.1016/j.neuroimage.2014.11.001}, 
abstract = {{Functional connectivity (FC) sheds light on the interactions between different brain regions. Besides basic research, it is clinically relevant for applications in Alzheimer's disease, schizophrenia, presurgical planning, epilepsy, and traumatic brain injury. Simulations of whole-brain mean-field computational models with realistic connectivity determined by tractography studies enable us to reproduce with accuracy aspects of average FC in the resting state. Most computational studies, however, did not address the prominent non-stationarity in resting state FC, which may result in large intra- and inter-subject variability and thus preclude an accurate individual predictability. Here we show that this non-stationarity reveals a rich structure, characterized by rapid transitions switching between a few discrete FC states. We also show that computational models optimized to fit time-averaged FC do not reproduce these spontaneous state transitions and, thus, are not qualitatively superior to simplified linear stochastic models, which account for the effects of structure alone. We then demonstrate that a slight enhancement of the non-linearity of the network nodes is sufficient to broaden the repertoire of possible network behaviors, leading to modes of fluctuations, reminiscent of some of the most frequently observed Resting State Networks. Because of the noise-driven exploration of this repertoire, the dynamics of FC qualitatively change now and display non-stationary switching similar to empirical resting state recordings (Functional Connectivity Dynamics (FCD)). Thus FCD bear promise to serve as a better biomarker of resting state neural activity and of its pathologic alterations. Copyright ̧opyright 2014 The Authors. Published by Elsevier Inc. All rights reserved.}}, 
pages = {525--535}, 
volume = {105}, 
keywords = {}
}
@incollection{fox2015bursting, 
year = {2015}, 
title = {{Bursting in neurons and small networks}}, 
author = {Fox, David M and Rotstein, Horacio G and Nadim, Farzan}, 
editor = {Jaeger, Dieter and Jung, Ranu}, 
booktitle = {Encyclopedia of computational neuroscience}, 
isbn = {978-1-4614-6674-1}, 
pages = {455--469}, 
publisher = {Springer New York}, 
address = {New York, NY}, 
keywords = {}, 
doi = {10.1007/978-1-4614-6675-8\_454}
}
@article{bezanson2017julia, 
year = {2017}, 
title = {{Julia: A fresh approach to numerical computing}}, 
author = {Bezanson, Jeff and Edelman, Alan and Karpinski, Stefan and Shah, Viral B}, 
journal = {SIAM Review}, 
issn = {0036-1445}, 
doi = {10.1137/141000671}, 
url = {http://epubs.siam.org/doi/10.1137/141000671}, 
abstract = {{The Julia programming language is gaining enormous popularity. Julia was designed to be easy and fast. Most importantly, Julia shatters deeply established notions widely held in the applied community: 1. High-level, dynamic code has to be slow by some sort of law of nature 2. It is sensible to prototype in one language and then recode in another language 3. There are parts of a system for the programmer, and other parts best left untouched as they are built by the experts. Julia began with a deep understanding of the needs of the scientic programmer and the needs of the computer in mind. Bridging cultures that have often been distant, Julia combines expertise from computer science and computational science creating a new approach to scientic computing. This note introduces the programmer to the language and the underlying design theory. It invites the reader to rethink the fundamental foundations of numerical computing systems. In particular, there is the fascinating dance between specialization and abstraction. Specialization allows for custom treatment. We can pick just the right algorithm for the right circumstance and this can happen at runtime based on argument types (code selection via multiple dispatch). Abstraction recognizes what remains the same after dierences are stripped away and ignored as irrelevant. The recognition of abstraction allows for code reuse (generic programming). A simple idea that yields incredible power. The Julia design facilitates this interplay in many explicit and subtle ways for machine performance and, most importantly, human convenience.}}, 
pages = {65--98}, 
number = {1}, 
volume = {59}, 
keywords = {}
}
@article{lacamera2019cortical, 
year = {2019}, 
rating = {5}, 
title = {{Cortical computations via metastable activity}}, 
author = {Camera, Giancarlo La and Fontanini, Alfredo and Mazzucato, Luca}, 
journal = {Current Opinion in Neurobiology}, 
doi = {10.1016/j.conb.2019.06.007}, 
pmid = {31326722}, 
url = {http://dx.doi.org/10.1016/j.conb.2019.06.007}, 
abstract = {{Metastable brain dynamics are characterized by abrupt, jump-like modulations so that the neural activity in single trials appears to unfold as a sequence of discrete, quasi-stationary ‘states'. Evidence that cortical neural activity unfolds as a sequence of metastable states is accumulating at fast pace. Metastable activity occurs both in response to an external stimulus and during ongoing, self-generated activity. These spontaneous metastable states are increasingly found to subserve internal representations that are not locked to external triggers, including states of deliberations, attention and expectation. Moreover, decoding stimuli or decisions via metastable states can be carried out trial-by-trial. Focusing on metastability will allow us to shift our perspective on neural coding from traditional concepts based on trial-averaging to models based on dynamic ensemble representations. Recent theoretical work has started to characterize the mechanistic origin and potential roles of metastable representations. In this article we review recent findings on metastable activity, how it may arise in biologically realistic models, and its potential role for representing internal states as well as relevant task variables.}}, 
pages = {37--45}, 
volume = {58}, 
keywords = {}
}
@article{Fries.2005, 
year = {2005}, 
title = {{A mechanism for cognitive dynamics: neuronal communication through neuronal coherence.}}, 
author = {Fries, Pascal}, 
journal = {Trends in Cognitive Sciences}, 
issn = {1364-6613}, 
doi = {10.1016/j.tics.2005.08.011}, 
pmid = {16150631}, 
url = {http://dx.doi.org/10.1016/j.tics.2005.08.011}, 
abstract = {{At any one moment, many neuronal groups in our brain are active. Microelectrode recordings have characterized the activation of single neurons and fMRI has unveiled brain-wide activation patterns. Now it is time to understand how the many active neuronal groups interact with each other and how their communication is flexibly modulated to bring about our cognitive dynamics. I hypothesize that neuronal communication is mechanistically subserved by neuronal coherence. Activated neuronal groups oscillate and thereby undergo rhythmic excitability fluctuations that produce temporal windows for communication. Only coherently oscillating neuronal groups can interact effectively, because their communication windows for input and for output are open at the same times. Thus, a flexible pattern of coherence defines a flexible communication structure, which subserves our cognitive flexibility.}}, 
pages = {474--480}, 
number = {10}, 
volume = {9}, 
keywords = {}
}
@article{bressler2016coordination, 
year = {2016}, 
title = {{Coordination dynamics in cognitive neuroscience.}}, 
author = {Bressler, Steven L and Kelso, J A Scott}, 
journal = {Frontiers in Neuroscience}, 
issn = {1662-4548}, 
doi = {10.3389/fnins.2016.00397}, 
pmid = {27695395}, 
pmcid = {PMC5023665}, 
url = {http://dx.doi.org/10.3389/fnins.2016.00397}, 
abstract = {{Many researchers and clinicians in cognitive neuroscience hold to a modular view of cognitive function in which the cerebral cortex operates by the activation of areas with circumscribed elementary cognitive functions. Yet an ongoing paradigm shift to a dynamic network perspective is underway. This new viewpoint treats cortical function as arising from the coordination dynamics within and between cortical regions. Cortical coordination dynamics arises due to the unidirectional influences imposed on a cortical area by inputs from other areas that project to it, combined with the projection reciprocity that characterizes cortical connectivity and gives rise to reentrant processing. As a result, cortical dynamics exhibits both segregative and integrative tendencies and gives rise to both cooperative and competitive relations within and between cortical areas that are hypothesized to underlie the emergence of cognition in brains.}}, 
pages = {397}, 
volume = {10}, 
keywords = {}
}
@article{singer1999neuronal, 
year = {1999}, 
title = {{Neuronal synchrony: a versatile code for the definition of relations?}}, 
author = {Singer, W}, 
journal = {Neuron}, 
issn = {0896-6273}, 
doi = {10.1016/s0896-6273(00)80821-1}, 
pmid = {10677026}, 
url = {http://dx.doi.org/10.1016/s0896-6273(00)80821-1}, 
pages = {49--65,111}, 
number = {1}, 
volume = {24}, 
keywords = {}
}
@book{glendinning, 
year = {1994}, 
title = {{Stability, Instability And Chaos: An Introduction To The Theory Of Nonlinear Differential Equations (cambridge Texts In Applied Mathematics)}}, 
author = {Glendinning, Paul}, 
isbn = {978-0-521-42566-7}, 
abstract = {{By providing an introduction to nonlinear differential equations, Dr. Glendinning aims to equip the student with the mathematical know-how needed to appreciate stability theory and bifurcations. His approach is readable and covers material both old and new to undergraduate courses. Included are treatments of the Poincaré-Bendixson theorem, the Hopf bifurcation and chaotic systems.}}, 
series = {Cambridge Texts in Applied Mathematics}, 
publisher = {Cambridge University Press}, 
address = {Cambridge [England]}, 
keywords = {}, 
edition = {1}
}
@article{swadlow2001impact, 
year = {2001}, 
title = {{The impact of 'bursting' thalamic impulses at a neocortical synapse.}}, 
author = {Swadlow, H A and Gusev, A G}, 
journal = {Nature Neuroscience}, 
issn = {1097-6256}, 
doi = {10.1038/86054}, 
pmid = {11276231}, 
url = {http://dx.doi.org/10.1038/86054}, 
abstract = {{Considerable effort has gone into understanding the mechanisms underlying high-frequency 'bursting' of thalamocortical impulses, their sensory information content and their involvement in perception. However, little is known about the influence of such impulses on their cortical targets. Here we follow bursting thalamic impulses to their terminus at the thalamocortical synapse of the awake rabbit, and examine their influence on a class of somatosensory cortical neurons. We show that thalamic bursts potently activate cortical circuits. Initial impulses of each burst have a greatly enhanced ability to elicit cortical action potentials, and later impulses in the burst further raise the probability of eliciting spikes. In some cases, multiple cortical spikes result from a single burst. Moreover, we show that the interval preceding each burst is crucial for generating the enhanced cortical response. The powerful activation of neocortex by thalamocortical bursts is fully consistent with an involvement of these impulses in perceptual/attentional processes.}}, 
pages = {402--408}, 
number = {4}, 
volume = {4}, 
keywords = {}
}
@article{Hindmarsh.1984, 
year = {1984}, 
title = {{A model of neuronal bursting using three coupled first order differential equations}}, 
author = {Hindmarsh, J L and Rose, R M}, 
journal = {Proceedings of the royal society of London B: biological sciences}, 
pages = {87--102}, 
number = {1222}, 
volume = {221}, 
keywords = {}
}
@article{jirsa1994theoretical, 
year = {1994}, 
title = {{A theoretical model of phase transitions in the human brain.}}, 
author = {Jirsa, V K and Friedrich, R and Haken, H and Kelso, J A}, 
journal = {Biological Cybernetics}, 
issn = {0340-1200}, 
doi = {10.1007/bf00198909}, 
pmid = {8054384}, 
url = {http://dx.doi.org/10.1007/\%7BBF00198909\textbackslash\%7D}, 
abstract = {{An experiment using a multisensor SQUID (superconducting quantum interference device) array was performed by Kelso and colleagues (1992) which combined information from three different sources: perception, motor response, and brain signals. When an acoustic stimulus frequency is changed systematically, a spontaneous transition in coordination occurs at a critical frequency in both motor behavior and brain signals. Qualitatively analogous transitions are known for physical and biological systems such as changes in the coordination of human hand movements (Kelso 1981, 1984). In this paper we develop a theoretical model based on methods from the interdisciplinary field of synergetics (Haken 1983, 1987) and nonlinear oscillator theory that reproduces the main experimental features very well and suggests a formulation of a fundamental biophysical coupling.}}, 
pages = {27--35}, 
number = {1}, 
volume = {71}, 
keywords = {}
}
@article{aguilera2016extended, 
year = {2016}, 
keywords = {Criticality,Embodied cognition,Evolutionary robotics,Metastability,Neural assemblies,Sensorimotor coupling,Synaptic plasticity}, 
title = {{Extended neural metastability in an embodied model of sensorimotor coupling}}, 
author = {Aguilera, Miguel and Bedia, Manuel G. and Barandiaran, Xabier E.}, 
journal = {Frontiers in Systems Neuroscience}, 
doi = {10.3389/fnsys.2016.00076}, 
pmid = {27721746}, 
pmcid = {PMC5033977}, 
url = {http://dx.doi.org/10.3389/fnsys.2016.00076}, 
abstract = {{The hypothesis that brain organization is based on mechanisms of metastable synchronization in neural assemblies has been popularized during the last decades of neuroscientific research. Nevertheless, the role of body and environment for understanding the functioning of metastable assemblies is frequently dismissed. The main goal of this paper is to investigate the contribution of sensorimotor coupling to neural and behavioral metastability using a minimal computational model of plastic neural ensembles embedded in a robotic agent in a behavioral preference task. Our hypothesis is that, under some conditions, the metastability of the system is not restricted to the brain but extends to the system composed by the interaction of brain, body and environment. We test this idea, comparing an agent in continuous interaction with its environment in a task demanding behavioral flexibility with an equivalent model from the point of view of “internalist neuroscience.” A statistical characterization of our model and tools from information theory allow us to show how (1) the bidirectional coupling between agent and environment brings the system closer to a regime of criticality and triggers the emergence of additional metastable states which are not found in the brain in isolation but extended to the whole system of sensorimotor interaction, (2) the synaptic plasticity of the agent is fundamental to sustain open structures in the neural controller of the agent flexibly engaging and disengaging different behavioral patterns that sustain sensorimotor metastable states, and (3) these extended metastable states emerge when the agent generates an asymmetrical circular loop of causal interaction with its environment, in which the agent responds to variability of the environment at fast timescales while acting over the environment at slow timescales, suggesting the constitution of the agent as an autonomous entity actively modulating its sensorimotor coupling with the world. We conclude with a reflection about how our results contribute in a more general way to current progress in neuroscientific research.}}, 
pages = {76}, 
number = {SEP}, 
volume = {10}
}
@article{fries2015rhythms, 
year = {2015}, 
keywords = {Phase synchronization}, 
title = {{Rhythms for Cognition: Communication through Coherence.}}, 
author = {Fries, Pascal}, 
journal = {Neuron}, 
doi = {10.1016/j.neuron.2015.09.034}, 
pmid = {26447583}, 
pmcid = {PMC4605134}, 
url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627315008235}, 
abstract = {{I propose that synchronization affects communication between neuronal groups. Gamma-band (30-90 Hz) synchronization modulates excitation rapidly enough that it escapes the following inhibition and activates postsynaptic neurons effectively. Synchronization also ensures that a presynaptic activation pattern arrives at postsynaptic neurons in a temporally coordinated manner. At a postsynaptic neuron, multiple presynaptic groups converge, e.g., representing different stimuli. If a stimulus is selected by attention, its neuronal representation shows stronger and higher-frequency gamma-band synchronization. Thereby, the attended stimulus representation selectively entrains postsynaptic neurons. The entrainment creates sequences of short excitation and longer inhibition that are coordinated between pre- and postsynaptic groups to transmit the attended representation and shut out competing inputs. The predominantly bottom-up-directed gamma-band influences are controlled by predominantly top-down-directed alpha-beta-band (8-20 Hz) influences. Attention itself samples stimuli at a 7-8 Hz theta rhythm. Thus, several rhythms and their interplay render neuronal communication effective, precise, and selective. Copyright ̧opyright 2015 Elsevier Inc. All rights reserved.}}, 
pages = {220--235}, 
number = {1}, 
volume = {88}
}
@article{werner2007metastability, 
year = {2007}, 
keywords = {Coordination dynamics,Dynamic core hypothesis,Global workspace,Metastability,Nonlinear dynamics,Phase transitions,Self-organized criticality}, 
title = {{Metastability, criticality and phase transitions in brain and its models}}, 
author = {Werner, Gerhard}, 
journal = {BioSystems}, 
doi = {10.1016/j.biosystems.2006.12.001}, 
pmid = {17316974}, 
url = {http://dx.doi.org/10.1016/j.biosystems.2006.12.001}, 
abstract = {{This survey of experimental findings and theoretical insights of the past 25 years places the brain firmly into the conceptual framework of nonlinear dynamics, operating at the brink of criticality, which is achieved and maintained by self-organization. It is here the basis for proposing that the application of the twin concepts of scaling and universality of the theory of non-equilibrium phase transitions can serve as an informative approach for elucidating the nature of underlying neural-mechanisms, with emphasis on the dynamics of recursively reentrant activity flow in intracortical and cortico-subcortical neuronal loops. © 2006 Elsevier Ireland Ltd. All rights reserved.}}, 
pages = {496--508}, 
number = {2}, 
volume = {90}
}
@article{hudson2017metastability, 
year = {2017}, 
keywords = {Attractor dynamics,Attractor networks,Isoflurane,Metastability,Rats,Sprague-Dawley}, 
title = {{Metastability of neuronal dynamics during general anesthesia: Time for a change in our assumptions?}}, 
author = {Hudson and Andrew, E.}, 
journal = {Frontiers in Neural Circuits}, 
doi = {10.3389/fncir.2017.00058}, 
pmid = {28890688}, 
pmcid = {PMC5574877}, 
url = {http://dx.doi.org/10.3389/fncir.2017.00058}, 
abstract = {{There is strong evidence that anesthetics have stereotypical effects on brain state, so that a given anesthetic appears to have a signature in the electroencephalogram (EEG), which may vary with dose. This can be usefully interpreted as the anesthetic determining an attractor in the phase space of the brain. How brain activity shifts between these attractors in time remains understudied, as most studies implicitly assume a one-to-one relationship between drug dose and attractor features by assuming stationarity over the analysis interval and analyzing data segments of several minutes in length. Yet data in rats anesthetized with isoflurane suggests that, at anesthetic levels consistent with surgical anesthesia, brain activity alternates between multiple attractors, often spending on the order of 10 min in one activity pattern before shifting to another. Moreover, the probability of these jumps between attractors changes with anesthetic concentration. This suggests the hypothesis that brain state is metastable during anesthesia: though it appears at equilibrium on short timescales (on the order of seconds to a few minutes), longer intervals show shifting behavior. Compelling evidence for metastability in rats anesthetized with isoflurane is reviewed, but so far only suggestive hints of metastability in brain states exist with other anesthetics or in other species. Explicit testing of metastability during anesthesia will require experiments with longer acquisition intervals and carefully designed analytic approaches; some of the implications of these constraints are reviewed for typical spectral analysis approaches. If metastability exists during anesthesia, it implies degeneracy in the relationship between brain state and effect site concentration, as there is not a one-to-one mapping between the two. This degeneracy could explain some of the reported difficulty in using brain activity monitors to titrate drug dose to prevent awareness during anesthesia and should force a rethinking of the notion of depth of anesthesia as a single dimension. Finally, explicit incorporation of knowledge of the dynamics of the brain during anesthesia could offer better depth of anesthesia monitoring.}}, 
pages = {58}, 
volume = {11}
}
@article{Friston.2000, 
year = {2000}, 
title = {{The labile brain. I. Neuronal transients and nonlinear coupling.}}, 
author = {Friston, K J}, 
journal = {Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences}, 
issn = {0962-8436}, 
doi = {10.1098/rstb.2000.0560}, 
pmid = {10724457}, 
pmcid = {PMC1692735}, 
url = {http://dx.doi.org/10.1098/rstb.2000.0560}, 
abstract = {{In this, the first of three papers, the nature of, and motivation for, neuronal transients is described in relation to characterizing brain dynamics. This paper deals with some basic aspects of neuronal dynamics, interactions, coupling and implicit neuronal codes. The second paper develops neuronal transients and nonlinear coupling in the context of dynamic instability and complexity, and suggests that instability or lability is necessary for adaptive self-organization. The final paper addresses the role of neuronal transients through information theory and the emergence of spatio-temporal receptive fields and functional specialization. By considering the brain as an ensemble of connected dynamic systems one can show that a sufficient description of neuronal dynamics comprises neuronal activity at a particular time and its recent history This history constitutes a neuronal transient. As such, transients represent a fundamental metric of neuronal interactions and, implicitly, a code employed in the functional integration of brain systems. The nature of transients, expressed conjointly in distinct neuronal populations, reflects the underlying coupling among populations. This coupling may be synchronous (and possibly oscillatory) or asynchronous. A critical distinction between synchronous and asynchronous coupling is that the former is essentially linear and the latter is nonlinear. The nonlinear nature of asynchronous coupling enables the rich, context-sensitive interactions that characterize real brain dynamics, suggesting that it plays a role in functional integration that may be as important as synchronous interactions. The distinction between linear and nonlinear coupling has fundamental implications for the analysis and characterization of neuronal interactions, most of which are predicated on linear (synchronous) coupling (e.g. cross-correlograms and coherence). Using neuromagnetic data it is shown that nonlinear (asynchronous) coupling is, in fact, more abundant and can be more significant than synchronous coupling.}}, 
pages = {215--236}, 
number = {1394}, 
volume = {355}, 
keywords = {}
}
@article{deco2016metastability, 
year = {2016}, 
keywords = {Communication through coherence,Metastability,Synchronisation,Whole-brain-modelling}, 
title = {{Metastability and Coherence: Extending the Communication through Coherence Hypothesis Using A Whole-Brain Computational Perspective}}, 
author = {Deco, Gustavo and Kringelbach, Morten L.}, 
journal = {Trends in Neurosciences}, 
doi = {10.1016/j.tins.2016.01.001}, 
pmid = {26833259}, 
url = {http://dx.doi.org/10.1016/j.tins.2016.01.001}, 
abstract = {{Understanding the mechanisms for communication in the brain remains one of the most challenging scientific questions. The communication through coherence (CTC) hypothesis was originally proposed 10 years ago, stating that two groups of neurons communicate most effectively when their excitability fluctuations are coordinated in time (i.e., coherent), and this control by cortical coherence is a fundamental brain mechanism for large-scale, distant communication. In light of new evidence from whole-brain computational modelling of multimodal neuroimaging data, we link CTC to the concept of metastability, which refers to a rich exploration of the functional repertoire made possible by the underlying structural whole-brain connectivity.}}, 
pages = {125--135}, 
number = {3}, 
volume = {39}
}
@article{rubinov2015wiring, 
year = {2015}, 
title = {{Wiring cost and topological participation of the mouse brain connectome.}}, 
author = {Rubinov, Mikail and Ypma, Rolf J F and Watson, Charles and Bullmore, Edward T}, 
journal = {Proceedings of the National Academy of Sciences of the United States of America}, 
issn = {0027-8424}, 
doi = {10.1073/pnas.1420315112}, 
pmid = {26216962}, 
pmcid = {PMC4538676}, 
url = {http://dx.doi.org/10.1073/pnas.1420315112}, 
abstract = {{Brain connectomes are topologically complex systems, anatomically embedded in 3D space. Anatomical conservation of "wiring cost" explains many but not all aspects of these networks. Here, we examined the relationship between topology and wiring cost in the mouse connectome by using data from 461 systematically acquired anterograde-tracer injections into the right cortical and subcortical regions of the mouse brain. We estimated brain-wide weights, distances, and wiring costs of axonal projections and performed a multiscale topological and spatial analysis of the resulting weighted and directed mouse brain connectome. Our analysis showed that the mouse connectome has small-world properties, a hierarchical modular structure, and greater-than-minimal wiring costs. High-participation hubs of this connectome mediated communication between functionally specialized and anatomically localized modules, had especially high wiring costs, and closely corresponded to regions of the default mode network. Analyses of independently acquired histological and gene-expression data showed that nodal participation colocalized with low neuronal density and high expression of genes enriched for cognition, learning and memory, and behavior. The mouse connectome contains high-participation hubs, which are not explained by wiring-cost minimization but instead reflect competitive selection pressures for integrated network topology as a basis for higher cognitive and behavioral functions.}}, 
pages = {10032--10037}, 
number = {32}, 
volume = {112}, 
keywords = {}
}
@article{friston2000transients, 
year = {2000}, 
title = {{The labile brain. II. Transients, complexity and selection.}}, 
author = {Friston, K J}, 
journal = {Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences}, 
issn = {0962-8436}, 
doi = {10.1098/rstb.2000.0561}, 
pmid = {10724458}, 
pmcid = {PMC1692732}, 
url = {http://dx.doi.org/10.1098/rstb.2000.0561}, 
abstract = {{The successive expression of neuronal transients is related to dynamic correlations and, as shown in this paper, to dynamic instability. Dynamic instability is a form of complexity, typical of neuronal systems, which may be crucial for adaptive brain function from two perspectives. The first is from the point of view of neuronal selection and self-organizing systems: if selective mechanisms underpin the emergence of adaptive neuronal responses then dynamic instability is, itself, necessarily adaptive. This is because dynamic instability is the source of diversity on which selection acts and is therefore subject to selective pressure. In short, the emergence of order, through selection, depends almost paradoxically on the instabilities that characterize the diversity of brain dynamics. The second perspective is provided by information theory.}}, 
pages = {237--252}, 
number = {1394}, 
volume = {355}, 
keywords = {}
}
@book{Gerstner.2002, 
year = {2002}, 
title = {{Spiking neuron models: single neurons, populations, plasticity}}, 
author = {Gerstner, Wulfram and Kistler, Werner M}, 
isbn = {978-0-511-81570-6}, 
url = {https://www.cambridge.org/core/product/identifier/9780511815706/type/book}, 
publisher = {Cambridge University Press}, 
keywords = {}, 
doi = {10.1017/cbo9780511815706}
}
@article{fingelkurts2006timing, 
year = {2006}, 
title = {{Timing in cognition and EEG brain dynamics: discreteness versus continuity.}}, 
author = {Fingelkurts, Andrew A and Fingelkurts, Alexander A}, 
journal = {Cognitive Processing}, 
issn = {1612-4782}, 
doi = {10.1007/s10339-006-0035-0}, 
pmid = {16832687}, 
url = {http://dx.doi.org/10.1007/s10339-006-0035-0}, 
abstract = {{This article provides an overview of recent developments in solving the timing problem (discreteness vs. continuity) in cognitive neuroscience. Both theoretical and empirical studies have been considered, with an emphasis on the framework of operational architectonics (OA) of brain functioning (Fingelkurts and Fingelkurts in Brain Mind 2:291-29, 2001; Neurosci Biobehav Rev 28:827-836, 2005). This framework explores the temporal structure of information flow and interarea interactions within the network of functional neuronal populations by examining topographic sharp transition processes in the scalp EEG, on the millisecond scale. We conclude, based on the OA framework, that brain functioning is best conceptualized in terms of continuity-discreteness unity which is also the characteristic property of cognition. At the end we emphasize where one might productively proceed for the future research.}}, 
pages = {135--162}, 
number = {3}, 
volume = {7}, 
keywords = {}
}
@book{izhikevichbook, 
year = {2007}, 
title = {{Dynamical systems in neuroscience}}, 
author = {Izhikevich, Eugene M}, 
publisher = {MIT press}, 
keywords = {}
}
@article{naik2017metastability, 
year = {2017}, 
title = {{Metastability in Senescence}}, 
author = {Naik, Shruti and Banerjee, Arpan and Bapi, Raju S. and Deco, Gustavo and Roy, Dipanjan}, 
journal = {Trends in Cognitive Sciences}, 
issn = {1364-6613}, 
doi = {10.1016/j.tics.2017.04.007}, 
pmid = {28499740}, 
url = {https://www.sciencedirect.com/science/article/abs/pii/S1364661317300797}, 
abstract = {{The brain during healthy aging exhibits gradual deterioration of structure but maintains a high level of cognitive ability. These structural changes a…}}, 
pages = {509--521}, 
number = {7}, 
volume = {21}, 
language = {en}, 
note = {Publisher: Elsevier Current Trends}, 
keywords = {}
}
@incollection{bovier2009metastability, 
year = {2009}, 
keywords = {Dirichlet Problem,Invariant Measure,Markov Chain,Markov Process,Small Eigenvalue}, 
title = {{Metastability}}, 
author = {Bovier, Anton}, 
editor = {\{\textbackslash\{Bovier, ["[\textbackslashtextbackslash"Biskup and\} and \{\textbackslashtextbackslash\textbackslashtextbackslash\textbackslash\{Hollander, Marek and\textbackslash\} and\} and \{\textbackslashtextbackslash\textbackslashtextbackslash\textbackslash\{Ioffe, Anton and den\textbackslashtextbackslash\textbackslashtextbackslash\textbackslash\} and\} and \{\textbackslashtextbackslash\textbackslashtextbackslash\textbackslash\{Martinelli, Frank and\textbackslashtextbackslash\textbackslashtextbackslash\textbackslash\} and\} and \{\textbackslashtextbackslash\textbackslashtextbackslash\textbackslash\{Netočný, Dima and\textbackslashtextbackslash\textbackslashtextbackslash\textbackslash\} and\} and \{\textbackslashtextbackslash\textbackslashtextbackslash\textbackslash\{Toninelli, Fabio and\textbackslashtextbackslash\textbackslashtextbackslash\textbackslash\} and\} and \{\textbackslashtextbackslash\textbackslashtextbackslash\textbackslash\{Kotecký, Karel and\textbackslashtextbackslash\textbackslashtextbackslash\textbackslash\} and\} and \{Roman\textbackslashtextbackslash"]"], Fabio and\textbackslashtextbackslash\textbackslashtextbackslash\textbackslash\} and\}}, 
booktitle = {Methods of Contemporary Mathematical Statistical Physics}, 
isbn = {978-3-540-92796-9}, 
url = {https://doi.org/10.1007/978-3-540-92796-9\_4}, 
abstract = {{In these lectures we will discuss Markov processes with a particular interest for a phenomenon called metastability. Basically this refers to the existence of two or more time-scales over which the system shows very different behaviour: on the short time scale, the systems reaches quickly a “pseudo-equilibrium” and remains effectively in a restricted subset of the available phase space; the particular pseudo-equilibrium that is reached will depend on the initial conditions. However, when observed on the longer time scale, one will occasionally observe transitions from one such pseudo-equilibrium to another one. In many cases (as we will see) there exists one particular time scale for each such pseudo-equilibrium; in other cases of interest, several, or even many, such distinct pseudo-equilibria exist having the same time scale of exit. Mathematically speaking, our interest is to derive the (statistical) properties of the process on these long time scales from the given description of the process on the microscopic time scale. In principle, our aim should be an effective model for the motion at the long time scale on a coarse grained state space; in fact, disregarding fast motion leads us naturally to consider a reduced state space that may be labeled in some way by the quasi-equilibria.The type of situation we sketched above occurs in many situations in nature. The classical example is of course the phenomenon of metastability in phase transitions: if a (sufficiently pure) container of water is cooled below freezing temperature, it may remain in the liquid state for a rather long period of time, but at some moment the entire container freezes extremely rapidly. In reality, this moment is of course mostly triggered by some slight external perturbation. Another example of the same phenomenon occurs in the dynamics of large bio-molecules, such as proteins. Such molecules frequently have several possible spatial conformations, transitions between which occur sporadically on often very long time scales. Another classical example is metastability in chemical reactions. Here reactants oscillate between several possible chemical compositions, sometimes nicely distinguished by different colours. This example was instrumental in the development of stochastic models for metastability by Eyring, Kramers and others [21, 30]. Today, metastable effects are invoked to explain a variety of diverse phenomena such as changes in global climate systems both on earth (ice-ages) and on Mars (liquid water presence), structural transitions on eco- and oeco systems, to name just a few examples.}}, 
urldate = {2021-05-19}, 
pages = {177--221}, 
series = {Lecture Notes in Mathematics}, 
publisher = {Springer}, 
address = {Berlin, Heidelberg}, 
language = {en}, 
doi = {10.1007/978-3-540-92796-9\_4}
}
@article{Kahana.2006, 
year = {2006}, 
keywords = {Brain,Cognition,Electroencephalography,Humans,Magnetoencephalography,Oscillometry,Space Perception,Speech}, 
title = {{The cognitive correlates of human brain oscillations}}, 
author = {Kahana and Michael, J.}, 
journal = {The Journal of Neuroscience: The Official Journal of the Society for Neuroscience}, 
issn = {1529-2401}, 
doi = {10.1523/jneurosci.3737-05c.2006}, 
pmid = {16467513}, 
pmcid = {PMC6793637}, 
pages = {1669--1672}, 
number = {6}, 
volume = {26}, 
language = {eng}
}
@misc{Kelso.1995, 
year = {1995}, 
author = {Kelso, Scott}, 
title = {{Dynamic Patterns | The MIT Press}}, 
url = {https://mitpress.mit.edu/books/dynamic-patterns}, 
abstract = {{foreword by Hermann Haken For the past twenty years Scott Kelso's research has focused on extending the physical concepts of self- organization and the mathematical tools of nonlinear dynamics to understand how human beings (and human brains) perceive, intend, learn, control, and coordinate complex behaviors. In this book Kelso proposes a new, general framework within which to connect brain, mind, and behavior.Kelso's prescription for mental life breaks dramatically with the classical computational approach that is still the operative framework for many newer psychological and neurophysiological studies. His core thesis is that the creation and evolution of patterned behavior at all levels—from neurons to mind—is governed by the generic processes of self-organization. Both human brain and behavior are shown to exhibit features of pattern-forming dynamical systems, including multistability, abrupt phase transitions, crises, and intermittency.Dynamic Patterns brings together different aspects of this approach to the study of human behavior, using simple experimental examples and illustrations to convey essential concepts, strategies, and methods, with a minimum of mathematics.Kelso begins with a general account of dynamic pattern formation. He then takes up behavior, focusing initially on identifying pattern-forming instabilities in human sensorimotor coordination. Moving back and forth between theory and experiment, he establishes the notion that the same pattern-forming mechanisms apply regardless of the component parts involved (parts of the body, parts of the nervous system, parts of society) and the medium through which the parts are coupled. Finally, employing the latest techniques to observe spatiotemporal patterns of brain activity, Kelso shows that the human brain is fundamentally a pattern forming dynamical system, poised on the brink of instability. Self-organization thus underlies the cooperative action of neurons that produces human behavior in all its forms.}}, 
urldate = {2021-05-19}, 
publisher = {The MIT Press}, 
language = {en}, 
note = {Publisher: The MIT Press}, 
keywords = {}
}
@article{Negrello.2008, 
year = {2008}, 
title = {{Attractor Landscapes and Active Tracking: The Neurodynamics of Embodied Action}}, 
author = {Negrello, Mario and Pasemann, Frank}, 
journal = {Adaptive Behavior}, 
issn = {1059-7123}, 
doi = {10.1177/1059712308090200}, 
url = {http://journals.sagepub.com/doi/10.1177/1059712308090200}, 
abstract = {{Behavior is the product of three intertwining dynamics: of the world, of the body and of internal control structures. Neurodynamics focuses on the dynamics of neural control, while observing interfaces with the world and the body. From this perspective, we present a dynamical analysis of embodied recurrent neural networks evolved to control a cybernetic device that solves a problem in active tracking. For competent action selection, agents must rely on the attractor landscapes of the evolved networks. Insights into how the networks achieve this are given in terms of the network's dynamical substrate, which highlights the role of the network's inherent attractors as they change as a function of the input parameters (sensors). We introduce some terminological extensions to neurodynamics to allow for a more precise formulation of how attractor changes influence behavior generation: in particular, attractor landscapes, which are the space of all attractors accessible through coherent parametrizations of the network (input stimuli), and the meta-transient, which resolves behavior by approaching attractors as they shape-shift. We apply these concepts to the analysis of interesting behaviors of the tracking device, such as temporal contextual dependency, chaotic transitory regimes in moments of ambiguity, and implicit mapping of environmental asymmetricities in the response of the device. Finally, we discuss the relevance of the concepts introduced in terms of autonomy, learning, and modularity.}}, 
shorttitle = {Attractor Landscapes and Active Tracking}, 
pages = {196--216}, 
number = {2-3}, 
volume = {16}, 
language = {en}, 
keywords = {}
}
@article{medeiros2021the, 
year = {2021}, 
title = {{The impact of chaotic saddles on the synchronization of complex networks of discrete-time units}}, 
author = {Medeiros, Everton and Medrano-T, Rene and Caldas, Ibere and Feudel, Ulrike}, 
journal = {Journal of Physics: Complexity}, 
doi = {10.1088/2632-072x/abedc2}, 
pages = {035002}, 
number = {3}, 
volume = {2}, 
keywords = {}
}
@article{makela1997metastable, 
year = {1997}, 
title = {{Metastable states in classical and quantum systems}}, 
author = {Makela, Mark and Parmley, Samantha and Yu, Roger}, 
journal = {American Journal of Physics}, 
issn = {0002-9505}, 
doi = {10.1119/1.18622}, 
url = {http://aapt.scitation.org/doi/10.1119/1.18622}, 
pages = {653--657}, 
number = {7}, 
volume = {65}, 
language = {en}, 
keywords = {}
}
@book{Singleton.2021, 
year = {2021}, 
title = {{LSD flattens the brain′s energy landscape: evidence from receptor-informed network control theory}}, 
author = {Singleton, S. and Luppi, Andrea and Carhart-Harris, Robin and Cruzat, Josephine and Roseman, Leor and Deco, Gustavo and Kringelbach, Morten and Stamatakis, Emmanuel and Kuceyeski, Amy}, 
abstract = {{Psychedelics like lysergic acid diethylamide (LSD) offer a powerful window into the function of the human brain and mind, by temporarily altering subjective experience through their neurochemical effects. The RElaxed Beliefs Under Psychedelics (REBUS) model postulates that 5-HT2a receptor agonism allows the brain to explore its dynamic landscape more readily, as suggested by more diverse (entropic) brain activity. Formally, this effect is theorized to correspond to a reduction in the energy required to transition between different brain-states, i.e. a “flattening of the energy landscape.” However, this hypothesis remains thus far untested. Here, we leverage network control theory to map the brain’s energy landscape, by quantifying the energy required to transition between recurrent brain states. In accordance with the REBUS model, we show that LSD reduces the energy required for brain-state transitions, and, furthermore, that this reduction in energy correlates with more frequent state transitions and increased entropy of brain-state dynamics. Through network control analysis that incorporates the spatial distribution of 5-HT2a receptors, we demonstrate the specific role of this receptor in flattening the brain’s energy landscape. Also, in accordance with REBUS, we show that the occupancy of bottom-up states is increased by LSD. In addition to validating fundamental predictions of the REBUS model of psychedelic action, this work highlights the potential of receptor-informed network control theory to provide mechanistic insights into pharmacological modulation of brain dynamics.  Significance Statement
We present a multi-modal framework for quantifying the effects of a psychedelic drug (LSD) on brain dynamics by combining functional magnetic resonance imaging (fMRI), diffusion MRI (dMRI), positron emission tomography (PET) and network control theory. Our findings provide support for a fundamental theory of the mechanism of action of psychedelics by showing that LSD flattens the brain’s energy landscape, allowing for more facile and frequent state transitions and more temporally diverse brain activity. We also demonstrate that the spatial distribution of serotonin 2a receptors - the main target of LSD - is key for generating these effects. This approach could be used to understand how drugs act on different receptors in the brain to influence brain function.}}, 
shorttitle = {LSD flattens the brain′s energy landscape}, 
series = {bioRxiv}, 
keywords = {}, 
doi = {10.1101/2021.05.14.444193}
}
@incollection{Hollander.2009, 
year = {2009}, 
keywords = {Free Particle,Glauber Dynamic,Ising Model,Metastable Behavior,Simple Random Walk}, 
title = {{Three Lectures on Metastability Under Stochastic Dynamics}}, 
author = {Hollander, Frank den}, 
editor = {\{\textbackslash\{Bovier, ["[\textbackslashtextbackslash"Biskup and\} and \{\textbackslashtextbackslash\textbackslashtextbackslash\textbackslash\{Hollander, Marek and\textbackslash\} and\} and \{\textbackslashtextbackslash\textbackslashtextbackslash\textbackslash\{Ioffe, Anton and den\textbackslashtextbackslash\textbackslashtextbackslash\textbackslash\} and\} and \{\textbackslashtextbackslash\textbackslashtextbackslash\textbackslash\{Martinelli, Frank and\textbackslashtextbackslash\textbackslashtextbackslash\textbackslash\} and\} and \{\textbackslashtextbackslash\textbackslashtextbackslash\textbackslash\{Netočný, Dima and\textbackslashtextbackslash\textbackslashtextbackslash\textbackslash\} and\} and \{\textbackslashtextbackslash\textbackslashtextbackslash\textbackslash\{Toninelli, Fabio and\textbackslashtextbackslash\textbackslashtextbackslash\textbackslash\} and\} and \{\textbackslashtextbackslash\textbackslashtextbackslash\textbackslash\{Kotecký, Karel and\textbackslashtextbackslash\textbackslashtextbackslash\textbackslash\} and\} and \{Roman\textbackslashtextbackslash"]"], Fabio and\textbackslashtextbackslash\textbackslashtextbackslash\textbackslash\} and\}}, 
booktitle = {Methods of Contemporary Mathematical Statistical Physics}, 
isbn = {978-3-540-92796-9}, 
url = {https://doi.org/10.1007/978-3-540-92796-9\_5}, 
abstract = {{Metastability is a phenomenon where a physical, chemical or biological system, under the influence of a noisy dynamics, moves between different regions of its state space on different time scales. On short time scales the system is in a quasi-equilibrium within a single region, while on long time scales it undergoes rapid transitions between quasiequilibria in different regions (see Fig. 1).Examples of metastability can be found in: biology: folding of proteins; climatology: effects of global warming; economics: crashes of financial markets; materials science: anomalous relaxation in disordered media; physics: freezing of supercooled liquids. The task of mathematics is to formulate microscopic models of the relevant underlying dynamics, to prove the occurrence of metastable behavior in these models on macroscopic space-time scales, and to identify the key mechanisms behind the experimentally observed universality in the metastable behavior of whole classes of systems. This is a challenging program!}}, 
urldate = {2021-05-19}, 
pages = {223--246}, 
series = {Lecture Notes in Mathematics}, 
publisher = {Springer}, 
address = {Berlin, Heidelberg}, 
language = {en}, 
doi = {10.1007/978-3-540-92796-9\_5}
}
@book{Kardar.2007, 
year = {2007}, 
title = {{Statistical Physics of Particles}}, 
author = {Kardar, Mehran}, 
isbn = {978-0-521-87342-0}, 
url = {https://www.cambridge.org/core/books/statistical-physics-of-particles/3CC2F33BD9F8DC56758DBDDB5B870558}, 
abstract = {{Statistical physics has its origins in attempts to describe the thermal properties of matter in terms of its constituent particles, and has played a fundamental role in the development of quantum mechanics. Based on lectures taught by Professor Kardar at MIT, this textbook introduces the central concepts and tools of statistical physics. It contains a chapter on probability and related issues such as the central limit theorem and information theory, and covers interacting particles, with an extensive description of the van der Waals equation and its derivation by mean field approximation. It also contains an integrated set of problems, with solutions to selected problems at the end of the book and a complete set of solutions is available to lecturers on a password protected website at www.cambridge.org/9780521873420. A companion volume, Statistical Physics of Fields, discusses non-mean field aspects of scaling and critical phenomena, through the perspective of renormalization group.}}, 
urldate = {2021-05-19}, 
publisher = {Cambridge University Press}, 
address = {Cambridge}, 
keywords = {}, 
doi = {10.1017/cbo9780511815898}
}
@book{Kozma.2016, 
year = {2016}, 
title = {{Cognitive Phase Transitions in the Cerebral Cortex - Enhancing the Neuron Doctrine by Modeling Neural Fields}}, 
author = {Kozma, Robert and Freeman, Walter J.}, 
isbn = {978-3-319-24404-4}, 
url = {https://www.springer.com/gp/book/9783319244044}, 
abstract = {{This intriguing book was born out of the many discussions the authors had in the past 10 years about the role of scale-free structure and dynamics in producing intelligent behavior in brains. The microscopic dynamics of neural networks is well described by the prevailing paradigm based in a narrow interpretation of the neuron doctrine. This book broadens the doctrine by incorporating the dynamics of neural fields, as first revealed by modeling with differential equations (K-sets). The book broadens that approach by application of random graph theory (neuropercolation). The book concludes with diverse commentaries that exemplify the wide range of mathematical/conceptual approaches to neural fields. This book is intended for researchers, postdocs, and graduate students, who see the limitations of network theory and seek a beachhead from which to embark on mesoscopic and macroscopic neurodynamics.}}, 
urldate = {2021-05-25}, 
series = {Studies in Systems, Decision and Control}, 
publisher = {Springer International Publishing}, 
language = {en}, 
keywords = {}, 
doi = {10.1007/978-3-319-24406-8}
}
@article{alderson2018metastable, 
year = {2018}, 
title = {{Metastable neural dynamics in Alzheimer’s disease are disrupted by lesions to the structural connectome}}, 
author = {Alderson, Thomas H. and Bokde, Arun L.W. and Kelso, J.A. Scott and Maguire, Liam and Coyle, Damien}, 
journal = {NeuroImage}, 
issn = {1053-8119}, 
doi = {10.1016/j.neuroimage.2018.08.033}, 
pmid = {30130642}, 
pmcid = {PMC6374703}, 
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6374703/}, 
abstract = {{Current theory suggests brain regions interact to reconcile the competing demands of integration and segregation by leveraging metastable dynamics. An emerging consensus recognises the importance of metastability in healthy neural
dynamics where the transition between network states over time is dependent upon
the structural connectivity between brain regions. In Alzheimer’s disease
(AD) - the most common form of dementia - these couplings are progressively
weakened, metastability of neural dynamics are reduced and cognitive ability is
impaired. Accordingly, we use a joint empirical and computational approach to
reveal how behaviourally relevant changes in neural metastability are contingent
on the structural integrity of the anatomical connectome. We estimate the
metastability of fMRI BOLD signal in subjects from across the AD spectrum and in
healthy controls and demonstrate the dissociable effects of structural
disconnection on synchrony versus metastability. In addition, we reveal the
critical role of metastability in general cognition by demonstrating the link
between an individuals cognitive performance and their metastable neural
dynamic. Finally, using whole-brain computer modelling, we demonstrate how a
healthy neural dynamic is conditioned upon the topological integrity of the
structural con- nectome. Overall, the results of our joint computational and
empirical analysis suggest an important causal relationship between metastable
neural dynamics, cognition, and the structural efficiency of the anatomical
connectome.}}, 
pages = {438--455}, 
volume = {183}, 
keywords = {}
}
@article{gili2018metastable, 
year = {2018}, 
title = {{Metastable States of Multiscale Brain Networks Are Keys to Crack the Timing Problem}}, 
author = {Gili, Tommaso and Ciullo, Valentina and Spalletta, Gianfranco}, 
journal = {Frontiers in Computational Neuroscience}, 
issn = {1662-5188}, 
doi = {10.3389/fncom.2018.00075}, 
pmid = {30254581}, 
pmcid = {PMC6141745}, 
url = {https://www.frontiersin.org/articles/10.3389/fncom.2018.00075/full}, 
abstract = {{The dynamic nature of the environment where we live in and the need to interact with it, predicting events in our context, provided strong evolutionary pressures for the brain functioning to process temporal information and generate timed responses. As a result of these pressures, the human brain is able to process temporal information and generate temporal patterns. Despite the clear importance of temporal processing to cognition, learning, communication and sensory, motor and emotional processing, even the most basic mechanisms of how animals discriminate simple intervals or generate timed responses are still under debate. The lesson we learned from the last decade of research in neuroscience is that functional and structural brain connectivity matter. Specifically, it has been accepted that the organization of the brain in interacting segregated networks enables its function. In this paper we delineate the route to a promising approach for investigating timing mechanisms. We illustrate how novel insight into timing mechanisms can come by investigating brain functioning as a multi-layer dynamical network whose clustered dynamics is bound to report the presence of metastable states. We anticipate that metastable dynamics underlie the real-time coordination necessary for the brain’s dynamic functioning associated with time perception. This new point of view will help further clarifying mechanisms of neuropsychiatric disorders.}}, 
pages = {75}, 
volume = {12}, 
keywords = {}
}
@article{Kelso, 
title = {{TOWARD A COMPLEMENTARY NEUROSCIENCE: METASTABLE COORDINATION DYNAMICS OF THE BRAIN}}, 
author = {Kelso, J A Scott and Tognoli, Emmanuelle}, 
abstract = {{Metastability has been proposed as a new principle of behavioral and brain function and may point the way to a truly complementary neuroscience. From elementary coordination dynamics we show explicitly that metastability is a result of a symmetry breaking caused by the subtle interplay of two forces: the tendency of the components to couple together and the tendency of the components to express their intrinsic independent behavior. The metastable regime reconciles the well-known tendencies of specialized brain regions to express their autonomy (segregation) and the tendencies for those regions to work together as a synergy (integration). Integration \textbackslashtextasciitilde segregation is just one of the complementary pairs (denoted by the tilde (\textbackslashtextasciitilde) symbol) to emerge from the science of coordination dynamics. We discuss metastability in the brain by describing the favorable conditions existing for its emergence and by deriving some predictions for its empirical characterization in neurophysiological recordings.}}, 
pages = {23}, 
language = {en}, 
keywords = {}
}
@article{fingelkurts2008brainmind, 
year = {2008}, 
title = {{Brain-Mind Operational Architectonics Imaging: Technical and Methodological Aspects}}, 
author = {Fingelkurts, Andrew A and Fingelkurts, Alexander A}, 
journal = {The Open Neuroimaging Journal}, 
issn = {1874-4400}, 
doi = {10.2174/1874440000802010073}, 
pmid = {19526071}, 
pmcid = {PMC2695620}, 
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2695620/}, 
abstract = {{This review paper deals with methodological and technical foundations of the Operational Architectonics framework of brain and mind functioning. This theory provides a framework for mapping and understanding important aspects of the brain mechanisms that constitute perception, cognition, and eventually consciousness. The methods utilized within Operational Architectonics framework allow analyzing with an incredible detail the operational behavior of local neuronal assemblies and their joint activity in the form of unified and metastable operational modules, which constitute the whole hierarchy of brain operations, operations of cognition and phenomenal consciousness.}}, 
shorttitle = {Brain-Mind Operational Architectonics Imaging}, 
pages = {73--93}, 
volume = {2}, 
keywords = {}
}
@article{sewell1980stability, 
year = {1980}, 
title = {{Stability, equilibrium and metastability in statistical mechanics}}, 
author = {Sewell and Geoffrey, L.}, 
journal = {Physics Reports}, 
doi = {10.1016/0370-1573(80)90167-2}, 
url = {https://linkinghub.elsevier.com/retrieve/pii/0370157380901672}, 
abstract = {{We survey a body of work, containing some new material, concerning the characterisation of equilibrium and metastable states of large assemblies of particles in terms of a variety of stability conditions. The theory is formulated in the thermodynamic limit and is based on the premise that the former states are those that are stable against all dynamical and thermodynamical perturbations, whereas the latter ones are endowed with only limited stability, sufficing to guarantee their long lifetimes and good thermodynamical behaviour. The Kubo-Martin-Schwinger (KMS) fluctuation-dissipation conditions play a central role in the developments stemming from this viewpoint, since it turns out that these conditions represent stability against localised disturbances of both the dynamical and thermo-dynamical kinds. Consequently, the stability arguments invoked here lead us to the following principal conclusions: (1) The equilibrium states are those that minimise the free energy density of the system and also satisfy the KMS conditions. This substantiates Gibbs's hypothesis that these states correspond to the standard ensembles. (2) Metastable states are of two kinds, that we term “ideal” and “normal”. Those of the former type satisfy the KMS conditions but minimise only the restriction of the free energy density to some reduced state space: those of the latter type are characterised by a still lower grade of stability. (3) The conditions on the forces under which ideal metastable states can exist are very restrictive, and thus the normal ones generally correspond to those observed in nature.}}, 
pages = {307--342}, 
number = {5}, 
volume = {57}, 
language = {en}, 
keywords = {}
}
@book{gunton1983introduction, 
year = {1983}, 
title = {{Introduction to the Theory of Metastable and Unstable States}}, 
author = {Gunton, J. D. and Droz, M.}, 
isbn = {978-3-540-12306-4}, 
url = {https://www.springer.com/de/book/9783540123064}, 
abstract = {{Introduction to the Theory of Metastable and Unstable States...}}, 
urldate = {2021-05-25}, 
series = {Lecture Notes in Physics}, 
publisher = {Springer-Verlag}, 
address = {Berlin Heidelberg}, 
language = {en}, 
keywords = {}, 
doi = {10.1007/bfb0035331}
}
@article{cordovapalomera2017disrupted, 
year = {2017}, 
title = {{Disrupted global metastability and static and dynamic brain connectivity across individuals in the Alzheimer's disease continuum.}}, 
author = {Córdova-Palomera, Aldo and Kaufmann, Tobias and Persson, Karin and Alnæs, Dag and Doan, Nhat Trung and Moberget, Torgeir and Lund, Martina Jonette and Barca, Maria Lage and Engvig, Andreas and Brækhus, Anne and Engedal, Knut and Andreassen, Ole A and Selbæk, Geir and Westlye, Lars T}, 
journal = {Scientific reports}, 
doi = {10.1038/srep40268}, 
pmid = {28074926}, 
pmcid = {PMC5225495}, 
abstract = {{As findings on the neuropathological and behavioral components of Alzheimer's disease (AD) continue to accrue, converging evidence suggests that macroscale brain functional disruptions may mediate their association. Recent developments on theoretical neuroscience indicate that instantaneous patterns of brain connectivity and metastability may be a key mechanism in neural communication underlying cognitive performance. However, the potential significance of these patterns across the AD spectrum remains virtually unexplored. We assessed the clinical sensitivity of static and dynamic functional brain disruptions across the AD spectrum using resting-state fMRI in a sample consisting of AD patients (n = 80) and subjects with either mild (n = 44) or subjective (n = 26) cognitive impairment (MCI, SCI). Spatial maps constituting the nodes in the functional brain network and their associated time-series were estimated using spatial group independent component analysis and dual regression, and whole-brain oscillatory activity was analyzed both globally (metastability) and locally (static and dynamic connectivity). Instantaneous phase metrics showed functional coupling alterations in AD compared to MCI and SCI, both static (putamen, dorsal and default-mode) and dynamic (temporal, frontal-superior and default-mode), along with decreased global metastability. The results suggest that brains of AD patients display altered oscillatory patterns, in agreement with theoretical premises on cognitive dynamics.}}, 
pages = {40268}, 
number = {1}, 
volume = {7}, 
keywords = {}
}
@article{afraimovich2010longrange, 
year = {2010}, 
title = {{Long-range Interactions, Stochasticity and Fractional Dynamics, Dedicated to George M. Zaslavsky (1935–2008)}}, 
author = {Afraimovich, Valentin S. and Muezzinoglu, Mehmet K. and Rabinovich, Mikhail I.}, 
journal = {Nonlinear Physical Science}, 
issn = {1867-8440}, 
doi = {10.1007/978-3-642-12343-6\_4}, 
abstract = {{Experimental neuroscience is often based on the implicit premise that the neural mechanisms underlying perception, emotion and cognition are well approximated by steady-state measurements of neuron activity or snapshot of images. We will unfold a new paradigm in the study of brain mental dynamics departing from the stable transient activity neural networks, as supported by experiments. Transients have two main features: (1) they are resistant to noise, and reliable even in the face of small variations in initial condition, (2) the transients are input-specific, and thus convey information about what caused them in the first place. This new dynamical view manifests a rigorous explanation of how perception, cognition, emotion, and other mental processes evolve as a sequence of metastable states in the brain and suggests the new approaches to the diagnostics of mental diseases. The mathematical image of robust and sensitive transients is a stable heteroclinic channel that is possibly the only dynamical object that satisfies all required conditions. We discuss the ideas that lead to the creation of a quantitative theory of mental human activity. For the convenience of the reader we put all mathematical details into Appendices.}}, 
pages = {133--175}, 
keywords = {}
}
@article{lehmann1987eeg, 
year = {1987}, 
title = {{EEG alpha map series: brain micro-states by space-oriented adaptive segmentation}}, 
author = {Lehmann, D. and Ozaki, H. and Pal, I.}, 
journal = {Electroencephalography and Clinical Neurophysiology}, 
issn = {0013-4694}, 
doi = {10.1016/0013-4694(87)90025-3}, 
pmid = {2441961}, 
abstract = {{The spontaneous EEG, viewed as a series of momentary scalp field maps, shows stable map configurations (of periodically reversed polarity) for varying durations, and discontinuous changes of the configurations. For adaptive segmentation of map series into spatially stationary epochs, the maps at the times of maximal map relief are selected and spatially described by the 3wo locations of maximal and minimal (extreme) potentials; a segment ends if over time an extreme leaves its pre-set spatial window. Over 6 objects, the resting alpha EEG showed 210 msec mean segment duration; segments longer than 323 msec covered 50\% of the total time; the most prominent segment class (1.5\textbackslash\% of all classes) covered 20\textbackslash\% of total time (prominence varied strongly over classes; not all possible classes occured). Spectral power and phase of averages of adaptive and pre-determined segments demonstrated the adequacy of the strategy, and the homegeneity of adaptive segment classes by their reduced within-class variance. It is suggested that different segment classes manifest different brain functional states exerting different effects on information processing. The spatially stationary segments might be basic building blocks of brain information processing, possibly operationalizing consciousness time and offering a common phenomenology for spontaneous activity and event-related potentials. The functional significance of segments might be modes or steps of information processing or performance, tested, e.g., as reaction time.}}, 
pages = {271--288}, 
number = {3}, 
volume = {67}, 
keywords = {}
}
@article{tognoli2014enlarging, 
year = {2014}, 
title = {{Enlarging the scope: grasping brain complexity}}, 
author = {Tognoli, Emmanuelle and Kelso, J. A. Scott}, 
journal = {Frontiers in Systems Neuroscience}, 
issn = {1662-5137}, 
doi = {10.3389/fnsys.2014.00122}, 
pmid = {25009476}, 
pmcid = {PMC4070173}, 
eprint = {1310.7277}, 
abstract = {{To further advance our understanding of the brain, new concepts and theories are needed. In particular, the ability of the brain to create information flows must be reconciled with its propensity for synchronization and mass action. The theoretical and empirical framework of Coordination Dynamics, a key aspect of which is metastability, are presented as a starting point to study the interplay of integrative and segregative tendencies that are expressed in space and time during the normal course of brain and behavioral function. Some recent shifts in perspective are emphasized, that may ultimately lead to a better understanding of brain complexity.}}, 
pages = {122}, 
volume = {8}, 
keywords = {}
}
@article{deco2015rethinking, 
year = {2015}, 
title = {{Rethinking segregation and integration: contributions of whole-brain modelling}}, 
author = {Deco, Gustavo and Tononi, Giulio and Boly, Melanie and Kringelbach, Morten L.}, 
journal = {Nature Reviews Neuroscience}, 
issn = {1471-003X}, 
doi = {10.1038/nrn3963}, 
pmid = {26081790}, 
abstract = {{The brain balances the segregation and integration of incoming information to facilitate flexible cognition and behaviour. In this Opinion article, Deco and colleagues argue that whole-brain computational modelling based on neuroimaging data can provide insights into these segregation and integration processes. The brain regulates information flow by balancing the segregation and integration of incoming stimuli to facilitate flexible cognition and behaviour. The topological features of brain networks — in particular, network communities and hubs — support this segregation and integration but do not provide information about how external inputs are processed dynamically (that is, over time). Experiments in which the consequences of selective inputs on brain activity are controlled and traced with great precision could provide such information. However, such strategies have thus far had limited success. By contrast, recent whole-brain computational modelling approaches have enabled us to start assessing the effect of input perturbations on brain dynamics in silico.}}, 
pages = {430--439}, 
number = {7}, 
volume = {16}, 
keywords = {}
}
@article{rabinovich2018discrete, 
year = {2018}, 
title = {{Discrete Sequential Information Coding: Heteroclinic Cognitive Dynamics}}, 
author = {Rabinovich, Mikhail I. and Varona, Pablo}, 
journal = {Frontiers in Computational Neuroscience}, 
issn = {1662-5188}, 
doi = {10.3389/fncom.2018.00073}, 
pmid = {30245621}, 
pmcid = {PMC6137616}, 
abstract = {{Discrete sequential information coding is a key mechanism that transforms complex cognitive brain activity into a low-dimensional dynamical process based on the sequential switching among finite numbers of patterns. The storage size of the corresponding process is large because of the permutation capacity as a function of control signals in ensembles of these patterns. Extracting low-dimensional functional dynamics from multiple large-scale neural populations is a central problem both in neuro- and cognitive- sciences. Experimental results in the last decade represent a solid base for the creation of low-dimensional models of different cognitive functions and allow moving toward a dynamical theory of consciousness. We discuss here a methodology to build simple kinetic equations that can be the mathematical skeleton of this theory. Models of the corresponding discrete information processing can be designed using the following dynamical principles: (i) clusterization of the neural activity in space and time and formation of information patterns; (ii) robustness of the sequential dynamics based on heteroclinic chains of metastable clusters; and (iii) sensitivity of such sequential dynamics to intrinsic and external informational signals. We analyze sequential discrete coding based on winnerless competition low-frequency dynamics. Under such dynamics, entrainment, and heteroclinic coordination leads to a large variety of coding regimes that are invariant in time.}}, 
pages = {73}, 
volume = {12}, 
keywords = {}
}
@article{feudel2008complex, 
year = {2008}, 
title = {{Complex Dynamics In Multistable Systems}}, 
author = {Feudel, Ulrike}, 
journal = {International Journal of Bifurcation and Chaos}, 
issn = {0218-1274}, 
doi = {10.1142/s0218127408021233}, 
abstract = {{The coexistence of several stable states for a given set of parameters has been observed in many natural and experimental systems as well as in theoretical models. This paper gives an overview over the wide range of applications in different disciplines of science. Furthermore, different system classes possessing multistability are analyzed in terms of the appearance of coexisting attractors and their basins of attraction. It is shown that multistable systems are very sensitive to perturbations leading to a noise-induced hopping process between attractors. The role of chaotic saddles in the escape from attractors in multistable systems is discussed.}}, 
pages = {1607--1626}, 
number = {06}, 
volume = {18}, 
keywords = {}
}
@article{hellyer2015cognitive, 
year = {2015}, 
title = {{Cognitive Flexibility through Metastable Neural Dynamics Is Disrupted by Damage to the Structural Connectome}}, 
author = {Hellyer, Peter J. and Scott, Gregory and Shanahan, Murray and Sharp, David J. and Leech, Robert}, 
journal = {The Journal of Neuroscience}, 
issn = {0270-6474}, 
doi = {10.1523/jneurosci.4648-14.2015}, 
pmid = {26085630}, 
pmcid = {PMC4469735}, 
abstract = {{Current theory proposes that healthy neural dynamics operate in a metastable regime, where brain regions interact to simultaneously maximize integration and segregation. Metastability may confer important behavioral properties, such as cognitive flexibility. It is increasingly recognized that neural dynamics are constrained by the underlying structural connections between brain regions. An important challenge is, therefore, to relate structural connectivity, neural dynamics, and behavior. Traumatic brain injury (TBI) is a pre-eminent structural disconnection disorder whereby traumatic axonal injury damages large-scale connectivity, producing characteristic cognitive impairments, including slowed information processing speed and reduced cognitive flexibility, that may be a result of disrupted metastable dynamics. Therefore, TBI provides an experimental and theoretical model to examine how metastable dynamics relate to structural connectivity and cognition. Here, we use complementary empirical and computational approaches to investigate how metastability arises from the healthy structural connectome and relates to cognitive performance. We found reduced metastability in large-scale neural dynamics after TBI, measured with resting-state functional MRI. This reduction in metastability was associated with damage to the connectome, measured using diffusion MRI. Furthermore, decreased metastability was associated with reduced cognitive flexibility and information processing. A computational model, defined by empirically derived connectivity data, demonstrates how behaviorally relevant changes in neural dynamics result from structural disconnection. Our findings suggest how metastable dynamics are important for normal brain function and contingent on the structure of the human connectome.}}, 
pages = {9050--9063}, 
number = {24}, 
volume = {35}, 
keywords = {}
}
@article{muller2016rotating, 
year = {2016}, 
title = {{Rotating waves during human sleep spindles organize global patterns of activity that repeat precisely through the night}}, 
author = {Muller, Lyle and Piantoni, Giovanni and Koller, Dominik and Cash, Sydney S and Halgren, Eric and Sejnowski, Terrence J}, 
journal = {eLife}, 
doi = {10.7554/elife.17267}, 
pmid = {27855061}, 
pmcid = {PMC5114016}, 
abstract = {{During sleep, the thalamus generates a characteristic pattern of transient, 11-15 Hz sleep spindle oscillations, which synchronize the cortex through large-scale thalamocortical loops. Spindles have been increasingly demonstrated to be critical for sleep-dependent consolidation of memory, but the specific neural mechanism for this process remains unclear. We show here that cortical spindles are spatiotemporally organized into circular wave-like patterns, organizing neuronal activity over tens of milliseconds, within the timescale for storing memories in large-scale networks across the cortex via spike-time dependent plasticity. These circular patterns repeat over hours of sleep with millisecond temporal precision, allowing reinforcement of the activity patterns through hundreds of reverberations. These results provide a novel mechanistic account for how global sleep oscillations and synaptic plasticity could strengthen networks distributed across the cortex to store coherent and integrated memories. DOI: http://dx.doi.org/10.7554/eLife.17267.001}}, 
pages = {e17267}, 
volume = {5}, 
keywords = {}
}
@article{vandeville2010eeg, 
year = {2010}, 
title = {{EEG microstate sequences in healthy humans at rest reveal scale-free dynamics}}, 
author = {Ville, Dimitri Van De and Britz, Juliane and Michel, Christoph M.}, 
journal = {Proceedings of the National Academy of Sciences}, 
issn = {0027-8424}, 
doi = {10.1073/pnas.1007841107}, 
pmid = {20921381}, 
abstract = {{Recent findings identified electroencephalography (EEG) microstates as the electrophysiological correlates of fMRI resting-state networks. Microstates are defined as short periods (100 ms) during which the EEG scalp topography remains quasi-stable; that is, the global topography is fixed but strength might vary and polarity invert. Microstates represent the subsecond coherent activation within global functional brain networks. Surprisingly, these rapidly changing EEG microstates correlate significantly with activity in fMRI resting-state networks after convolution with the hemodynamic response function that constitutes a strong temporal smoothing filter. We postulate here that microstate sequences should reveal scale-free, self-similar dynamics to explain this remarkable effect and thus that microstate time series show dependencies over long time ranges. To that aim, we deploy wavelet-based fractal analysis that allows determining scale-free behavior. We find strong statistical evidence that microstate sequences are scale free over six dyadic scales covering the 256-ms to 16-s range. The degree of long-range dependency is maintained when shuffling the local microstate labels but becomes indistinguishable from white noise when equalizing microstate durations, which indicates that temporal dynamics are their key characteristic. These results advance the understanding of temporal dynamics of brain-scale neuronal network models such as the global workspace model. Whereas microstates can be considered the “atoms of thoughts,” the shortest constituting elements of cognition, they carry a dynamic signature that is reminiscent at characteristic timescales up to multiple seconds. The scale-free dynamics of the microstates might be the basis for the rapid reorganization and adaptation of the functional networks of the brain.}}, 
pages = {18179--18184}, 
number = {42}, 
volume = {107}, 
keywords = {}
}
@article{alderson2020metastable, 
year = {2020}, 
title = {{Metastable neural dynamics underlies cognitive performance across multiple behavioural paradigms}}, 
author = {Alderson, Thomas H. and Bokde, Arun L. W. and Kelso, J. A. Scott and Maguire, Liam and Coyle, Damien}, 
journal = {Human Brain Mapping}, 
issn = {1065-9471}, 
doi = {10.1002/hbm.25009}, 
pmid = {32301561}, 
pmcid = {PMC7375112}, 
abstract = {{Despite resting state networks being associated with a variety of cognitive abilities, it remains unclear how these local areas act in concert to express particular cognitive operations. Theoretical and empirical accounts indicate that large‐scale resting state networks reconcile dual tendencies towards integration and segregation by operating in a metastable regime of their coordination dynamics. Metastability may confer important behavioural qualities by binding distributed local areas into large‐scale neurocognitive networks. We tested this hypothesis by analysing fMRI data in a large cohort of healthy individuals (N = 566) and comparing the metastability of the brain's large‐scale resting network architecture at rest and during the performance of several tasks. Metastability was estimated using a well‐defined collective variable capturing the level of 'phase‐locking' between large‐scale networks over time. Task‐based reasoning was principally characterised by high metastability in cognitive control networks and low metastability in sensory processing areas. Although metastability between resting state networks increased during task performance, cognitive ability was more closely linked to spontaneous activity. High metastability in the intrinsic connectivity of cognitive control networks was linked to novel problem solving or fluid intelligence, but was less important in tasks relying on previous experience or crystallised intelligence. Crucially, subjects with resting architectures similar or 'pre‐configured' to a task‐general arrangement demonstrated superior cognitive performance. Taken together, our findings support a key linkage between the spontaneous metastability of large‐scale networks in the cerebral cortex and cognition.}}, 
pages = {3212--3234}, 
number = {12}, 
volume = {41}, 
keywords = {}
}
@article{sasaki2007metastability, 
year = {2007}, 
title = {{Metastability of Active CA3 Networks}}, 
author = {Sasaki, T and Matsuki, N and Ikegaya, Y}, 
journal = {Journal of Neuroscience}, 
issn = {0270-6474}, 
doi = {10.1523/jneurosci.4514-06.2007}, 
pmid = {17234584}, 
abstract = {{The brain is spontaneously active even in the absence of external input. This ongoing background activity impacts neural information processing. We used functional multineuron calcium imaging (fMCI) to analyze the net structure of spontaneous CA3 network activity in hippocampal slice cultures loaded with Oregon Green 488 BAPTA-1 using a spinning disk confocal microscope (10-30 frames/s). Principal component analysis revealed that network states, defined by active cell ensembles, were stable but heterogenous and discrete. These states were stabilized through synaptic activity and maintained against external perturbations. A few discrete states emerged during our observation period of up to 30 min. Networks tended to stay in a single state for tens of seconds and then suddenly jump to a new state. After a state transition, the old state was rarely, if ever, revisited by the network during our observation period. This temporal profile of state transitions could not be simulated by a hidden Markov model, indicating that the state dynamics is nonrandomly organized. Within each state, the pattern of network activity tended to stabilize in a specific configuration. Neither maintenance nor transition of the network states required NMDA receptor activity. These findings suggest that the network states are metastable, rather than multistable, and might be governed by local attractor-like dynamics. The fMCI data analyzed here are available at http://hippocampus.jp/data/}}, 
pages = {517--528}, 
number = {3}, 
volume = {27}, 
keywords = {}
}
@article{Pascanu.2011, 
year = {2011}, 
title = {{A neurodynamical model for working memory}}, 
author = {Pascanu, Razvan and Jaeger, Herbert}, 
journal = {Neural Networks}, 
issn = {0893-6080}, 
doi = {10.1016/j.neunet.2010.10.003}, 
pmid = {21036537}, 
abstract = {{Neurodynamical models of working memory (WM) should provide mechanisms for storing, maintaining, retrieving, and deleting information. Many models address only a subset of these aspects. Here we present a rather simple WM model in which all of these performance modes are trained into a recurrent neural network (RNN) of the echo state network (ESN) type. The model is demonstrated on a bracket level parsing task with a stream of rich and noisy graphical script input. In terms of nonlinear dynamics, memory states correspond, intuitively, to attractors in an input-driven system. As a supplementary contribution, the article proposes a rigorous formal framework to describe such attractors, generalizing from the standard definition of attractors in autonomous (input-free) dynamical systems.}}, 
pages = {199--207}, 
number = {2}, 
volume = {24}, 
keywords = {}
}
@article{rabinovich2001dynamical, 
year = {2001}, 
title = {{Dynamical Encoding by Networks of Competing Neuron Groups: Winnerless Competition}}, 
author = {Rabinovich, M. and Volkovskii, A. and Lecanda, P. and Huerta, R. and Abarbanel, H. D. I. and Laurent, G.}, 
journal = {Physical Review Letters}, 
issn = {0031-9007}, 
doi = {10.1103/physrevlett.87.068102}, 
pmid = {11497865}, 
abstract = {{Following studies of olfactory processing in insects and fish, we investigate neural networks whose dynamics in phase space is represented by orbits near the heteroclinic connections between saddle regions (fixed points or limit cycles). These networks encode input information as trajectories along the heteroclinic connections. If there are N neurons in the network, the capacity is approximately e(N-1)!, i.e., much larger than that of most traditional network structures. We show that a small winnerless competition network composed of FitzHugh-Nagumo spiking neurons efficiently transforms input information into a spatiotemporal output.}}, 
pages = {068102}, 
number = {6}, 
volume = {87}, 
keywords = {}
}
@article{rabinovich2014chunking, 
year = {2014}, 
title = {{Chunking dynamics: heteroclinics in mind}}, 
author = {Rabinovich, Mikhail I. and Varona, Pablo and Tristan, Irma and Afraimovich, Valentin S.}, 
journal = {Frontiers in Computational Neuroscience}, 
issn = {1662-5188}, 
doi = {10.3389/fncom.2014.00022}, 
pmid = {24672469}, 
pmcid = {PMC3954027}, 
abstract = {{Recent results of imaging technologies and non-linear dynamics make possible to relate the structure and dynamics of functional brain networks to different mental tasks and to build theoretical models for the description and prediction of cognitive activity. Such models are non-linear dynamical descriptions of the interaction of the core components—brain modes—participating in a specific mental function. The dynamical images of different mental processes depend on their temporal features. The dynamics of many cognitive functions are transient. They are often observed as a chain of sequentially changing metastable states. A stable heteroclinic channel (SHC) consisting of a chain of saddles—metastable states—connected by unstable separatrices is a mathematical image for robust transients. In this paper we focus on hierarchical chunking dynamics that can represent several forms of transient cognitive activity. Chunking is a dynamical phenomenon that nature uses to perform information processing of long sequences by dividing them in shorter information items. Chunking, for example, makes more efficient the use of short-term memory by breaking up long strings of information (like in language where one can see the separation of a novel on chapters, paragraphs, sentences, and finally words). Chunking is important in many processes of perception, learning, and cognition in humans and animals. Based on anatomical information about the hierarchical organization of functional brain networks, we propose a cognitive network architecture that hierarchically chunks and super-chunks switching sequences of metastable states produced by winnerless competitive heteroclinic dynamics.}}, 
pages = {22}, 
volume = {8}, 
keywords = {}
}
@article{wilting2018operating, 
year = {2018}, 
title = {{Operating in a Reverberating Regime Enables Rapid Tuning of Network States to Task Requirements}}, 
author = {Wilting, Jens and Dehning, Jonas and Neto, Joao Pinheiro and Rudelt, Lucas and Wibral, Michael and Zierenberg, Johannes and Priesemann, Viola}, 
journal = {Frontiers in Systems Neuroscience}, 
issn = {1662-5137}, 
doi = {10.3389/fnsys.2018.00055}, 
pmid = {30459567}, 
pmcid = {PMC6232511}, 
eprint = {1809.07550}, 
abstract = {{Neural circuits are able to perform computations under very diverse conditions and requirements. The required computations impose clear constraints on their fine-tuning: a rapid and maximally informative response to stimuli in general requires decorrelated baseline neural activity. Such network dynamics is known as asynchronous-irregular. In contrast, spatio-temporal integration of information requires maintenance and transfer of stimulus information over extended time periods. This can be realized at criticality, a phase transition where correlations, sensitivity and integration time diverge. Being able to flexibly switch, or even combine the above properties in a task-dependent manner would present a clear functional advantage. We propose that cortex operates in a “reverberating regime” because it is particularly favorable for ready adaptation of computational properties to context and task. This reverberating regime enables cortical networks to interpolate between the asynchronous-irregular and the critical state by small changes in effective synaptic strength or excitation-inhibition ratio. These changes directly adapt computational properties, including sensitivity, amplification, integration time and correlation length within the local network. We review recent converging evidence that cortex in vivo operates in the reverberating regime, and that various cortical areas have adapted their integration times to processing requirements. In addition, we propose that neuromodulation enables a fine-tuning of the network, so that local circuits can either decorrelate or integrate, and quench or maintain their input depending on task. We argue that this task-dependent tuning, which we call “dynamic adaptive computation,” presents a central organization principle of cortical networks and discuss first experimental evidence.}}, 
pages = {55}, 
volume = {12}, 
keywords = {}
}
@article{buonomano2009state, 
year = {2009}, 
title = {{State-dependent computations: spatiotemporal processing in cortical networks}}, 
author = {Buonomano, Dean V. and Maass, Wolfgang}, 
journal = {Nature Reviews Neuroscience}, 
issn = {1471-003X}, 
doi = {10.1038/nrn2558}, 
pmid = {19145235}, 
abstract = {{All forms of sensory processing require sense to be made of the complex spatiotemporal patterns of action potentials that are generated in our sensory organs by external stimuli.Any general model of cortical processing must account for the brain's ability to process both the spatial and the temporal features of stimuli, and thus must account for spatiotemporal processing in general.State-dependent classes of neural network models propose that the temporal information is inherently encoded in the state of the network.The internal state can be divided into the active state, which reflects ongoing neural activity that interacts with incoming external inputs, and the hidden state, which reflects neural properties that change in time even when a network is silent (for example, short-term synaptic plasticity).In vivo electrophysiological recordings show that the neural population response of a network is strongly influenced by preceding activity, and thus that networks behave in a state-dependent manner.A prediction that emerges from the proposed framework is that the neural network response to a given stimulus encodes not only the current stimulus, but also previous stimuli. All forms of sensory processing require sense to be made of the complex spatiotemporal patterns of action potentials that are generated in our sensory organs by external stimuli. Any general model of cortical processing must account for the brain's ability to process both the spatial and the temporal features of stimuli, and thus must account for spatiotemporal processing in general. State-dependent classes of neural network models propose that the temporal information is inherently encoded in the state of the network. The internal state can be divided into the active state, which reflects ongoing neural activity that interacts with incoming external inputs, and the hidden state, which reflects neural properties that change in time even when a network is silent (for example, short-term synaptic plasticity). In vivo electrophysiological recordings show that the neural population response of a network is strongly influenced by preceding activity, and thus that networks behave in a state-dependent manner. A prediction that emerges from the proposed framework is that the neural network response to a given stimulus encodes not only the current stimulus, but also previous stimuli. Most models of sensory processing consider the spatial and temporal aspects of sensory stimuli separately. Here, Buonomano and Maass describe a framework in which spatiotemporal computations emerge from the interaction between incoming stimuli and the internal dynamic state of neural networks. A conspicuous ability of the brain is to seamlessly assimilate and process spatial and temporal features of sensory stimuli. This ability is indispensable for the recognition of natural stimuli. Yet, a general computational framework for processing spatiotemporal stimuli remains elusive. Recent theoretical and experimental work suggests that spatiotemporal processing emerges from the interaction between incoming stimuli and the internal dynamic state of neural networks, including not only their ongoing spiking activity but also their 'hidden' neuronal states, such as short-term synaptic plasticity.}}, 
pages = {113--125}, 
number = {2}, 
volume = {10}, 
keywords = {}
}
@article{tononi1998consciousness, 
year = {1998}, 
title = {{Consciousness and Complexity}}, 
author = {Tononi, Giulio and Edelman, Gerald M.}, 
journal = {Science}, 
issn = {0036-8075}, 
doi = {10.1126/science.282.5395.1846}, 
pmid = {9836628}, 
abstract = {{Conventional approaches to understanding consciousness are generally concerned with the contribution of specific brain areas or groups of neurons. By contrast, it is considered here what kinds of n...}}, 
pages = {1846--1851}, 
number = {5395}, 
volume = {282}, 
keywords = {}
}
@article{tsuda2015chaotic, 
year = {2015}, 
title = {{Chaotic itinerancy and its roles in cognitive neurodynamics}}, 
author = {Tsuda, Ichiro}, 
journal = {Current Opinion in Neurobiology}, 
issn = {0959-4388}, 
doi = {10.1016/j.conb.2014.08.011}, 
pmid = {25217808}, 
abstract = {{Chaotic itinerancy is an autonomously excited trajectory through high-dimensional state space of cortical neural activity that causes the appearance of a temporal sequence of quasi-attractors. A quasi-attractor is a local region of weakly convergent flows that represent ordered activity, yet connected to divergent flows representing disordered, chaotic activity between the regions. In a cognitive neurodynamic aspect, quasi-attractors represent perceptions, thoughts and memories, chaotic trajectories between them with intelligent searches, such as history-dependent trial-and-error via exploration, and itinerancy with history-dependent sequences in thinking, speaking and writing.}}, 
pages = {67--71}, 
volume = {31}, 
keywords = {}
}
@book{strogatz2002nonlinear, 
year = {2002}, 
title = {{Nonlinear Dynamics and Chaos}}, 
author = {Strogatz}, 
series = {Studies in nonlinearity}, 
publisher = {Westview}, 
keywords = {}, 
doi = {10.1201/9781420033830-8}
}
@article{ashwin1994bubbling, 
year = {1994}, 
title = {{Bubbling of attractors and synchronisation of chaotic oscillators}}, 
author = {Ashwin, Peter and Buescu, Jorge and Stewart, Ian}, 
journal = {Physics Letters A}, 
issn = {0375-9601}, 
doi = {10.1016/0375-9601(94)90947-4}, 
abstract = {{We present a system of two coupled identical chaotic electronic circuits that exhibit a blowout bifurcation resulting in loss of stability of the synchronised state. We introduce the concept of bubbling of an attractor, a new type of intermittency that is triggered by low levels of noise, and demonstrate numerical and experimental examples of this behaviour. In particular we observe bubbling near the synchronised state of two coupled chaotic oscillators. We give a theoretical description of the behaviour associated with locally riddled basins, emphasising the role of invariant measures. In general these are non-unique for a given chaotic attractor, which gives rise to a spectrum of Lyapunov exponents. The behaviour of the attractor depends on the whole spectrum. In particular, bubbling is associated with the loss of stability of an attractor in a dynamically invariant subspace, and is typical in such systems.}}, 
pages = {126--139}, 
number = {2}, 
volume = {193}, 
keywords = {}
}
@article{ott1994blowout, 
year = {1994}, 
title = {{Blowout bifurcations: the occurrence of riddled basins and on-off intermittency}}, 
author = {Ott, Edward and Sommerer, John C.}, 
journal = {Physics Letters A}, 
issn = {0375-9601}, 
doi = {10.1016/0375-9601(94)90114-7}, 
abstract = {{We consider situations where a nonlinear dynamical system possesses a smooth invariant manifold. For parameter values p less than a critical value pc, the invariant manifold has within it a chaotic attractor of the system. As p increases through pc a blowout bifurcation takes place, in which the former attraction to the manifold changes to repulsion, and the chaotic set in the manifold ceases to be an attractor of the system. Depending on the dynamics away from the manifold, blowout bifurcations can be either hysteretic or nonhysteretic, and they are correspondingly accompanied either by riddled basins (in which the basin is a “fat fractal”) or by an extreme form of temporally intermittent bursting recently called on-off intermittency. The role of the dynamics away from the manifold in determining the hysteretic or supercritical nature of the bifurcation is explicitly illustrated with a numerical example.}}, 
pages = {39--47}, 
number = {1}, 
volume = {188}, 
keywords = {}
}
@article{Belykh.2005, 
year = {2005}, 
title = {{Synchronization of Bursting Neurons: What Matters in the Network Topology}}, 
author = {Belykh, Igor and Lange, Enno de and Hasler, Martin}, 
journal = {Physical Review Letters}, 
issn = {0031-9007}, 
doi = {10.1103/physrevlett.94.188101}, 
pmid = {15904412}, 
abstract = {{We study the influence of coupling strength and network topology on synchronization behavior in pulse-coupled networks of bursting Hindmarsh-Rose neurons. Surprisingly, we find that the stability of the completely synchronous state in such networks only depends on the number of signals each neuron receives, independent of all other details of the network topology. This is in contrast with linearly coupled bursting neurons where complete synchrony strongly depends on the network structure and number of cells. Through analysis and numerics, we show that the onset of synchrony in a network with any coupling topology admitting complete synchronization is ensured by one single condition.}}, 
pages = {188101}, 
number = {18}, 
volume = {94}, 
keywords = {}
}
@article{Blackbeard.2014, 
year = {2014}, 
title = {{From synchronisation to persistent optical turbulence in laser arrays}}, 
author = {Blackbeard, Nicholas and Wieczorek, Sebastian and Erzgräber, Hartmut and Dutta, Partha Sharathi}, 
journal = {Physica D: Nonlinear Phenomena}, 
issn = {0167-2789}, 
doi = {10.1016/j.physd.2014.07.007}, 
abstract = {{We define and study synchronisation in a linear array of nearest-neighbour coupled lasers. Our focus is on possible synchronisation types and the stability of their corresponding synchronisation manifolds with dependence on the coupling strength, the laser frequency detuning, the amount of shear (amplitude–phase coupling) in a single laser, and the array size. We classify, and give analytical conditions for the existence of complete synchronisation solutions, where all the lasers emit light with the same intensity and frequency. Furthermore, we derive stability criteria for two special cases where all the lasers oscillate (i) in-phase with each other and (ii) in anti-phase with their nearest neighbour(s). We then explain transitions from complete synchronisation, to partial synchronisation (where only a subset of the lasers synchronises), to persistent optical turbulence (where no lasers synchronise and each laser is chaotic) in terms of bifurcations including blowouts of chaotic attractors. Finally, we quantify properties of optical turbulence using Lyapunov spectrum and dimension, which highlights differences in chaos generated by nearest-neighbour and globally coupled oscillators.}}, 
pages = {43--58}, 
volume = {286}, 
keywords = {}
}
@article{saha2018characteristics, 
year = {2018}, 
title = {{Characteristics of in-out intermittency in delay-coupled FitzHugh–Nagumo oscillators}}, 
author = {Saha, Arindam and Feudel, Ulrike}, 
journal = {The European Physical Journal Special Topics}, 
issn = {1951-6355}, 
doi = {10.1140/epjst/e2018-800085-0}, 
eprint = {1805.02159}, 
abstract = {{We analyze a pair of delay-coupled FitzHugh–Nagumo oscillators exhibiting in-out intermittency as a part of the generating mechanism of extreme events. We study in detail the characteristics of in-out intermittency and identify the invariant subsets involved – a saddle fixed point and a saddle periodic orbit – neither of which are chaotic as in the previously reported cases of in-out intermittency. Based on the analysis of a periodic attractor possessing in-out dynamics, we can characterize the approach to the invariant synchronization manifold and the spiralling out to the saddle periodic orbit with subsequent ejection from the manifold. Due to the striking similarities, this analysis of in-out dynamics also explains in-out intermittency}}, 
pages = {1205--1219}, 
number = {10-11}, 
volume = {227}, 
keywords = {}
}
@article{heagy1994characterization, 
year = {1994}, 
title = {{Characterization of on-off intermittency}}, 
author = {Heagy, J. F. and Platt, N. and Hammel, S. M.}, 
journal = {Physical Review E}, 
issn = {1539-3755}, 
doi = {10.1103/physreve.49.1140}, 
pmid = {9961322}, 
abstract = {{The recently reported behavior known as ‘‘on-off intermittency’’ [N. Platt, E. A. Spiegel, and C. Tresser, Phys. Rev. Lett. 70, 279 (1993)] is investigated in a class of one-dimensional maps that are multiplicatively coupled to either random or chaotic signals. Specific attention is paid to the conditions for the onset of intermittent behavior, the distribution of laminar phases, and the mean laminar phase as a function of the coupling strength. An exact expression is obtained for the distribution of laminar phases in the case of uniformly distributed random driving. A universal asymptotic -3/2 power-law distribution is proven to hold for a large class of random driving cases. Power-law scaling of the mean laminar phase as a function of coupling strength near onset is predicted for random driving, with a critical exponent of -1. Numerical studies with chaotically driven maps reveal similar behavior to random driving cases and suggest the need for a systematic study of ‘‘chaotic walks.’’}}, 
pages = {1140--1150}, 
number = {2}, 
volume = {49}, 
keywords = {}
}
@article{saha2017extreme, 
year = {2017}, 
title = {{Extreme events in FitzHugh-Nagumo oscillators coupled with two time delays}}, 
author = {Saha, Arindam and Feudel, Ulrike}, 
journal = {Physical Review E}, 
issn = {2470-0045}, 
doi = {10.1103/physreve.95.062219}, 
pmid = {28709240}, 
eprint = {1703.08300}, 
abstract = {{We study two identical FitzHugh-Nagumo oscillators which are coupled with one or two different time delays. If only a single-delay coupling is used, the length of the delay determines whether the synchronization manifold is transversally stable or unstable, exhibiting mixed-mode or chaotic oscillations in which the small amplitude oscillations are always in phase but the large amplitude oscillations are in phase or out of phase, respectively. For two delays we find an intricate dynamics which comprises an irregular alteration of small amplitude oscillations, in-phase and out-of-phase large amplitude oscillations, also called extreme events. This transient chaotic dynamics is sandwiched between a bubbling transition and a blowout bifurcation.}}, 
pages = {062219}, 
number = {6}, 
volume = {95}, 
keywords = {}
}
@article{medeiros2018boundaries, 
year = {2018}, 
title = {{Boundaries of synchronization in oscillator networks}}, 
author = {Medeiros, Everton S. and Medrano-T, Rene O. and Caldas, Iberê L. and Feudel, Ulrike}, 
journal = {Physical Review E}, 
issn = {2470-0045}, 
doi = {10.1103/physreve.98.030201}, 
abstract = {{We analyze the final state sensitivity of nonlocal networks with respect to initial conditions of their units. By changing the initial conditions of a single network unit, we perturb an initially synchronized state. Depending on the perturbation strength, we observe the existence of two possible network long-term states: (i) The network neutralizes the perturbation effects and returns to its synchronized configuration. (ii) The perturbation leads the network to an alternative desynchronized state. By computing uncertainty exponents of a two-dimensional cross section of the state space, we find the existence of fractal basin boundaries separating synchronized solutions from desynchronized ones. We attribute these features to an unstable chaotic set in which trajectories persist for times indefinitely long in the network.}}, 
pages = {030201}, 
number = {3}, 
volume = {98}, 
keywords = {}
}
@article{hong2006anomalous, 
year = {2006}, 
title = {{Anomalous Binder Cumulant and Lack of Self-Averageness in Systems with Quenched Disorder}}, 
author = {Hong, Hyunsuk and Park, Hyunggyu and Tang, Lei-Han}, 
journal = {Journal of the Korean Physical Society}, 
abstract = {{The Binder cumulant (BC) has been widely used for locating the phase transition point accurately in systems with thermal noise. In systems with quenched disorder, the BC may show subtle finite-size effects due to large sample-to-sample fluctuations. We study the globally coupled Kuramoto model of interacting limit-cycle oscillators with random natural frequencies and find an anomalous dip in the BC near the transition. We show that the dip is related to non-self-averageness of the order parameter at the transition. Alternative definitions of the BC, which do not show any anomalous behavior regardless of the existence of non-self-averageness, are proposed.}}, 
pages = {L1885--L1889}, 
number = {5}, 
volume = {49}, 
keywords = {}
}
@article{hindmarshmodel1984, 
year = {1984}, 
title = {{A model of neuronal bursting using three coupled first order differential equations}}, 
author = {Hindmarsh, J. L. and Rose, R. M.}, 
journal = {Proceedings of the Royal Society of London. Series B. Biological Sciences}, 
issn = {0080-4649}, 
doi = {10.1098/rspb.1984.0024}, 
pmid = {6144106}, 
abstract = {{We describe a modification to our recent model of the action potential which introduces two additional equilibrium points. By using stability analysis we show that one of these equilibrium points is a saddle point from which there are two separatrices which divide the phase plane into two regions. In one region all phase paths approach a limit cycle and in the other all phase paths approach a stable equilibrium point. A consequence of this is that a short depolarizing current pulse will change an initially silent model neuron into one that fires repetitively. Addition of a third equation limits this firing to either an isolated burst or a depolarizing afterpotential. When steady depolarizing current was applied to this model it resulted in periodic bursting. The equations, which were initially developed to explain isolated triggered bursts, therefore provide one of the simplest models of the more general phenomenon of oscillatory burst discharge.}}, 
pages = {87--102}, 
number = {1222}, 
volume = {221}, 
keywords = {}
}
@article{Ashwin.1998, 
year = {1998}, 
title = {{On the unfolding of a blowout bifurcation}}, 
author = {Ashwin, Peter and Aston, Philip J. and Nicol, Matthew}, 
journal = {Physica D: Nonlinear Phenomena}, 
issn = {0167-2789}, 
doi = {10.1016/s0167-2789(97)80006-1}, 
abstract = {{Suppose a chaotic attractor A in an invariant subspace loses stability on varying a parameter. At the point of loss of stability, the most positive Lyapunov exponent of the natural measure on A crosses zero at what has been called a ‘blowout’ bifurcation.We introduce the notion of an essential basin of an attractor A. This is the set of points x such that accumulation points of the sequence of measures 1n∑n − 1k = 0δfk(x) are supported on A. We characterise supercritical and subcritical scenarios according to whether the Lebesgue measure of the essential basin of A is positive or zero.We study a drift-diffusion model and a model class of piecewise linear mappings of the plane. In the supercritical case, we find examples where a Lyapunov exponent of the branch of attractors may be positive (‘hyperchaos’) or negative, depending purely on the dynamics far from the invariant subspace. For the mappings we find asymptotically linear scaling of Lyapunov exponents, average distance from the subspace and basin size on varying a parameter. We conjecture that these are general characteristics of blowout bifurcations.}}, 
pages = {81--95}, 
number = {1-4}, 
volume = {111}, 
keywords = {}
}
@article{townsend2020dense, 
year = {2020}, 
title = {{Dense networks that do not synchronize and sparse ones that do}}, 
author = {Townsend, Alex and Stillman, Michael and Strogatz, Steven H.}, 
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science}, 
issn = {1054-1500}, 
doi = {10.1063/5.0018322}, 
pmid = {32872810}, 
abstract = {{Consider any network of n identical Kuramoto oscillators in which each oscillator is coupled bidirectionally with unit strength to at least μ ( n − 1 ) other oscillators. Then, there is a critical value of μ above which the system is guaranteed to converge to the in-phase synchronous state for almost all initial conditions. The precise value of μ remains unknown. In 2018, Ling, Xu, and Bandeira proved that if each oscillator is coupled to at least 79.29\% of all the others, global synchrony is ensured. In 2019, Lu and Steinerberger improved this bound to 78.89\%. Here, we find clues that the critical connectivity may be exactly 75\%. Our methods yield a slight improvement on the best known lower bound on the critical connectivity from 68.18 \% to 68.28 \%. We also consider the opposite end of the connectivity spectrum, where the networks are sparse rather than dense. In this regime, we ask how few edges one needs to add to a ring of n oscillators to turn it into a globally synchronizing network. We prove a partial result: all the twisted states in a ring of size n = 2 m can be destabilized by adding just O ( n log 2 ⁡ n ) edges. To finish the proof, one needs to rule out all other candidate attractors. We have done this for n ≤ 8 but the problem remains open for larger n. Thus, even for systems as simple as Kuramoto oscillators, much remains to be learned about dense networks that do not globally synchronize and sparse ones that do.}}, 
pages = {083142}, 
number = {8}, 
volume = {30}, 
keywords = {}
}
@article{strogatz2000from, 
year = {2000}, 
title = {{From Kuramoto to Crawford: exploring the onset of synchronization in populations of coupled oscillators}}, 
author = {Strogatz, Steven H.}, 
journal = {Physica D: Nonlinear Phenomena}, 
issn = {0167-2789}, 
doi = {10.1016/s0167-2789(00)00094-4}, 
abstract = {{The Kuramoto model describes a large population of coupled limit-cycle oscillators whose natural frequencies are drawn from some prescribed distribution. If the coupling strength exceeds a certain threshold, the system exhibits a phase transition: some of the oscillators spontaneously synchronize, while others remain incoherent. The mathematical analysis of this bifurcation has proved both problematic and fascinating. We review 25 years of research on the Kuramoto model, highlighting the false turns as well as the successes, but mainly following the trail leading from Kuramoto’s work to Crawford’s recent contributions. It is a lovely winding road, with excursions through mathematical biology, statistical physics, kinetic theory, bifurcation theory, and plasma physics.}}, 
pages = {1--20}, 
number = {1-4}, 
volume = {143}, 
keywords = {}
}
@article{rogers1996phasetransitions, 
year = {1996}, 
title = {{Phase transitions in nonlinear oscillator chains}}, 
author = {Rogers, Jeffrey L. and Wille, Luc T.}, 
journal = {Physical Review E}, 
issn = {1539-3755}, 
doi = {10.1103/physreve.54.r2193}, 
pmid = {9965439}, 
abstract = {{It is shown numerically that a one-dimensional system of coupled disparate nonlinear oscillators undergoes a phase transition from a synchronized to a desynchronized state as the range of interactions is decreased. Using a coupling that decreases with distance as r-α, the functional dependence of the critical coupling exponent on the coupling constant αc(K) is mapped out and the nature of the transition is discussed. Previously studied models and results are recovered in the appropriate limits of the coupling exponent.}}, 
pages = {R2193--R2196}, 
number = {3}, 
volume = {54}, 
keywords = {}
}
@article{hong2007finitesizescaling, 
year = {2007}, 
title = {{Finite-Size Scaling in Complex Networks}}, 
author = {Hong, Hyunsuk and Ha, Meesoon and Park, Hyunggyu}, 
journal = {Physical Review Letters}, 
issn = {0031-9007}, 
doi = {10.1103/physrevlett.98.258701}, 
pmid = {17678061}, 
abstract = {{A finite-size-scaling (FSS) theory is proposed for various models in complex networks. In particular, we focus on the FSS exponent, which plays a crucial role in analyzing numerical data for finite-size systems. Based on the droplet-excitation (hyperscaling) argument, we conjecture the values of the FSS exponents for the Ising model, the susceptible-infected-susceptible model, and the contact process, all of which are confirmed reasonably well in numerical simulations.}}, 
pages = {258701}, 
number = {25}, 
volume = {98}, 
keywords = {}
}
@article{wiseman1998finite, 
year = {1998}, 
title = {{Finite-Size Scaling and Lack of Self-Averaging in Critical Disordered Systems}}, 
author = {Wiseman, Shai and Domany, Eytan}, 
journal = {Physical Review Letters}, 
issn = {0031-9007}, 
doi = {10.1103/physrevlett.81.22}, 
abstract = {{We simulated site dilute Ising models in d=3 dimensions for several lattice sizes L. For each L singular thermodynamic quantities X were measured at criticality and their distributions P(X) were determined for ensembles of several thousand random samples. For L→∞ the relative width of P(X) tends to a universal constant: there is no self-averaging. The width of the distribution of the sample (i) dependent pseudocritical temperatures Tc(i,L) scales as δTc(L)∼L-1/ν and not as ∼L-d/2. The sample dependence of Xi(T,L) enters dominantly, but not exclusively, via Tc(i,L).}}, 
pages = {22--25}, 
number = {1}, 
volume = {81}, 
keywords = {}
}
@article{Ansmann.2013, 
year = {2013}, 
title = {{Extreme events in excitable systems and mechanisms of their generation}}, 
author = {Ansmann, Gerrit and Karnatak, Rajat and Lehnertz, Klaus and Feudel, Ulrike}, 
journal = {Physical Review E}, 
issn = {1539-3755}, 
doi = {10.1103/physreve.88.052911}, 
pmid = {24329335}, 
eprint = {1311.5776}, 
abstract = {{We study deterministic systems, composed of excitable units of FitzHugh–Nagumo type, that are capable of self-generating and self-terminating strong deviations from their regular dynamics without the influence of noise or parameter change. These deviations are rare, short-lasting, and recurrent and can therefore be regarded as extreme events. Employing a range of methods we analyze dynamical properties of the systems, identifying features in the systems’ dynamics that may qualify as precursors to extreme events. We investigate these features and elucidate mechanisms that may be responsible for the generation of the extreme events.}}, 
pages = {052911}, 
number = {5}, 
volume = {88}, 
keywords = {}
}
@article{medvedev2014small, 
year = {2014}, 
title = {{Small-world networks of Kuramoto oscillators}}, 
author = {Medvedev, Georgi S.}, 
journal = {Physica D: Nonlinear Phenomena}, 
issn = {0167-2789}, 
doi = {10.1016/j.physd.2013.09.008}, 
abstract = {{The Kuramoto model of coupled phase oscillators on small-world (SW) graphs is analyzed in this work. When the number of oscillators in the network goes to infinity, the model acquires a family of steady state solutions of degree q, called q-twisted states. We show that this class of solutions plays an important role in the formation of spatial patterns in the Kuramoto model on SW graphs. In particular, the analysis of q-twisted states elucidates the role of long-range random connections in shaping the attractors in this model.We develop two complementary approaches for studying q-twisted states in the coupled oscillator model on SW graphs: linear stability analysis and numerical continuation. The former approach shows that long-range random connections in the SW graphs promote synchronization and yields the estimate of the synchronization rate as a function of the SW randomization parameter. The continuation shows that the increase of the long-range connections results in patterns consisting of one or several plateaus separated by sharp interfaces.These results elucidate the pattern formation mechanisms in nonlocally coupled dynamical systems on random graphs.}}, 
pages = {13--22}, 
volume = {266}, 
keywords = {}
}
@article{wiley2006the, 
year = {2006}, 
title = {{The size of the sync basin}}, 
author = {Wiley, Daniel A. and Strogatz, Steven H. and Girvan, Michelle}, 
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science}, 
issn = {1054-1500}, 
doi = {10.1063/1.2165594}, 
pmid = {16599769}, 
abstract = {{We suggest a new line of research that we hope will appeal to the nonlinear dynamics community, especially the readers of this Focus Issue. Consider a network of identical oscillators. Suppose the synchronous state is locally stable but not globally stable; it competes with other attractors for the available phase space. How likely is the system to synchronize, starting from a random initial condition? And how does the probability of synchronization depend on the way the network is connected? On the one hand, such questions are inherently difficult because they require calculation of a global geometric quantity, the size of the “sync basin” (or, more formally, the measure of the basin of attraction for the synchronous state). On the other hand, these questions are wide open, important in many real-world settings, and approachable by numerical experiments on various combinations of dynamical systems and network topologies. To give a case study in this direction, we report results on the sync basin for a ring of n⪢1 identical phase oscillators with sinusoidal coupling. Each oscillator interacts equally with its k nearest neighbors on either side. For k∕n greater than a critical value (approximately 0.34, obtained analytically), we show that the sync basin is the whole phase space, except for a set of measure zero. As k∕n passes below this critical value, coexisting attractors are born in a well-defined sequence. These take the form of uniformly twisted waves, each characterized by an integer winding number q, the number of complete phase twists in one circuit around the ring. The maximum stable twist is proportional to n∕k; the constant of proportionality is also obtained analytically. For large values of n∕k, corresponding to large rings or short-range coupling, many different twisted states compete for their share of phase space. Our simulations reveal that their basin sizes obey a tantalizingly simple statistical law: the probability that the final state has q twists follows a Gaussian distribution with respect to q. Furthermore, as n∕k increases, the standard deviation of this distribution grows linearly with n∕k. We have been unable to explain either of these last two results by anything beyond a hand-waving argument.}}, 
pages = {015103}, 
number = {1}, 
volume = {16}, 
keywords = {}
}
@article{binder1987finite, 
year = {1987}, 
title = {{Finite size effects on phase transitions}}, 
author = {Binder, K.}, 
journal = {Ferroelectrics}, 
issn = {0015-0193}, 
doi = {10.1080/00150198708227908}, 
abstract = {{Both first- and second-order transitions get smeared and shifted due to the finite size of a sample. Recent theoretical developments on this finite size rounding of singularities associated with phase transitions are briefly reviewed, and evidence from Monte Carlo simulations for the validity of these concepts will be discussed. It is also shown how finite size scaling theories in conjunction with simulation data from finite systems are a powerful tool for the quantitative study of bulk critical phenomena. We shall also mention extensions such as finite size tests of hyperscaling, finite size scaling of interfacial properties, finite size effects on critical relaxation, etc. A brief discussion of the experimental situation concludes this review.}}, 
pages = {43--67}, 
number = {1}, 
volume = {73}, 
keywords = {}
}
@article{strogatz1988phase, 
year = {1988}, 
title = {{Phase-locking and critical phenomena in lattices of coupled nonlinear oscillators with random intrinsic frequencies}}, 
author = {Strogatz, Steven H. and Mirollo, Renato E.}, 
journal = {Physica D: Nonlinear Phenomena}, 
issn = {0167-2789}, 
doi = {10.1016/0167-2789(88)90074-7}, 
abstract = {{We study phase-locking in a network of coupled nonlinear oscillators with local interactions and random intrinsic frequencies. The oscillators are located at the vertices of a graph and interact along the edges. They are coupled by sinusoidal functions of the phase differences across the edges, and their intrinsic frequencies are independent and identically distributed with finite mean and variance.We derive an exact expression for the probability of phase-locking in a linear chain of such oscillators and prove that this probability tends to zero as the number of oscillators grows without bound. However, if the coupling strength increases as the square root of the number of oscillators, the probability of phase-locking tends to a limiting distribution, the Kolmogorov-Smirnov distribution. This latter result is obtained by showing that the phase-locking problem is equivalent to a discretization of pinned Brownian motion.The results on chains of oscillators are extended to more general graphs. In particular, for a hypercubic lattice of any dimension, the probability of phase-locking tends to zero exponentially fast as the number of oscillators grows without bound. We also consider a less stringent type of synchronization, characterized by large clusters of oscillators mutually entrained at the same average frequency. It is shown that if such clusters exist, they necessarily have a sponge-like geometry.}}, 
pages = {143--168}, 
number = {2}, 
volume = {31}, 
keywords = {}
}
@article{motter2005enhancing, 
year = {2005}, 
title = {{Enhancing complex-network synchronization}}, 
author = {Motter, A. E. and Zhou, C. S. and Kurths, J.}, 
journal = {Europhysics Letters}, 
issn = {0295-5075}, 
doi = {10.1209/epl/i2004-10365-4}, 
eprint = {cond-mat/0406207}, 
abstract = {{Heterogeneity in the degree (connectivity) distribution has been shown to suppress synchronization in networks of symmetrically coupled oscillators with uniform coupling strength (unweighted coupling). Here we uncover a condition for enhanced synchronization in weighted networks with asymmetric coupling. We show that, in the optimum regime, synchronizability is solely determined by the average degree and does not depend on the system size and the details of the degree distribution. In scale-free networks, where the average degree may increase with heterogeneity, synchronizability is drastically enhanced and may become positively correlated with heterogeneity, while the overall cost involved in the network coupling is significantly reduced as compared to the case of unweighted coupling.}}, 
pages = {334--340}, 
number = {3}, 
volume = {69}, 
keywords = {}
}
@article{fonollosa2015learning, 
year = {2015}, 
title = {{Learning of Chunking Sequences in Cognition and Behavior}}, 
author = {Fonollosa, Jordi and Neftci, Emre and Rabinovich, Mikhail}, 
journal = {PLOS Computational Biology}, 
issn = {1553-734X}, 
doi = {10.1371/journal.pcbi.1004592}, 
pmid = {26584306}, 
pmcid = {PMC4652905}, 
abstract = {{We often learn and recall long sequences in smaller segments, such as a phone number 858 534 22 30 memorized as four segments. Behavioral experiments suggest that humans and some animals employ this strategy of breaking down cognitive or behavioral sequences into chunks in a wide variety of tasks, but the dynamical principles of how this is achieved remains unknown. Here, we study the temporal dynamics of chunking for learning cognitive sequences in a chunking representation using a dynamical model of competing modes arranged to evoke hierarchical Winnerless Competition (WLC) dynamics. Sequential memory is represented as trajectories along a chain of metastable fixed points at each level of the hierarchy, and bistable Hebbian dynamics enables the learning of such trajectories in an unsupervised fashion. Using computer simulations, we demonstrate the learning of a chunking representation of sequences and their robust recall. During learning, the dynamics associates a set of modes to each information-carrying item in the sequence and encodes their relative order. During recall, hierarchical WLC guarantees the robustness of the sequence order when the sequence is not too long. The resulting patterns of activities share several features observed in behavioral experiments, such as the pauses between boundaries of chunks, their size and their duration. Failures in learning chunking sequences provide new insights into the dynamical causes of neurological disorders such as Parkinson’s disease and Schizophrenia.}}, 
pages = {e1004592}, 
number = {11}, 
volume = {11}, 
keywords = {}
}
@book{pikovsky2001synchronization, 
year = {2001}, 
title = {{Synchronization: A Universal Concept in Nonlinear Science}}, 
author = {Pikovsky, Arkady and Rosenblum, Michael and Kurths, Jürgen}, 
volume = {70}, 
publisher = {Cambridge University Press}, 
keywords = {}, 
doi = {10.1119/1.1475332}
}
@article{skardal2014optimal, 
year = {2014}, 
keywords = {Kuramoto,Optimization,Phase oscillators,Synchronization}, 
title = {{Optimal Synchronization of Complex Networks}}, 
author = {Skardal, Per Sebastian and Taylor, Dane and Sun, Jie}, 
journal = {Physical Review Letters}, 
issn = {0031-9007}, 
doi = {10.1103/physrevlett.113.144101}, 
pmid = {25325646}, 
abstract = {{We study optimal synchronization in networks of heterogeneous phase oscillators. Our main result is the derivation of a synchrony alignment function that encodes the interplay between network structure and oscillators’ frequencies and that can be readily optimized. We highlight its utility in two general problems: constrained frequency allocation and network design. In general, we find that synchronization is promoted by strong alignments between frequencies and the dominant Laplacian eigenvectors, as well as a matching between the heterogeneity of frequencies and network structure.}}, 
pages = {144101}, 
number = {14}, 
volume = {113}
}
@article{taylor2016synchronization, 
year = {2016}, 
title = {{Synchronization of Heterogeneous Oscillators Under Network Modifications: Perturbation and Optimization of the Synchrony Alignment Function}}, 
author = {Taylor, Dane and Skardal, Per Sebastian and Sun, Jie}, 
journal = {SIAM Journal on Applied Mathematics}, 
issn = {0036-1399}, 
doi = {10.1137/16m1075181}, 
pmid = {27872501}, 
eprint = {1605.04009}, 
abstract = {{Synchronization is central to many complex systems in engineering physics (e.g., the power grid, Josephson junction circuits, and electrochemical oscillators) and biology (e.g., neuronal, circadian, and cardiac rhythms). Despite these widespread applications---for which proper functionality depends sensitively on the extent of synchronization---there remains a lack of understanding for how systems can best evolve and adapt to enhance or inhibit synchronization. We study how network modifications affect the synchronization properties of network-coupled dynamical systems that have heterogeneous node dynamics (e.g., phase oscillators with nonidentical frequencies), which is often the case for real-world systems. Our approach relies on a synchrony alignment function (SAF) that quantifies the interplay between heterogeneity of the network and of the oscillators and provides an objective measure for a system's ability to synchronize. We conduct a spectral perturbation analysis of the SAF for structural network modifications including the addition and removal of edges, which subsequently ranks the edges according to their importance to synchronization. Based on this analysis, we develop gradient-descent algorithms to efficiently solve optimization problems that aim to maximize phase synchronization via network modifications. We support these and other results with numerical experiments.}}, 
pages = {1984--2008}, 
number = {5}, 
volume = {76}, 
keywords = {}
}
@article{Cabral.2022, 
year = {2022}, 
keywords = {Metastability}, 
title = {{Synchronization in the connectome: Metastable oscillatory modes emerge from interactions in the brain spacetime network}}, 
author = {Cabral, Joana and Castaldo, Francesca and Vohryzek, Jakub and Litvak, Vladimir and Bick, Christian and Lambiotte, Renaud and Friston, Karl and Kringelbach, Morten L. and Deco, Gustavo}, 
journal = {bioRxiv}, 
doi = {10.1101/2022.01.06.475196}, 
abstract = {{A rich repertoire of oscillatory signals is detected from human brains with electro- and magnetoencephalography (EEG/MEG). However, the principles underwriting coherent oscillations and their link with neural activity remain unclear. Here, we hypothesise that the emergence of transient brain rhythms is a signature of weakly stable synchronization between spatially distributed brain areas, occurring at network-specific collective frequencies due to non-negligible conduction times. We test this hypothesis using a phenomenological network model to simulate interactions between neural mass potentials (resonating at 40Hz) in the structural connectome. Crucially, we identify a critical regime where metastable oscillatory modes emerge spontaneously in the delta (0.5-4Hz), theta (4-8Hz), alpha (8-13Hz) and beta (13-30Hz) frequency bands from weak synchronization of subsystems, closely approximating the MEG power spectra from 89 healthy individuals. Grounded in the physics of delay-coupled oscillators, these numerical analyses demonstrate the role of the spatiotemporal connectome in structuring brain activity in the frequency domain.}}, 
pages = {2022.01.06.475196}
}
@article{boaretto2021discriminating, 
year = {2021}, 
title = {{Discriminating chaotic and stochastic time series using permutation entropy and artificial neural networks}}, 
author = {Boaretto, B. R. R. and Budzinski, R. C. and Rossi, K. L. and Prado, T. L. and Lopes, S. R. and Masoller, C.}, 
journal = {Scientific Reports}, 
doi = {10.1038/s41598-021-95231-z}, 
pmid = {34349134}, 
pmcid = {PMC8338970}, 
abstract = {{Extracting relevant properties of empirical signals generated by nonlinear, stochastic, and high-dimensional systems is a challenge of complex systems research. Open questions are how to differentiate chaotic signals from stochastic ones, and how to quantify nonlinear and/or high-order temporal correlations. Here we propose a new technique to reliably address both problems. Our approach follows two steps: first, we train an artificial neural network (ANN) with flicker (colored) noise to predict the value of the parameter, α, that determines the strength of the correlation of the noise. To predict α the ANN input features are a set of probabilities that are extracted from the time series by using symbolic ordinal analysis. Then, we input to the trained ANN the probabilities extracted from the time series of interest, and analyze the ANN output. We find that the α value returned by the ANN is informative of the temporal correlations present in the time series. To distinguish between stochastic and chaotic signals, we exploit the fact that the difference between the permutation entropy (PE) of a given time series and the PE of flicker noise with the same α parameter is small when the time series is stochastic, but it is large when the time series is chaotic. We validate our technique by analysing synthetic and empirical time series whose nature is well established. We also demonstrate the robustness of our approach with respect to the length of the time series and to the level of noise. We expect that our algorithm, which is freely available, will be very useful to the community.}}, 
pages = {15789}, 
number = {1}, 
volume = {11}, 
keywords = {}
}
@article{kuramoto1975self, 
year = {1975}, 
title = {{Self-entrainment of a population of coupled non-linear oscillators}}, 
author = {Kuramoto, Yoshiki}, 
journal = {International Symposium on Mathematical Problems in Theoretical Physics. Lecture Notes in Physics}, 
doi = {10.1007/bfb0013365}, 
editor = {Springer}, 
pages = {420--422}, 
volume = {39}, 
keywords = {}
}
@article{skardal2020higher, 
year = {2020}, 
title = {{Higher order interactions in complex networks of phase oscillators promote abrupt synchronization switching}}, 
author = {Skardal, Per Sebastian and Arenas, Alex}, 
journal = {Communications Physics}, 
doi = {10.1038/s42005-020-00485-0}, 
abstract = {{Synchronization processes play critical roles in the functionality of a wide range of both natural and man-made systems. Recent work in physics and neuroscience highlights the importance of higher-order interactions between dynamical units, i.e., three- and four-way interactions in addition to pairwise interactions, and their role in shaping collective behavior. Here we show that higher-order interactions between coupled phase oscillators, encoded microscopically in a simplicial complex, give rise to added nonlinearity in the macroscopic system dynamics that induces abrupt synchronization transitions via hysteresis and bistability of synchronized and incoherent states. Moreover, these higher-order interactions can stabilize strongly synchronized states even when the pairwise coupling is repulsive. These findings reveal a self-organized phenomenon that may be responsible for the rapid switching to synchronization in many biological and other systems that exhibit synchronization without the need of particular correlation mechanisms between the oscillators and the topological structure. While first order phase transitions between incoherence and synchronization are critical for collective behavior in various oscillator system application, e.g., the brain and power grids, such transitions typically require finely tuned properties. In this work the authors show that first order phase transitions and bistability can emerge naturally as a consequence of the presence of higher-order interactions between oscillators.}}, 
pages = {218}, 
number = {1}, 
volume = {3}, 
keywords = {}
}
@article{aeyels2004existence, 
year = {2004}, 
title = {{Existence of Partial Entrainment and Stability of Phase Locking Behavior of Coupled Oscillators}}, 
author = {Aeyels, Dirk and Rogge, Jonathan A.}, 
journal = {Progress of Theoretical Physics}, 
issn = {0033-068X}, 
doi = {10.1143/ptp.112.921}, 
abstract = {{We study a network of all-to-all interconnected phase oscillators as modeled by the Kuramoto model. For coupling strengths larger than a critical value, we show the existence of a collective behavior called phase locking: the phase differences between all oscillators are constant in time. As the coupling strength increases, the distance between each pair of phases decreases. Stability of each phase locking solution is proven for general frequency distributions. There exist one unique asymptotically stable phase locking solution. Furthermore a description is given of partial entrainment, which can be regarded as the finite number analogon of partial synchronization in the infinite number case. When the network is partially entraining some phase differences possess an upper and lower bound. Partial entrainment of the three-cell network is analyzed: an estimate of the onset of partial entrainment is given and the existence of partial entrainment is proven. Furthermore, local stability of partial entrainment is proven for the three-cell network with two identical oscillators.}}, 
pages = {921--942}, 
number = {6}, 
volume = {112}, 
keywords = {}
}
@article{omelchenko2013bifurcations, 
year = {2013}, 
title = {{Bifurcations in the Sakaguchi–Kuramoto model}}, 
author = {Omel’chenko, Oleh E. and Wolfrum, Matthias}, 
journal = {Physica D: Nonlinear Phenomena}, 
issn = {0167-2789}, 
doi = {10.1016/j.physd.2013.08.004}, 
abstract = {{We analyze the Sakaguchi–Kuramoto model of coupled phase oscillators in a continuum limit given by a frequency dependent version of the Ott–Antonsen system. Based on a self-consistency equation, we provide a detailed analysis of partially synchronized states, their bifurcation from the completely incoherent state and their stability properties. We use this method to analyze the bifurcations for various types of frequency distributions and explain the appearance of non-universal synchronization transitions.}}, 
pages = {74--85}, 
volume = {263}, 
keywords = {}
}
@article{tilles2011multistable, 
year = {2011}, 
title = {{Multistable behavior above synchronization in a locally coupled Kuramoto model}}, 
author = {Tilles, Paulo F. C. and Ferreira, Fernando F. and Cerdeira, Hilda A.}, 
journal = {Physical Review E}, 
issn = {1539-3755}, 
doi = {10.1103/physreve.83.066206}, 
pmid = {21797460}, 
abstract = {{A system of nearest neighbors Kuramoto-like coupled oscillators placed in a ring is studied above the critical synchronization transition. We find a richness of solutions when the coupling increases, which exists only within a solvability region (SR). We also find that the solutions possess different characteristics, depending on the section of the boundary of the SR where they appear. We study the birth of these solutions and how they evolve when the coupling strength increases, and determine the diagram of solutions in phase space.}}, 
pages = {066206}, 
number = {6}, 
volume = {83}, 
keywords = {}
}
@article{Datseris.2022, 
year = {2022}, 
title = {{Nonlinear Dynamics, A Concise Introduction Interlaced with Code}}, 
author = {Datseris, George and Parlitz, Ulrich}, 
journal = {Undergraduate Lecture Notes in Physics}, 
issn = {2192-4791}, 
doi = {10.1007/978-3-030-91032-7}, 
keywords = {}
}
@article{muller2021algebraic, 
year = {2021}, 
title = {{Algebraic approach to the Kuramoto model}}, 
author = {Muller, Lyle and Mináč, Ján and Nguyen, Tung T.}, 
journal = {Physical Review E}, 
issn = {2470-0045}, 
doi = {10.1103/physreve.104.l022201}, 
pmid = {34525516}, 
abstract = {{We study the Kuramoto model with attractive sine coupling. We introduce a complex-valued matrix formulation whose argument coincides with the original Kuramoto dynamics. We derive an exact solution for the complex-valued model, which permits analytical insight into individual realizations of the Kuramoto model. The existence of a complex-valued form of the Kuramoto model provides a key demonstration that, in some cases, reformulations of nonlinear dynamics in higher-order number fields may provide tractable analytical approaches.}}, 
pages = {L022201}, 
number = {2}, 
volume = {104}, 
keywords = {}
}
@article{witthaut2022collective, 
year = {2022}, 
title = {{Collective nonlinear dynamics and self-organization in decentralized power grids}}, 
author = {Witthaut, Dirk and Hellmann, Frank and Kurths, Jürgen and Kettemann, Stefan and Meyer-Ortmanns, Hildegard and Timme, Marc}, 
journal = {Reviews of Modern Physics}, 
issn = {0034-6861}, 
doi = {10.1103/revmodphys.94.015005}, 
abstract = {{The ongoing transition to renewable energy supply comes with a restructuring of power grids, changing their effective interaction topologies, more and more strongly decentralizing them and substantially modifying their input, output, and response characteristics. All of these changes imply that power grids become increasingly affected by collective, nonlinear dynamic phenomena, structurally and dynamically more distributed and less predictable in space and time, more heterogeneous in its building blocks, and as a consequence less centrally controllable. Here cornerstone aspects of data-driven and mathematical modeling of collective dynamical phenomena emerging in real and model power grid networks by combining theories from nonlinear dynamics, stochastic processes and statistical physics, anomalous statistics, optimization, and graph theory are reviewed. The mathematical background required for adequate modeling and analysis approaches is introduced, an overview of power system models is given, and a range of collective dynamical phenomena are focused on, including synchronization and phase locking, flow (re)routing, Braess’s paradox, geometric frustration, and spreading and localization of perturbations and cascading failures, as well as the nonequilibrium dynamics of power grids, where fluctuations play a pivotal role.}}, 
pages = {015005}, 
number = {1}, 
volume = {94}, 
keywords = {}
}
@article{undefined, 
year = {2022}, 
title = {{Neural mechanisms underlying the temporal organization of naturalistic animal behavior}}, 
author = {Mazzucato, Luca}, 
journal = {arXiv}, 
eprint = {2203.02151}, 
abstract = {{Naturalistic animal behavior exhibits a strikingly complex organization in the temporal domain, whose variability stems from at least three sources: hierarchical, contextual, and stochastic. What are the neural mechanisms and computational principles generating such complex temporal features? In this review, we provide a critical assessment of the existing behavioral and neurophysiological evidence for these sources of temporal variability in naturalistic behavior. We crystallize recent studies which converge on an emergent mechanistic theory of temporal variability based on attractor neural networks and metastable dynamics, arising from the coordinated interactions between mesoscopic neural circuits. We highlight the crucial role played by structural heterogeneities and by noise arising in mesoscopic circuits. We assess the shortcomings and missing links in the current theoretical and experimental literature and propose new directions of investigations to fill these gaps.}}, 
keywords = {}
}
@article{rackauckas2016differential, 
year = {2016}, 
title = {{DifferentialEquations.jl – A Performant and Feature-Rich Ecosystem for Solving Differential Equations in Julia}}, 
author = {Rackauckas, Christopher and Nie, Qing}, 
journal = {Journal of Open Research Software}, 
issn = {2049-9647}, 
doi = {10.5334/jors.151}, 
abstract = {{DifferentialEquations.jl is a package for solving differential equations in Julia. It covers discrete equations (function maps, discrete stochastic (Gillespie/Markov) simulations), ordinary differential equations, stochastic differential equations, algebraic differential equations, delay differential equations, hybrid differential equations, jump diffusions, and (stochastic) partial differential equations. Through extensive use of multiple dispatch, metaprogramming, plot recipes, foreign function interfaces (FFI), and call-overloading, DifferentialEquations.jl offers a unified user interface to solve and analyze various forms of differential equations while not sacrificing features or performance. Many modern features are integrated into the solvers, such as allowing arbitrary user-defined number systems for high-precision and arithmetic with physical units, built-in multithreading and parallelism, and symbolic calculation of Jacobians. Integrated into the package is an algorithm testing and benchmarking suite to both ensure accuracy and serve as an easy way for researchers to develop and distribute their own methods. Together, these features build a highly extendable suite which is feature-rich and highly performant.Funding statement: This work was partially supported by NIH grants P50GM76516 and R01GM107264 and NSF grants DMS1562176 and DMS1161621. This material is based upon work supported by the National Science Foundation Graduate Research Fellowship under Grant No. DGE-1321846, the National Academies of Science, Engineering, and Medicine via the Ford Foundation, and the National Institutes of Health Award T32 EB009418. Its contents are solely the responsibility of the authors and do not necessarily represent the official views of the NIH.}}, 
pages = {15}, 
number = {1}, 
volume = {5}, 
keywords = {}
}
@article{datseris2020drwatson, 
year = {2020}, 
title = {{DrWatson: the perfect sidekick for your scientific inquiries}}, 
author = {Datseris, George and Isensee, Jonas and Pech, Sebastian and Gál, Tamás}, 
journal = {Journal of Open Source Software}, 
doi = {10.21105/joss.02673}, 
pages = {2673}, 
number = {54}, 
volume = {5}, 
keywords = {}
}
@article{datseris2022effortless, 
year = {2022}, 
title = {{Effortless estimation of basins of attraction}}, 
author = {Datseris, George and Wagemakers, Alexandre}, 
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science}, 
issn = {1054-1500}, 
doi = {10.1063/5.0076568}, 
pmid = {35232033}, 
eprint = {2110.04358}, 
abstract = {{We present a fully automated method that identifies attractors and their basins of attraction without approximations of the dynamics. The method works by defining a finite state machine on top of the dynamical system flow. The input to the method is a dynamical system evolution rule and a grid that partitions the state space. No prior knowledge of the number, location, or nature of the attractors is required. The method works for arbitrarily high-dimensional dynamical systems, both discrete and continuous. It also works for stroboscopic maps, Poincaré maps, and projections of high-dimensional dynamics to a lower-dimensional space. The method is accompanied by a performant open-source implementation in the DynamicalSystems.jl library. The performance of the method outclasses the naïve approach of evolving initial conditions until convergence to an attractor, even when excluding the task of first identifying the attractors from the comparison. We showcase the power of our implementation on several scenarios, including interlaced chaotic attractors, high-dimensional state spaces, fractal basin boundaries, and interlaced attracting periodic orbits, among others. The output of our method can be straightforwardly used to calculate concepts, such as basin stability and final state sensitivity.}}, 
pages = {023104}, 
number = {2}, 
volume = {32}, 
keywords = {}
}
@article{mitra2017multiple, 
year = {2017}, 
title = {{Multiple-node basin stability in complex dynamical networks}}, 
author = {Mitra, Chiranjit and Choudhary, Anshul and Sinha, Sudeshna and Kurths, Jürgen and Donner, Reik V.}, 
journal = {Physical Review E}, 
issn = {2470-0045}, 
doi = {10.1103/physreve.95.032317}, 
pmid = {28415192}, 
eprint = {1612.06015}, 
abstract = {{Dynamical entities interacting with each other on complex networks often exhibit multistability. The stability of a desired steady regime (e.g., a synchronized state) to large perturbations is critical in the operation of many real-world networked dynamical systems such as ecosystems, power grids, the human brain, etc. This necessitates the development of appropriate quantifiers of stability of multiple stable states of such systems. Motivated by the concept of basin stability (BS) [P. J. Menck , Nat. Phys. 9, 89 (2013)1745-247310.1038/nphys2516], we propose here the general framework of multiple-node basin stability for gauging the global stability and robustness of networked dynamical systems in response to nonlocal perturbations simultaneously affecting multiple nodes of a system. The framework of multiple-node BS provides an estimate of the critical number of nodes that, when simultaneously perturbed, significantly reduce the capacity of the system to return to the desired stable state. Further, this methodology can be applied to estimate the minimum number of nodes of the network to be controlled or safeguarded from external perturbations to ensure proper operation of the system. Multiple-node BS can also be utilized for probing the influence of spatially localized perturbations or targeted attacks to specific parts of a network. We demonstrate the potential of multiple-node BS in assessing the stability of the synchronized state in a deterministic scale-free network of Rössler oscillators and a conceptual model of the power grid of the United Kingdom with second-order Kuramoto-type nodal dynamics.}}, 
pages = {032317}, 
number = {3}, 
volume = {95}, 
keywords = {}
}
@article{10.1371/journal.pcbi.1003641, 
year = {2014}, 
title = {{A Signature of Attractor Dynamics in the CA3 Region of the Hippocampus}}, 
author = {Rennó-Costa, César and Lisman, John E. and Verschure, Paul F. M. J.}, 
journal = {PLoS Computational Biology}, 
issn = {1553-734X}, 
doi = {10.1371/journal.pcbi.1003641}, 
pmid = {24854425}, 
pmcid = {PMC4031055}, 
abstract = {{The notion of attractor networks is the leading hypothesis for how associative memories are stored and recalled. A defining anatomical feature of such networks is excitatory recurrent connections. These “attract” the firing pattern of the network to a stored pattern, even when the external input is incomplete (pattern completion). The CA3 region of the hippocampus has been postulated to be such an attractor network; however, the experimental evidence has been ambiguous, leading to the suggestion that CA3 is not an attractor network. In order to resolve this controversy and to better understand how CA3 functions, we simulated CA3 and its input structures. In our simulation, we could reproduce critical experimental results and establish the criteria for identifying attractor properties. Notably, under conditions in which there is continuous input, the output should be “attracted” to a stored pattern. However, contrary to previous expectations, as a pattern is gradually “morphed” from one stored pattern to another, a sharp transition between output patterns is not expected. The observed firing patterns of CA3 meet these criteria and can be quantitatively accounted for by our model. Notably, as morphing proceeds, the activity pattern in the dentate gyrus changes; in contrast, the activity pattern in the downstream CA3 network is attracted to a stored pattern and thus undergoes little change. We furthermore show that other aspects of the observed firing patterns can be explained by learning that occurs during behavioral testing. The CA3 thus displays both the learning and recall signatures of an attractor network. These observations, taken together with existing anatomical and behavioral evidence, make the strong case that CA3 constructs associative memories based on attractor dynamics.}}, 
pages = {e1003641}, 
number = {5}, 
volume = {10}, 
keywords = {}
}
@article{10.1146/annurev-neuro-062111-150351, 
year = {2012}, 
title = {{Attractor Dynamics of Spatially Correlated Neural Activity in the Limbic System}}, 
author = {Knierim, James J. and Zhang, Kechen}, 
journal = {Annual Review of Neuroscience}, 
issn = {0147-006x}, 
doi = {10.1146/annurev-neuro-062111-150351}, 
pmid = {22462545}, 
abstract = {{Attractor networks are a popular computational construct used to model different brain systems. These networks allow elegant computations that are thought to represent a number of aspects of brain function. Although there is good reason to believe that the brain displays attractor dynamics, it has proven difficult to test experimentally whether any particular attractor architecture resides in any particular brain circuit. We review models and experimental evidence for three systems in the rat brain that are presumed to be components of the rat's navigational and memory system. Head-direction cells have been modeled as a ring attractor, grid cells as a plane attractor, and place cells both as a plane attractor and as a point attractor. Whereas the models have proven to be extremely useful conceptual tools, the experimental evidence in their favor, although intriguing, is still mostly circumstantial.}}, 
pages = {267--285}, 
number = {1}, 
volume = {35}, 
keywords = {}
}
@article{ashwin2005when, 
year = {2005}, 
title = {{When instability makes sense}}, 
author = {Ashwin, Peter and Timme, Marc}, 
journal = {Nature}, 
issn = {0028-0836}, 
doi = {10.1038/436036b}, 
pmid = {16001052}, 
abstract = {{Mathematical models that use instabilities to describe changes of weather patterns or spacecraft trajectories are well established. Could such principles apply to the sense of smell, and to other aspects of neural computation?}}, 
pages = {36--37}, 
number = {7047}, 
volume = {436}, 
keywords = {}
}
@book{sornette2006critical, 
year = {2006}, 
title = {{Critical Phenomena in Natural Sciences, Chaos, Fractals, Selforganization and Disorder: Concepts and Tools}}, 
author = {Sornette, Didier}, 
isbn = {9783540308829}, 
series = {Springer Series in Synergetics}, 
keywords = {}, 
doi = {10.1007/3-540-33182-4}
}
@book{brankov2000theory, 
year = {2000}, 
title = {{Theory of Critical Phenomena in Finite-Size Systems}}, 
author = {Brankov, Jordan G and Danchev, Daniel M and Tonchev, Nicholai S}, 
isbn = {9789810239251}, 
publisher = {World Scientific}, 
keywords = {}, 
doi = {10.1142/9789812813435\_0006}
}
@article{10.1080/00107514.2015.1094987, 
year = {2015}, 
title = {{Phase reduction approach to synchronisation of nonlinear oscillators}}, 
author = {Nakao, Hiroya}, 
journal = {Contemporary Physics}, 
issn = {0010-7514}, 
doi = {10.1080/00107514.2015.1094987}, 
eprint = {1704.03293}, 
abstract = {{Systems of dynamical elements exhibiting spontaneous rhythms are found in various fields of science and engineering, including physics, chemistry, biology, physiology, and mechanical and electrical engineering. Such dynamical elements are often modelled as nonlinear limit-cycle oscillators. In this article, we briefly review phase reduction theory, which is a simple and powerful method for analysing the synchronisation properties of limit-cycle oscillators exhibiting rhythmic dynamics. Through phase reduction theory, we can systematically simplify the nonlinear multi-dimensional differential equations describing a limit-cycle oscillator to a one-dimensional phase equation, which is much easier to analyse. Classical applications of this theory, i.e. the phase locking of an oscillator to a periodic external forcing and the mutual synchronisation of interacting oscillators, are explained. Further, more recent applications of this theory to the synchronisation of non-interacting oscillators induced by common noise and the dynamics of coupled oscillators on complex networks are discussed. We also comment on some recent advances in phase reduction theory for noise-driven oscillators and rhythmic spatiotemporal patterns.}}, 
pages = {188--214}, 
number = {2}, 
volume = {57}, 
keywords = {}
}
@article{kuramoto2019on, 
year = {2019}, 
title = {{On the concept of dynamical reduction: the case of coupled oscillators}}, 
author = {Kuramoto, Yoshiki and Nakao, Hiroya}, 
journal = {Philosophical Transactions of the Royal Society A}, 
issn = {1364-503X}, 
doi = {10.1098/rsta.2019.0041}, 
pmid = {31656146}, 
abstract = {{An overview is given on two representative methods of dynamical reduction known as centre-manifold reduction and phase reduction. These theories are presented in a somewhat more unified fashion than the theories in the past. The target systems of reduction are coupled limit-cycle oscillators. Particular emphasis is placed on the remarkable structural similarity existing between these theories. While the two basic principles, i.e. (i) reduction of dynamical degrees of freedom and (ii) transformation of reduced evolution equation to a canonical form, are shared commonly by reduction methods in general, it is shown how these principles are incorporated into the above two reduction theories in a coherent manner. Regarding the phase reduction, a new formulation of perturbative expansion is presented for discrete populations of oscillators. The style of description is intended to be so informal that one may digest, without being bothered with technicalities, what has been done after all under the word reduction. This article is part of the theme issue Coupling functions: dynamical interaction mechanisms in the physical, biological and social sciences.}}, 
pages = {20190041}, 
number = {2160}, 
volume = {377}, 
keywords = {}
}
@article{wiseman1995lack, 
year = {1995}, 
title = {{Lack of self-averaging in critical disordered systems}}, 
author = {Wiseman, Shai and Domany, Eytan}, 
journal = {Physical Review E}, 
issn = {1539-3755}, 
doi = {10.1103/physreve.52.3469}, 
pmid = {9963823}, 
abstract = {{We consider the sample to sample fluctuations that occur in the value of a thermodynamic quantity P in an ensemble of finite systems with quenched disorder, at equilibrium. The variance of P, VP, which characterizes these fluctuations is calculated as a function of the systems' linear size l, focusing on the behavior at the critical point. The specific model considered is the bond-disordered Ashkin-Teller model on a square lattice [Phys. Rev. 64, 178 (1943)]. Using extensive Monte Carlo simulations, several bond-disordered Ashkin-Teller models were examined, including the bond-disordered Ising model and the bond-disordered four-state Potts model. It was found that far from criticality all thermodynamic quantities which were examined (energy, magnetization, specific heat, susceptibility) are strongly self-averaging, that is VP∼l-d (where d=2 is the dimension). At criticality though, the results indicate that the magnetization M and the susceptibility χ are non-self-averaging, i.e., Vχχ2, VMM2↛0. The energy E at criticality is clearly weakly self-averaging, that is VE∼l-yv with 0<yv<d. Less conclusively, and possibly only as a transient behavior, the specific heat too is found to be weakly self-averaging. A phenomenological theory of finite size scaling for disordered systems is developed, based on physical considerations similar to those leading to the Harris criterion. Its main prediction is that when the specific heat exponent α<0 (α of the disordered model) then, for a quantity P which scales as lρ at criticality, its variance VP will scale asymptotically as l2ρ+αν. The theory is not applicable in the asymptotic limit (l→∞) to the bond-disordered Ashkin-Teller model where αν=0+. Nonetheless in the accessible range of lattice sizes we found very good agreement between the theory and the data for Vχ and VE. The theory may also be compatible with the data for the variance of the magnetization VM and the variance of the specific heat VC, but evidence for this is less convincing.}}, 
pages = {3469--3484}, 
number = {4}, 
volume = {52}, 
keywords = {}
}
@article{zierenberg2020tailored, 
year = {2020}, 
title = {{Tailored ensembles of neural networks optimize sensitivity to stimulus statistics}}, 
author = {Zierenberg, Johannes and Wilting, Jens and Priesemann, Viola and Levina, Anna}, 
journal = {Physical Review Research}, 
doi = {10.1103/physrevresearch.2.013115}, 
eprint = {1905.10401}, 
abstract = {{The capability of a living organism to process stimuli with nontrivial intensity distributions cannot be explained by the proficiency of a single neural network. Moreover, it is not sufficient to maximize the dynamic range of the neural response; it is also necessary to tune the response to the intervals of stimulus intensities that should be reliably discriminated. We derive a class of neural networks where these intervals can be tuned to the desired interval. This allows us to tailor ensembles of networks optimized for arbitrary stimulus intensity distributions. We discuss potential applications in machine learning.}}, 
pages = {013115}, 
number = {1}, 
volume = {2}, 
keywords = {}
}
@article{nolte2019cortical, 
year = {2019}, 
title = {{Cortical reliability amid noise and chaos}}, 
author = {Nolte, Max and Reimann, Michael W. and King, James G. and Markram, Henry and Muller, Eilif B.}, 
journal = {Nature Communications}, 
doi = {10.1038/s41467-019-11633-8}, 
pmid = {31439838}, 
pmcid = {PMC6706377}, 
abstract = {{Typical responses of cortical neurons to identical sensory stimuli appear highly variable. It has thus been proposed that the cortex primarily uses a rate code. However, other studies have argued for spike-time coding under certain conditions. The potential role of spike-time coding is directly limited by the internally generated variability of cortical circuits, which remains largely unexplored. Here, we quantify this internally generated variability using a biophysical model of rat neocortical microcircuitry with biologically realistic noise sources. We find that stochastic neurotransmitter release is a critical component of internally generated variability, causing rapidly diverging, chaotic recurrent network dynamics. Surprisingly, the same nonlinear recurrent network dynamics can transiently overcome the chaos in response to weak feed-forward thalamocortical inputs, and support reliable spike times with millisecond precision. Our model shows that the noisy and chaotic network dynamics of recurrent cortical microcircuitry are compatible with stimulus-evoked, millisecond spike-time reliability, resolving a long-standing debate. Whether cortical neurons can fire reliable spikes amid cellular noise and chaotic network dynamics remains debated. Here the authors simulate a detailed neocortical microcircuit model and show that noisy and chaotic cortical network dynamics are compatible with stimulus-evoked, millisecond spike-time reliability.}}, 
pages = {3792}, 
number = {1}, 
volume = {10}, 
keywords = {}
}
@article{carareto2013natural, 
year = {2013}, 
title = {{Natural synchronization in power-grids with anti-correlated units}}, 
author = {Carareto, Rodrigo and Baptista, Murilo S. and Grebogi, Celso}, 
journal = {Communications in Nonlinear Science and Numerical Simulation}, 
issn = {1007-5704}, 
doi = {10.1016/j.cnsns.2012.08.030}, 
abstract = {{Synchronization between spatially distributed nodes of a power-grid is a crucial requirement for its proper operation. Using a Kuramoto-like network as a realistic physical model for the distribution of electrical power in a power-grid, we obtain coupling strengths and topological characteristics that favor the synchronous state of those technological networks. Power-grids are highly heterogeneous. They are composed of different classes of nodes and each node behaves differently. We show in this work that if a power-grid is extensive and nodes are highly connected, the coupling strength that leads to synchronization depends mainly on the eigenvalues of the Laplacian matrix, as it happens in homogeneous networks composed of equal nodes. On the other hand, if a power-grid is sparsely connected, the coupling strength that leads to synchronization is also strongly related to the correlation coefficient of the network, which means that a high number of connections between similar nodes (two power plants or two consumer centers) disfavor the synchronizability of the power-grid. We apply our results to the Brazilian power-grid system.}}, 
pages = {1035--1046}, 
number = {4}, 
volume = {18}, 
keywords = {}
}
@article{10.1063/1.2965095, 
year = {2008}, 
title = {{The Brain: What is Critical About It?}}, 
author = {Chialvo, Dante R. and Balenzuela, Pablo and Fraiman, Daniel}, 
journal = {AIP Conference Proceedings}, 
issn = {0094-243X}, 
doi = {10.1063/1.2965095}, 
eprint = {0804.0032}, 
abstract = {{We review the recent proposal that the most fascinating brain properties are related to the fact that it always stays close to a second order phase transition. In such conditions, the collective of neuronal groups can reliably generate robust and flexible behavior, because it is known that at the critical point there is the largest abundance of metastable states to choose from. Here we review the motivation, arguments and recent results, as well as further implications of this view of the functioning brain.}}, 
pages = {28--45}, 
number = {1}, 
volume = {1028}, 
keywords = {}
}
@article{10.1371/journal.pcbi.0020165, 
year = {2007}, 
title = {{Computational Aspects of Feedback in Neural Circuits}}, 
author = {Maass, Wolfgang and Joshi, Prashant and Sontag, Eduardo D}, 
journal = {PLoS Computational Biology}, 
issn = {1553-734X}, 
doi = {10.1371/journal.pcbi.0020165}, 
pmid = {17238280}, 
pmcid = {PMC1779299}, 
abstract = {{It has previously been shown that generic cortical microcircuit models can perform complex real-time computations on continuous input streams, provided that these computations can be carried out with a rapidly fading memory. We investigate the computational capability of such circuits in the more realistic case where not only readout neurons, but in addition a few neurons within the circuit, have been trained for specific tasks. This is essentially equivalent to the case where the output of trained readout neurons is fed back into the circuit. We show that this new model overcomes the limitation of a rapidly fading memory. In fact, we prove that in the idealized case without noise it can carry out any conceivable digital or analog computation on time-varying inputs. But even with noise, the resulting computational model can perform a large class of biologically relevant real-time computations that require a nonfading memory. We demonstrate these computational implications of feedback both theoretically, and through computer simulations of detailed cortical microcircuit models that are subject to noise and have complex inherent dynamics. We show that the application of simple learning procedures (such as linear regression or perceptron learning) to a few neurons enables such circuits to represent time over behaviorally relevant long time spans, to integrate evidence from incoming spike trains over longer periods of time, and to process new information contained in such spike trains in diverse ways according to the current internal state of the circuit. In particular we show that such generic cortical microcircuits with feedback provide a new model for working memory that is consistent with a large set of biological constraints. Although this article examines primarily the computational role of feedback in circuits of neurons, the mathematical principles on which its analysis is based apply to a variety of dynamical systems. Hence they may also throw new light on the computational role of feedback in other complex biological dynamical systems, such as, for example, genetic regulatory networks.}}, 
pages = {e165}, 
number = {1}, 
volume = {3}, 
keywords = {}
}
@article{10.1038/nn.3616, 
year = {2014}, 
title = {{Temporal structure of motor variability is dynamically regulated and predicts motor learning ability}}, 
author = {Wu, Howard G and Miyamoto, Yohsuke R and Castro, Luis Nicolas Gonzalez and Ölveczky, Bence P and Smith, Maurice A}, 
journal = {Nature Neuroscience}, 
issn = {1097-6256}, 
doi = {10.1038/nn.3616}, 
pmid = {24413700}, 
pmcid = {PMC4442489}, 
abstract = {{Here the authors report that higher levels of task-relevant motor variability predict faster learning both across individuals and across tasks in two different paradigms and that training can reshape the temporal structure of motor variability, aligning it with the trained task to improve learning. These results support the importance of action exploration, a key idea from reinforcement learning theory. Individual differences in motor learning ability are widely acknowledged, yet little is known about the factors that underlie them. Here we explore whether movement-to-movement variability in motor output, a ubiquitous if often unwanted characteristic of motor performance, predicts motor learning ability. Surprisingly, we found that higher levels of task-relevant motor variability predicted faster learning both across individuals and across tasks in two different paradigms, one relying on reward-based learning to shape specific arm movement trajectories and the other relying on error-based learning to adapt movements in novel physical environments. We proceeded to show that training can reshape the temporal structure of motor variability, aligning it with the trained task to improve learning. These results provide experimental support for the importance of action exploration, a key idea from reinforcement learning theory, showing that motor variability facilitates motor learning in humans and that our nervous systems actively regulate it to improve learning.}}, 
pages = {312--321}, 
number = {2}, 
volume = {17}, 
keywords = {}
}
@article{10.1101/2021.10.11.463861, 
year = {2021}, 
title = {{A reservoir of timescales in random neural networks}}, 
author = {Stern, Merav and Istrate, Nicolae and Mazzucato, Luca}, 
journal = {bioRxiv}, 
doi = {10.1101/2021.10.11.463861}, 
abstract = {{The temporal activity of many biological systems, including neural circuits, exhibits fluctuations simultaneously varying over a large range of timescales. The mechanisms leading to this temporal heterogeneity are yet unknown. Here we show that random neural networks endowed with a distribution of self-couplings, representing functional neural clusters of different sizes, generate multiple timescales activity spanning several orders of magnitude. When driven by a time-dependent broadband input, slow and fast neural clusters preferentially entrain slow and fast spectral components of the input, respectively, suggesting a potential mechanism for spectral demixing in cortical circuits. occur.}}, 
pages = {2021.10.11.463861}, 
keywords = {}
}
@article{10.1523/jneurosci.1895-20.2021, 
year = {2021}, 
title = {{State-Dependent Regulation of Cortical Processing Speed via Gain Modulation}}, 
author = {Wyrick, David and Mazzucato, Luca}, 
journal = {The Journal of Neuroscience}, 
issn = {0270-6474}, 
doi = {10.1523/jneurosci.1895-20.2021}, 
pmid = {33858943}, 
abstract = {{To thrive in dynamic environments, animals must be capable of rapidly and flexibly adapting behavioral responses to a changing context and internal state. Examples of behavioral flexibility include faster stimulus responses when attentive and slower responses when distracted. Contextual or state-dependent modulations may occur early in the cortical hierarchy and may be implemented via top-down projections from corticocortical or neuromodulatory pathways. However, the computational mechanisms mediating the effects of such projections are not known. Here, we introduce a theoretical framework to classify the effects of cell type-specific top-down perturbations on the information processing speed of cortical circuits. Our theory demonstrates that perturbation effects on stimulus processing can be predicted by intrinsic gain modulation, which controls the timescale of the circuit dynamics. Our theory leads to counterintuitive effects, such as improved performance with increased input variance. We tested the model predictions using large-scale electrophysiological recordings from the visual hierarchy in freely running mice, where we found that a decrease in single-cell intrinsic gain during locomotion led to an acceleration of visual processing. Our results establish a novel theory of cell type-specific perturbations, applicable to top-down modulation as well as optogenetic and pharmacological manipulations. Our theory links connectivity, dynamics, and information processing via gain modulation.SIGNIFICANCE STATEMENT To thrive in dynamic environments, animals adapt their behavior to changing circumstances and different internal states. Examples of behavioral flexibility include faster responses to sensory stimuli when attentive and slower responses when distracted. Previous work suggested that contextual modulations may be implemented via top-down inputs to sensory cortex coming from higher brain areas or neuromodulatory pathways. Here, we introduce a theory explaining how the speed at which sensory cortex processes incoming information is adjusted by changes in these top-down projections, which control the timescale of neural activity. We tested our model predictions in freely running mice, revealing that locomotion accelerates visual processing. Our theory is applicable to internal modulation as well as optogenetic and pharmacological manipulations and links circuit connectivity, dynamics, and information processing.}}, 
pages = {3988--4005}, 
number = {18}, 
volume = {41}, 
keywords = {}
}
@article{10.1186/s13408-015-0033-6, 
year = {2016}, 
title = {{Mathematical Frameworks for Oscillatory Network Dynamics in Neuroscience}}, 
author = {Ashwin, Peter and Coombes, Stephen and Nicks, Rachel}, 
journal = {Journal of Mathematical Neuroscience}, 
doi = {10.1186/s13408-015-0033-6}, 
pmid = {26739133}, 
pmcid = {PMC4703605}, 
eprint = {1506.05828}, 
abstract = {{The tools of weakly coupled phase oscillator theory have had a profound impact on the neuroscience community, providing insight into a variety of network behaviours ranging from central pattern generation to synchronisation, as well as predicting novel network states such as chimeras. However, there are many instances where this theory is expected to break down, say in the presence of strong coupling, or must be carefully interpreted, as in the presence of stochastic forcing. There are also surprises in the dynamical complexity of the attractors that can robustly appear—for example, heteroclinic network attractors. In this review we present a set of mathematical tools that are suitable for addressing the dynamics of oscillatory neural networks, broadening from a standard phase oscillator perspective to provide a practical framework for further successful applications of mathematics to understanding network dynamics in neuroscience.}}, 
pages = {2}, 
number = {1}, 
volume = {6}, 
keywords = {}
}
@article{10.1103/physrevlett.105.128701, 
year = {2010}, 
title = {{Griffiths Phases on Complex Networks}}, 
author = {Muñoz, Miguel A. and Juhász, Róbert and Castellano, Claudio and Ódor, Géza}, 
journal = {Physical Review Letters}, 
issn = {0031-9007}, 
doi = {10.1103/physrevlett.105.128701}, 
pmid = {20867681}, 
eprint = {1009.0395}, 
abstract = {{Quenched disorder is known to play a relevant role in dynamical processes and phase transitions. Its effects on the dynamics of complex networks have hardly been studied. Aimed at filling this gap, we analyze the contact process, i.e., the simplest propagation model, with quenched disorder on complex networks. We find Griffiths phases and other rare-region effects, leading rather generically to anomalously slow (algebraic, logarithmic, …) relaxation, on Erdős-Rényi networks. Similar effects are predicted to exist for other topologies with a finite percolation threshold. More surprisingly, we find that Griffiths phases can also emerge in the absence of quenched disorder, as a consequence of topological heterogeneity in networks with finite topological dimension. These results have a broad spectrum of implications for propagation phenomena and other dynamical processes on networks.}}, 
pages = {128701}, 
number = {12}, 
volume = {105}, 
keywords = {}
}
@article{10.1103/physrevresearch.4.023057, 
year = {2022}, 
title = {{Differences in the critical dynamics underlying the human and fruit-fly connectome}}, 
author = {Ódor, Géza and Deco, Gustavo and Kelling, Jeffrey}, 
journal = {Physical Review Research}, 
doi = {10.1103/physrevresearch.4.023057}, 
eprint = {2201.11084}, 
abstract = {{Previous simulation studies on human connectomes suggested that critical dynamics emerge subcritically in the so-called Griffiths phases. Now we investigate this on the largest available brain network, the 21662 node fruit-fly connectome, using the Kuramoto synchronization model. As this graph is less heterogeneous, lacking modular structure and exhibiting high topological dimension, we expect a difference from the previous results. Indeed, the synchronization transition is mean-field-like, and the width of the transition region is larger than in random graphs, but much smaller than as for the KKI-18 human connectome. This demonstrates the effect of modular structure and dimension on the dynamics, providing a basis for better understanding the complex critical dynamics of humans.}}, 
pages = {023057}, 
number = {2}, 
volume = {4}, 
keywords = {}
}
@article{10.1088/0305-4470/39/22/r01, 
year = {2006}, 
title = {{Rare region effects at classical, quantum and nonequilibrium phase transitions}}, 
author = {Vojta, Thomas}, 
journal = {Journal of Physics A: Mathematical and General}, 
issn = {0305-4470}, 
doi = {10.1088/0305-4470/39/22/r01}, 
eprint = {cond-mat/0602312}, 
abstract = {{Rare regions, i.e., rare large spatial disorder fluctuations, can dramatically change the properties of a phase transition in a quenched disordered system. In generic classical equilibrium systems, they lead to an essential singularity, the so-called Griffiths singularity, of the free energy in the vicinity of the phase transition. Stronger effects can be observed at zero-temperature quantum phase transitions, at nonequilibrium phase transitions and in systems with correlated disorder. In some cases, rare regions can actually completely destroy the sharp phase transition by smearing. This topical review presents a unifying framework for rare region effects at weakly disordered classical, quantum and nonequilibrium phase transitions based on the effective dimensionality of the rare regions. Explicit examples include disordered classical Ising and Heisenberg models, insulating and metallic random quantum magnets, and the disordered contact process.}}, 
pages = {R143}, 
number = {22}, 
volume = {39}, 
keywords = {}
}
@article{budzinski2022geometry, 
year = {2022}, 
title = {{Geometry unites synchrony, chimeras, and waves in nonlinear oscillator networks}}, 
author = {Budzinski, Roberto C. and Nguyen, Tung T. and Đoàn, Jacqueline and Mináč, Ján and Sejnowski, Terrence J. and Muller, Lyle E.}, 
journal = {Chaos}, 
issn = {1054-1500}, 
doi = {10.1063/5.0078791}, 
pmid = {35364855}, 
pmcid = {PMC8947818}, 
eprint = {2111.02560}, 
abstract = {{One of the simplest mathematical models in the study of nonlinear systems is the Kuramoto model, which describes synchronization in systems from swarms of insects to superconductors. We have recently found a connection between the original, real-valued nonlinear Kuramoto model and a corresponding complex-valued system that permits describing the system in terms of a linear operator and iterative update rule. We now use this description to investigate three major synchronization phenomena in Kuramoto networks (phase synchronization, chimera states, and traveling waves), not only in terms of steady state solutions but also in terms of transient dynamics and individual simulations. These results provide new mathematical insight into how sophisticated behaviors arise from connection patterns in nonlinear networked systems.}}, 
pages = {031104}, 
number = {3}, 
volume = {32}, 
keywords = {}
}
@article{10.1016/j.neuron.2009.07.018, 
year = {2009}, 
title = {{Generating Coherent Patterns of Activity from Chaotic Neural Networks}}, 
author = {Sussillo, David and Abbott, L.F.}, 
journal = {Neuron}, 
issn = {0896-6273}, 
doi = {10.1016/j.neuron.2009.07.018}, 
pmid = {19709635}, 
pmcid = {PMC2756108}, 
abstract = {{Neural circuits display complex activity patterns both spontaneously and when responding to a stimulus or generating a motor output. How are these two forms of activity related? We develop a procedure called FORCE learning for modifying synaptic strengths either external to or within a model neural network to change chaotic spontaneous activity into a wide variety of desired activity patterns. FORCE learning works even though the networks we train are spontaneously chaotic and we leave feedback loops intact and unclamped during learning. Using this approach, we construct networks that produce a wide variety of complex output patterns, input-output transformations that require memory, multiple outputs that can be switched by control inputs, and motor patterns matching human motion capture data. Our results reproduce data on premovement activity in motor and premotor cortex, and suggest that synaptic plasticity may be a more rapid and powerful modulator of network activity than generally appreciated.}}, 
pages = {544--557}, 
number = {4}, 
volume = {63}, 
keywords = {}
}
@article{undefined, 
year = {2021}, 
title = {{Asymmetric Adaptivity induces Recurrent Synchronization in Complex Networks}}, 
author = {Thiele, Max and Berner, Rico and Tass, Peter A and Schöll, Eckehard and Yanchuk, Serhiy}, 
journal = {arXiv}, 
eprint = {2112.08697}, 
abstract = {{Rhythmic activities that alternate between coherent and incoherent phases are ubiquitous in chemical, ecological, climate, or neural systems. Despite their importance, general mechanisms for their emergence are little understood. In order to fill this gap, we present a framework for describing the emergence of recurrent synchronization in complex networks with adaptive interactions. This phenomenon is manifested at the macroscopic level by temporal episodes of coherent and incoherent dynamics that alternate recurrently. At the same time, the dynamics of the individual nodes do not change qualitatively. We identify asymmetric adaptation rules and temporal separation between the adaptation and the dynamics of individual nodes as key ingredients for the emergence of recurrent synchronization. Our results suggest that asymmetric adaptation might play a fundamental role for pattern generators, e.g., in neuronal systems.}}, 
keywords = {}
}
@article{10.1016/j.cub.2015.11.062, 
year = {2016}, 
title = {{Local Slow Waves in Superficial Layers of Primary Cortical Areas during REM Sleep}}, 
author = {Funk, Chadd M. and Honjoh, Sakiko and Rodriguez, Alexander V. and Cirelli, Chiara and Tononi, Giulio}, 
journal = {Current Biology}, 
issn = {0960-9822}, 
doi = {10.1016/j.cub.2015.11.062}, 
pmid = {26804554}, 
pmcid = {PMC4747819}, 
abstract = {{Sleep is traditionally constituted of two global behavioral states, non-rapid eye movement (NREM) and rapid eye movement (REM), characterized by quiescence and reduced responsiveness to sensory stimuli [1]. NREM sleep is distinguished by slow waves and spindles throughout the cerebral cortex and REM sleep by an “activated,” low-voltage fast electroencephalogram (EEG) paradoxically similar to that of wake, accompanied by rapid eye movements and muscle atonia. However, recent evidence has shown that cortical activity patterns during wake and NREM sleep are not as global as previously thought. Local slow waves can appear in various cortical regions in both awake humans [2] and rodents [3–5]. Intracranial recordings in humans [6] and rodents [4, 7] have shown that NREM sleep slow waves most often involve only a subset of brain regions that varies from wave to wave rather than occurring near synchronously across all cortical areas. Moreover, some cortical areas can transiently “wake up” [8] in an otherwise sleeping brain. Yet until now, cortical activity during REM sleep was thought to be homogenously wake-like. We show here, using local laminar recordings in freely moving mice, that slow waves occur regularly during REM sleep, but only in primary sensory and motor areas and mostly in layer 4, the main target of relay thalamic inputs, and layer 3. This finding may help explain why, during REM sleep, we remain disconnected from the environment even though the bulk of the cortex shows wake-like, paradoxical activation.}}, 
pages = {396--403}, 
number = {3}, 
volume = {26}, 
keywords = {}
}
@article{10.1038/s41467-020-14417-7, 
year = {2020}, 
title = {{Network-induced multistability through lossy coupling and exotic solitary states}}, 
author = {Hellmann, Frank and Schultz, Paul and Jaros, Patrycja and Levchenko, Roman and Kapitaniak, Tomasz and Kurths, Jürgen and Maistrenko, Yuri}, 
journal = {Nature Communications}, 
doi = {10.1038/s41467-020-14417-7}, 
pmid = {32001705}, 
pmcid = {PMC6992754}, 
abstract = {{The stability of synchronised networked systems is a multi-faceted challenge for many natural and technological fields, from cardiac and neuronal tissue pacemakers to power grids. For these, the ongoing transition to distributed renewable energy sources leads to a proliferation of dynamical actors. The desynchronisation of a few or even one of those would likely result in a substantial blackout. Thus the dynamical stability of the synchronous state has become a leading topic in power grid research. Here we uncover that, when taking into account physical losses in the network, the back-reaction of the network induces new exotic solitary states in the individual actors and the stability characteristics of the synchronous state are dramatically altered. These effects will have to be explicitly taken into account in the design of future power grids. We expect the results presented here to transfer to other systems of coupled heterogeneous Newtonian oscillators. The design of future power grids with decentral control calls for a better understanding of the stability of synchronized networked systems. Here, Hellmann et al. show that the energy losses in coupled oscillators can significantly alter power grid dynamics by introducing solitary states in the network.}}, 
pages = {592}, 
number = {1}, 
volume = {11}, 
keywords = {}
}
@article{10.1103/revmodphys.90.031001, 
year = {2018}, 
title = {{Colloquium: Criticality and dynamical scaling in living systems}}, 
author = {Muñoz and Miguel, A.}, 
journal = {Reviews of Modern Physics}, 
issn = {0034-6861}, 
doi = {10.1103/revmodphys.90.031001}, 
eprint = {1712.04499}, 
abstract = {{A celebrated and controversial hypothesis suggests that some biological systems—parts, aspects, or groups of them—may extract important functional benefits from operating at the edge of instability, halfway between order and disorder, i.e., in the vicinity of the critical point of a phase transition. Criticality has been argued to provide biological systems with an optimal balance between robustness against perturbations and flexibility to adapt to changing conditions as well as to confer on them optimal computational capabilities, large dynamical repertoires, unparalleled sensitivity to stimuli, etc. Criticality, with its concomitant scale invariance, can be conjectured to emerge in living systems as the result of adaptive and evolutionary processes that, for reasons to be fully elucidated, select for it as a template upon which further layers of complexity can rest. This hypothesis is suggestive as it proposes that criticality could constitute a general and common organizing strategy in biology stemming from the physics of phase transitions. However, despite its implications, this is still in its infancy state as a well-founded theory and, as such, it has elicited some skepticism. From the experimental side, the advent of high-throughput technologies has created new prospects in the exploration of biological systems, and empirical evidence in favor of criticality has proliferated, with examples ranging from endogenous brain activity and gene-expression patterns to flocks of birds and insect-colony foraging, to name but a few. Some pieces of evidence are quite remarkable, while in some other cases empirical data are limited, incomplete, or not fully convincing. More stringent experimental setups and theoretical analyses are certainly needed to fully clarify the picture. In any case, the time seems ripe for bridging the gap between this theoretical conjecture and its empirical validation. Given the profound implications of shedding light on this issue, it is both pertinent and timely to review the state of the art and to discuss future strategies and perspectives.}}, 
pages = {031001}, 
number = {3}, 
volume = {90}, 
keywords = {}
}
@article{hanggi1986escape, 
year = {1986}, 
title = {{Escape from a metastable state}}, 
author = {Hanggi, Peter}, 
journal = {Journal of Statistical Physics}, 
issn = {0022-4715}, 
doi = {10.1007/bf01010843}, 
abstract = {{Many important processes in science involve the escape of a particle over a barrier. In this review, we report, extend, and interpret various theories of noise-activated escape. We discuss the connection between many-body transition state theory and Kramers' original diffusive Brownian motion approach (both in one-and multidimensional potential fields) and emphasize the physical situation inherent in Kramers' rate for weak friction. A rate theory accounting for memory friction is presented together with a set of criteria which test its validity. The complications and peculiarities of noise-activated escape in driven systems exhibiting multiple, locally stable stationary nonequilibrium states are identified and illustrated. At lower temperatures, quantum tunneling effects begin to play an increasingly important role. Early approaches and more recent developments of the quantum version of Kramers approach are discussed, thereby providing a description for dissipative escape at all temperatures.}}, 
pages = {105--148}, 
number = {1-2}, 
volume = {42}, 
keywords = {}
}
@article{10.1017/s0305004100064732, 
year = {1988}, 
title = {{Structurally stable heteroclinic cycles}}, 
author = {Guckenheimer, John and Holmes, Philip}, 
journal = {Mathematical Proceedings of the Cambridge Philosophical Society}, 
issn = {0305-0041}, 
doi = {10.1017/s0305004100064732}, 
abstract = {{This paper describes a previously undocumented phenomenon in dynamical systems theory; namely, the occurrence of heteroclinic cycles that are structurally stable within the space of Cr vector fields equivariant with respect to a symmetry group. In the space X(M) of Cr vector fields on a manifold M, there is a residual set of vector fields having no trajectories joining saddle points with stable manifolds of the same dimension. Such heteroclinic connections are a structurally unstable phenomenon [4]. However, in the space XG(M) ⊂ X(M) of vector fields equivariant with respect to a symmetry group G, the situation can be quite different. We give an example of an open set U of topologically equivalent vector fields in the space of vector fields on ℝ3 equivariant with respect to a particular finite subgroup G ⊂ O(3) such that each X ∈ U has a heteroclinic cycle that is an attractor. The heteroclinic cycles consist of three equilibrium points and three trajectories joining them.}}, 
pages = {189--192}, 
number = {1}, 
volume = {103}, 
keywords = {}
}
@article{schuller2020kramer, 
year = {2020}, 
title = {{Kramers’ escape rate problem within a non-Markovian description}}, 
author = {Schüller, Benjamin and Meistrenko, Alex and Hees, Hendrik van and Xu, Zhe and Greiner, Carsten}, 
journal = {Annals of Physics}, 
issn = {0003-4916}, 
doi = {10.1016/j.aop.2019.168045}, 
eprint = {1905.09652}, 
abstract = {{We compare the thermal escape rates of a Brownian particle, initially trapped into one of the two wells of an asymmetric double-well potential, for thermal Markovian and non-Markovian noise. The Markovian treatment of this problem goes originally back to the studies of Kramers in 1940 and is therefore often referred to as “Kramers’ escape rate problem”. We solve the generalized Langevin equation for the trajectories of the particles numerically and analytically for both limiting cases, Markovian and non-Markovian thermal noise. We compute the escape rate and work out the fundamental differences arising from finite correlation times of the thermal noise.}}, 
pages = {168045}, 
volume = {412}, 
keywords = {}
}
@article{10.1126/science.aat6412, 
year = {2018}, 
title = {{Transient phenomena in ecology}}, 
author = {Hastings, Alan and Abbott, Karen C. and Cuddington, Kim and Francis, Tessa and Gellner, Gabriel and Lai, Ying-Cheng and Morozov, Andrew and Petrovskii, Sergei and Scranton, Katherine and Zeeman, Mary Lou}, 
journal = {Science}, 
issn = {0036-8075}, 
doi = {10.1126/science.aat6412}, 
pmid = {30190378}, 
abstract = {{The importance of transient dynamics in ecological systems and in the models that describe them has become increasingly recognized. However, previous work has typically treated each instance of these dynamics separately. We review both empirical examples and model systems, and outline a classification of transient dynamics based on ideas and concepts from dynamical systems theory. This classification provides ways to understand the likelihood of transients for particular systems, and to guide investigations to determine the timing of sudden switches in dynamics and other characteristics of transients. Implications for both management and underlying ecological theories emerge.}}, 
number = {6406}, 
volume = {361}, 
keywords = {}
}
@article{buzna2009synchronization, 
year = {2009}, 
title = {{Synchronization in symmetric bipolar population networks}}, 
author = {Buzna, Lubos and Lozano, Sergi and Díaz-Guilera, Albert}, 
journal = {Physical Review E}, 
issn = {1539-3755}, 
doi = {10.1103/physreve.80.066120}, 
pmid = {20365244}, 
eprint = {0905.2487}, 
abstract = {{We analyze populations of Kuramoto oscillators with a particular distribution of natural frequencies. Inspired by networks where there are two groups of nodes with opposite behaviors, as for instance, in power-grids where energy is either generated or consumed at different locations, we assume that the frequencies can take only two different values. Correlations between the value of the frequency of a given node and its topological localization are considered in both regular and random topologies. Synchronization is enhanced when nodes are surrounded by nodes of the opposite frequency. The theoretical result presented in this paper is an analytical estimation for the minimum value of the coupling strength between oscillators that guarantees the achievement of a globally synchronized state. This analytical estimation, which is in a very good agreement with numerical simulations, provides a better understanding of the effect of topological localization of natural frequencies on synchronization dynamics.}}, 
pages = {066120}, 
number = {6}, 
volume = {80}, 
keywords = {}
}
@article{rabinovich2006dynamical, 
year = {2006}, 
title = {{Dynamical principles in neuroscience}}, 
author = {Rabinovich, Mikhail I. and Varona, Pablo and Selverston, Allen I. and Abarbanel, Henry D. I.}, 
journal = {Reviews of Modern Physics}, 
issn = {0034-6861}, 
doi = {10.1103/revmodphys.78.1213}, 
abstract = {{Dynamical modeling of neural systems and brain functions has a history of success over the last half century. This includes, for example, the explanation and prediction of some features of neural rhythmic behaviors. Many interesting dynamical models of learning and memory based on physiological experiments have been suggested over the last two decades. Dynamical models even of consciousness now exist. Usually these models and results are based on traditional approaches and paradigms of nonlinear dynamics including dynamical chaos. Neural systems are, however, an unusual subject for nonlinear dynamics for several reasons: (i) Even the simplest neural network, with only a few neurons and synaptic connections, has an enormous number of variables and control parameters. These make neural systems adaptive and flexible, and are critical to their biological function. (ii) In contrast to traditional physical systems described by well-known basic principles, first principles governing the dynamics of neural systems are unknown. (iii) Many different neural systems exhibit similar dynamics despite having different architectures and different levels of complexity. (iv) The network architecture and connection strengths are usually not known in detail and therefore the dynamical analysis must, in some sense, be probabilistic. (v) Since nervous systems are able to organize behavior based on sensory inputs, the dynamical modeling of these systems has to explain the transformation of temporal information into combinatorial or combinatorial-temporal codes, and vice versa, for memory and recognition. In this review these problems are discussed in the context of addressing the stimulating questions: What can neuroscience learn from nonlinear dynamics, and what can nonlinear dynamics learn from neuroscience?}}, 
pages = {1213--1265}, 
number = {4}, 
volume = {78}, 
keywords = {}
}
@article{10.1016/s0960-0779(97)00047-7, 
year = {1998}, 
title = {{Practical stability of chaotic attractors}}, 
author = {Kapitaniak, T. and Brindley, J.}, 
journal = {Chaos, Solitons \& Fractals}, 
issn = {0960-0779}, 
doi = {10.1016/s0960-0779(97)00047-7}, 
abstract = {{In this paper we introduce the concept of practical stability and practical stability in finite time for chaotic attractors. The connection between practical and asymptotic stability is discussed.}}, 
pages = {43--50}, 
number = {1-2}, 
volume = {9}, 
keywords = {}
}
@article{pomeau1979intermittency, 
year = {1979}, 
title = {{Intermittency and the Lorenz model}}, 
author = {Manneville, P. and Pomeau, Y.}, 
journal = {Physics Letters A}, 
issn = {0375-9601}, 
doi = {10.1016/0375-9601(79)90255-x}, 
abstract = {{The Lorenz system is shown to display intermittency at the transition from the first limit cycle to the second strange attractor.}}, 
pages = {1--2}, 
number = {1-2}, 
volume = {75}, 
keywords = {}
}
@article{yorke1979metastable, 
year = {1979}, 
title = {{Metastable chaos: The transition to sustained chaotic behavior in the Lorenz model}}, 
author = {Yorke, James A. and Yorke, Ellen D.}, 
journal = {Journal of Statistical Physics}, 
issn = {0022-4715}, 
doi = {10.1007/bf01011469}, 
abstract = {{The system of equations introduced by Lorenz to model turbulent convective flow is studied here for Rayleigh numbersr somewhat smaller than the critical value required for sustained chaotic behavior. In this regime the system is found to exhibit transient chaotic behavior. Some statistical properties of this transient chaos are examined numerically. A mean decay time from chaos to steady flow is found and its dependence uponr is studied both numerically and (very close to the criticalr) analytically.}}, 
pages = {263--277}, 
number = {3}, 
volume = {21}, 
keywords = {}
}
@article{gelbrecht2020monte, 
year = {2020}, 
title = {{Monte Carlo basin bifurcation analysis}}, 
author = {Gelbrecht, Maximilian and Kurths, Jürgen and Hellmann, Frank}, 
journal = {New Journal of Physics}, 
doi = {10.1088/1367-2630/ab7a05}, 
eprint = {1910.06322}, 
abstract = {{Abstract Many high-dimensional complex systems exhibit an enormously complex landscape of possible asymptotic states. Here, we present a numerical approach geared towards analyzing such systems. It is situated between the classical analysis with macroscopic order parameters and a more thorough, detailed bifurcation analysis. With our machine learning method, based on random sampling and clustering methods, we are able to characterize the different asymptotic states or classes thereof and even their basins of attraction. In order to do this, suitable, easy to compute, statistics of trajectories with randomly generated initial conditions and parameters are clustered by an algorithm such as DBSCAN. Due to its modular and flexible nature, our method has a wide range of possible applications in many disciplines. While typical applications are oscillator networks, it is not limited only to ordinary differential equation systems, every complex system yielding trajectories, such as maps or agent-based models, can be analyzed, as we show by applying it the Dodds–Watts model, a generalized SIRS-model, modeling social and biological contagion. A second order Kuramoto model, used, e.g. to investigate power grid dynamics, and a Stuart–Landau oscillator network, each exhibiting a complex multistable regime, are shown as well. The method is available to use as a package for the Julia language.}}, 
pages = {033032}, 
number = {3}, 
volume = {22}, 
keywords = {}
}
@article{10.1063/1.5012134, 
year = {2018}, 
title = {{Riddled basins of attraction in systems exhibiting extreme events}}, 
author = {Saha, Arindam and Feudel, Ulrike}, 
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science}, 
issn = {1054-1500}, 
doi = {10.1063/1.5012134}, 
pmid = {29604637}, 
eprint = {1711.02160}, 
abstract = {{Using a system of two FitzHugh-Nagumo units, we demonstrate the occurrence of riddled basins of attraction in delay-coupled systems as the coupling between the units is increased. We characterize riddled basins using the uncertainty exponent which is a measure of the dimensions of the basin boundary. Additionally, we show that the phase space can be partitioned into pure and mixed regions, where initial conditions in the pure regions certainly avoid the generation of extreme events, while initial conditions in the mixed region may or may not exhibit such events. This implies that any tiny perturbation of initial conditions in the mixed region could yield the emergence of extreme events because the latter state possesses a riddled basin of attraction.}}, 
pages = {033610}, 
number = {3}, 
volume = {28}, 
keywords = {}
}
@article{hangi1990reaction, 
year = {1990}, 
title = {{Reaction-rate theory: fifty years after Kramers}}, 
author = {Hänggi, Peter and Talkner, Peter and Borkovec, Michal}, 
journal = {Reviews of Modern Physics}, 
issn = {0034-6861}, 
doi = {10.1103/revmodphys.62.251}, 
abstract = {{The calculation of rate coefficients is a discipline of nonlinear science of importance to much of physics, chemistry, engineering, and biology. Fifty years after Kramers' seminal paper on thermally activated barrier crossing, the authors report, extend, and interpret much of our current understanding relating to theories of noise-activated escape, for which many of the notable contributions are originating from the communities both of physics and of physical chemistry. Theoretical as well as numerical approaches are discussed for single- and many-dimensional metastable systems (including fields) in gases and condensed phases. The role of many-dimensional transition-state theory is contrasted with Kramers' reaction-rate theory for moderate-to-strong friction; the authors emphasize the physical situation and the close connection between unimolecular rate theory and Kramers' work for weakly damped systems. The rate theory accounting for memory friction is presented, together with a unifying theoretical approach which covers the whole regime of weak-to-moderate-to-strong friction on the same basis (turnover theory). The peculiarities of noise-activated escape in a variety of physically different metastable potential configurations is elucidated in terms of the mean-first-passage-time technique. Moreover, the role and the complexity of escape in driven systems exhibiting possibly multiple, metastable stationary nonequilibrium states is identified. At lower temperatures, quantum tunneling effects start to dominate the rate mechanism. The early quantum approaches as well as the latest quantum versions of Kramers' theory are discussed, thereby providing a description of dissipative escape events at all temperatures. In addition, an attempt is made to discuss prominent experimental work as it relates to Kramers' reaction-rate theory and to indicate the most important areas for future research in theory and experiment.}}, 
pages = {251--341}, 
number = {2}, 
volume = {62}, 
keywords = {}
}
@article{motter2013spontaneous, 
year = {2013}, 
title = {{Spontaneous synchrony in power-grid networks}}, 
author = {Motter, Adilson E. and Myers, Seth A. and Anghel, Marian and Nishikawa, Takashi}, 
journal = {Nature Physics}, 
issn = {1745-2473}, 
doi = {10.1038/nphys2535}, 
abstract = {{An imperative condition for the functioning of a power-grid network is that its power generators remain synchronized. Disturbances can prompt desynchronization, which is a process that has been involved in large power outages. Here we derive a condition under which the desired synchronous state of a power grid is stable, and use this condition to identify tunable parameters of the generators that are determinants of spontaneous synchronization. Our analysis gives rise to an approach to specify parameter assignments that can enhance synchronization of any given network, which we demonstrate for a selection of both test systems and real power grids. These findings may be used to optimize stability and help devise new control schemes, thus offering an additional layer of protection and contributing to the development of smart grids that can recover from failures in real time. Power-grid networks must be synchronized in order to function. A condition for the stability of the synchronous state enables identification of network parameters that enhance spontaneous synchronization—heralding the possibility of smart grids that operate optimally in real-world systems.}}, 
pages = {191--197}, 
number = {3}, 
volume = {9}, 
keywords = {}
}
@article{dunne2002foodweb, 
year = {2002}, 
title = {{Food-web structure and network theory: The role of connectance and size}}, 
author = {Dunne, Jennifer A. and Williams, Richard J. and Martinez, Neo D.}, 
journal = {Proceedings of the National Academy of Sciences}, 
issn = {0027-8424}, 
doi = {10.1073/pnas.192407699}, 
pmid = {12235364}, 
pmcid = {PMC130560}, 
abstract = {{Networks from a wide range of physical, biological, and social systems have been recently described as “small-world” and “scale-free.” However, studies disagree whether ecological networks called food webs possess the characteristic path lengths, clustering coefficients, and degree distributions required for membership in these classes of networks. Our analysis suggests that the disagreements are based on selective use of relatively few food webs, as well as analytical decisions that obscure important variability in the data. We analyze a broad range of 16 high-quality food webs, with 25–172 nodes, from a variety of aquatic and terrestrial ecosystems. Food webs generally have much higher complexity, measured as connectance (the fraction of all possible links that are realized in a network), and much smaller size than other networks studied, which have important implications for network topology. Our results resolve prior conflicts by demonstrating that although some food webs have small-world and scale-free structure, most do not if they exceed a relatively low level of connectance. Although food-web degree distributions do not display a universal functional form, observed distributions are systematically related to network connectance and size. Also, although food webs often lack small-world structure because of low clustering, we identify a continuum of real-world networks including food webs whose ratios of observed to random clustering coefficients increase as a power–law function of network size over 7 orders of magnitude. Although food webs are generally not small-world, scale-free networks, food-web topology is consistent with patterns found within those classes of networks.}}, 
pages = {12917--12922}, 
number = {20}, 
volume = {99}, 
keywords = {}
}
@article{crotty2010josephson, 
year = {2010}, 
title = {{Josephson junction simulation of neurons}}, 
author = {Crotty, Patrick and Schult, Dan and Segall, Ken}, 
journal = {Physical Review E}, 
issn = {1539-3755}, 
doi = {10.1103/physreve.82.011914}, 
pmid = {20866655}, 
abstract = {{With the goal of understanding the intricate behavior and dynamics of collections of neurons, we present superconducting circuits containing Josephson junctions that model biologically realistic neurons. These “Josephson junction neurons” reproduce many characteristic behaviors of biological neurons such as action potentials, refractory periods, and firing thresholds. They can be coupled together in ways that mimic electrical and chemical synapses. Using existing fabrication technologies, large interconnected networks of Josephson junction neurons would operate fully in parallel. They would be orders of magnitude faster than both traditional computer simulations and biological neural networks. Josephson junction neurons provide a new tool for exploring long-term large-scale dynamics for networks of neurons.}}, 
pages = {011914}, 
number = {1}, 
volume = {82}, 
keywords = {}
}
@article{nixon2011synchronized, 
year = {2011}, 
title = {{Synchronized Cluster Formation in Coupled Laser Networks}}, 
author = {Nixon, Micha and Friedman, Moti and Ronen, Eitan and Friesem, Asher A. and Davidson, Nir and Kanter, Ido}, 
journal = {Physical Review Letters}, 
issn = {0031-9007}, 
doi = {10.1103/physrevlett.106.223901}, 
pmid = {21702599}, 
abstract = {{We experimentally investigate the phase dynamics of laser networks with homogenous time-delayed mutual coupling and establish the fundamental rules that govern their state of synchronization. We identified a specific substructure that imposes its synchronization state on the entire network and show that for any coupling configuration the network forms at most two synchronized clusters. Our results indicate that the synchronization state of the network is a nonlocal phenomenon and cannot be deduced by decomposing the network into smaller substructures, each with its individual synchronization state.}}, 
pages = {223901}, 
number = {22}, 
volume = {106}, 
keywords = {}
}
@article{josephson1964coupled, 
year = {1964}, 
title = {{Coupled Superconductors}}, 
author = {Josephson, B. D.}, 
journal = {Reviews of Modern Physics}, 
issn = {0034-6861}, 
doi = {10.1103/revmodphys.36.216}, 
pages = {216--220}, 
number = {1}, 
volume = {36}, 
keywords = {}
}
@article{marek1975synchronization, 
year = {1975}, 
title = {{Synchronization in two interacting oscillatory systems}}, 
author = {Marek, Milos and Stuchl, Ivan}, 
journal = {Biophysical Chemistry}, 
issn = {0301-4622}, 
doi = {10.1016/0301-4622(75)80016-0}, 
pmid = {1174646}, 
abstract = {{Nonlinear phenomena arising from the interaction of two oscillating systems of chemical reactions are studied experimentally. The system of two connected flow-through continuous stirred tank reactors (cells) with controlled exchange of reaction mixture is used. The Belousov reaction (oxidation of malonic acid by bromate in sulphuric acid with ceric/cerous ions as catalyst) served as model system. The frequency of oscillations was controlled by change of the reaction temperature. Phenomena such as synchronization of oscillations at a common frequency, synchronization at multiples of a common frequency, rhythm splitting and amplitude amplification were observed, depending on the degree of interaction and the differences in the original oscillation frequencies. Mathematical modelling of the above phenomena failed, probably due to insufficient knowledge of a kinetic model.}}, 
pages = {241--248}, 
number = {3}, 
volume = {3}, 
keywords = {}
}
@article{neu1979chemical, 
year = {1979}, 
title = {{Chemical Waves and the Diffusive Coupling of Limit Cycle Oscillators}}, 
author = {Neu, John C.}, 
journal = {SIAM Journal on Applied Mathematics}, 
issn = {0036-1399}, 
doi = {10.1137/0136038}, 
abstract = {{We analyze a model of an oscillating chemical reaction taking place in a diffusive medium. Using singular perturbation techniques, we derive a nonlinear equation that determines how spatial variations in the phase of the oscillations evolve in time. This result is the key to understanding the propagation of chemical waves. In particular, we use it to account for certain experimental observations on the BelusovZhabotinskii reaction.}}, 
pages = {509--515}, 
number = {3}, 
volume = {36}, 
keywords = {}
}
@article{10.1103/physrevresearch.3.023144, 
year = {2021}, 
title = {{Weak-winner phase synchronization: A curious case of weak interactions}}, 
author = {Choudhary, Anshul and Saha, Arindam and Krueger, Samuel and Finke, Christian and Rosa, Epaminondas and Freund, Jan A. and Feudel, Ulrike}, 
journal = {Physical Review Research}, 
doi = {10.1103/physrevresearch.3.023144}, 
eprint = {1812.02642}, 
abstract = {{We report the observation of a nontrivial emergent state in a chain of nonidentical, heterogeneously coupled oscillators where a set of weakly coupled oscillators becomes phase synchronized while the strongly coupled ones remain drifting. This intriguing “weak-winner” synchronization phenomenon can be explained by the interplay between nonisochronicity and the natural frequency of the oscillator, as coupling strength is varied. Furthermore, we present sufficient conditions under which the weak-winner phase synchronization can occur for limit cycles as well as chaotic oscillators. Employing a model system from ecology as well as a paradigmatic model from physics, we demonstrate that this phenomenon is a generic feature for a large class of coupled oscillator systems. The realization of this peculiar, yet quite generic weak-winner dynamics can have far-reaching consequences in a wide range of scientific disciplines that deal with the phenomenon of phase synchronization, including synchronization of networks. Our results also highlight the role of nonisochronicity (shear) as a fundamental feature of an oscillator in shaping emergent dynamical patterns in complex networks.}}, 
pages = {023144}, 
number = {2}, 
volume = {3}, 
keywords = {}
}
@article{witthaut2012braess, 
year = {2012}, 
title = {{Braess's paradox in oscillator networks, desynchronization and power outage}}, 
author = {Witthaut, Dirk and Timme, Marc}, 
journal = {New Journal of Physics}, 
issn = {1367-2630}, 
doi = {10.1088/1367-2630/14/8/083036}, 
abstract = {{Robust synchronization is essential to ensure the stable operation of many complex networked systems such as electric power grids. Increasing energy demands and more strongly distributing power sources raise the question of where to add new connection lines to the already existing grid. Here we study how the addition of individual links impacts the emergence of synchrony in oscillator networks that model power grids on coarse scales. We reveal that adding new links may not only promote but also destroy synchrony and link this counter-intuitive phenomenon to Braess's paradox known for traffic networks. We analytically uncover its underlying mechanism in an elementary grid example, trace its origin to geometric frustration in phase oscillators, and show that it generically occurs across a wide range of systems. As an important consequence, upgrading the grid requires particular care when adding new connections because some may destabilize the synchronization of the grid—and thus induce power outages.}}, 
pages = {083036}, 
number = {8}, 
volume = {14}, 
keywords = {}
}
@article{coletta2016linear, 
year = {2016}, 
title = {{Linear stability and the Braess paradox in coupled-oscillator networks and electric power grids}}, 
author = {Coletta, Tommaso and Jacquod, Philippe}, 
journal = {Physical Review E}, 
issn = {2470-0045}, 
doi = {10.1103/physreve.93.032222}, 
pmid = {27078359}, 
abstract = {{We investigate the influence that adding a new coupling has on the linear stability of the synchronous state in coupled-oscillator networks. Using a simple model, we show that, depending on its location, the new coupling can lead to enhanced or reduced stability. We extend these results to electric power grids where a new line can lead to four different scenarios corresponding to enhanced or reduced grid stability as well as increased or decreased power flows. Our analysis shows that the Braess paradox may occur in any complex coupled system, where the synchronous state may be weakened and sometimes even destroyed by additional couplings.}}, 
pages = {032222}, 
number = {3}, 
volume = {93}, 
keywords = {}
}
@article{buendia2022the, 
year = {2022}, 
title = {{The broad edge of synchronization: Griffiths effects and collective phenomena in brain networks}}, 
author = {Buenda, Victor and Villegas, Pablo and Burioni, Raffaella and Muoz, Miguel A.}, 
journal = {Philosophical Transactions of the Royal Society A}, 
issn = {1364-503X}, 
doi = {10.1098/rsta.2020.0424}, 
pmid = {35599563}, 
abstract = {{Many of the amazing functional capabilities of the brain are collective properties stemming from the interactions of large sets of individual neurons. In particular, the most salient collective phenomena in brain activity are oscillations, which require the synchronous activation of many neurons. Here, we analyse parsimonious dynamical models of neural synchronization running on top of synthetic networks that capture essential aspects of the actual brain anatomical connectivity such as a hierarchical-modular and core-periphery structure. These models reveal the emergence of complex collective states with intermediate and flexible levels of synchronization, halfway in the synchronousasynchronous spectrum. These states are best described as broad Griffiths-like phases, i.e. an extension of standard critical points that emerge in structurally heterogeneous systems. We analyse different routes (bifurcations) to synchronization and stress the relevance of hybrid-type transitions to generate rich dynamical patterns. Overall, our results illustrate the complex interplay between structure and dynamics, underlining key aspects leading to rich collective states needed to sustain brain functionality. This article is part of the theme issue Emergent phenomena in complex physical and socio-technical systems: from cells to societies.}}, 
pages = {20200424}, 
number = {2227}, 
volume = {380}, 
keywords = {}
}
@article{10.1016/j.neuroimage.2017.03.045, 
year = {2017}, 
title = {{Functional connectivity dynamically evolves on multiple time-scales over a static structural connectome: Models and mechanisms}}, 
author = {Cabral, Joana and Kringelbach, Morten L. and Deco, Gustavo}, 
journal = {NeuroImage}, 
issn = {1053-8119}, 
doi = {10.1016/j.neuroimage.2017.03.045}, 
pmid = {28343985}, 
abstract = {{Over the last decade, we have observed a revolution in brain structural and functional Connectomics. On one hand, we have an ever-more detailed characterization of the brain's white matter structural connectome. On the other, we have a repertoire of consistent functional networks that form and dissipate over time during rest. Despite the evident spatial similarities between structural and functional connectivity, understanding how different time-evolving functional networks spontaneously emerge from a single structural network requires analyzing the problem from the perspective of complex network dynamics and dynamical system's theory. In that direction, bottom-up computational models are useful tools to test theoretical scenarios and depict the mechanisms at the genesis of resting-state activity. Here, we provide an overview of the different mechanistic scenarios proposed over the last decade via computational models. Importantly, we highlight the need of incorporating additional model constraints considering the properties observed at finer temporal scales with MEG and the dynamical properties of FC in order to refresh the list of candidate scenarios.}}, 
pages = {84--96}, 
volume = {160}, 
keywords = {}
}
@article{villegas2014frustrated, 
year = {2014}, 
title = {{Frustrated hierarchical synchronization and emergent complexity in the human connectome network}}, 
author = {Villegas, Pablo and Moretti, Paolo and Muñoz, Miguel A.}, 
journal = {Scientific Reports}, 
doi = {10.1038/srep05990}, 
pmid = {25103684}, 
pmcid = {PMC4126002}, 
eprint = {1402.5289}, 
abstract = {{The spontaneous emergence of coherent behavior through synchronization plays a key role in neural function, and its anomalies often lie at the basis of pathologies. Here we employ a parsimonious (mesoscopic) approach to study analytically and computationally the synchronization (Kuramoto) dynamics on the actual human-brain connectome network. We elucidate the existence of a so-far-uncovered intermediate phase, placed between the standard synchronous and asynchronous phases, i.e. between order and disorder. This novel phase stems from the hierarchical modular organization of the connectome. Where one would expect a hierarchical synchronization process, we show that the interplay between structural bottlenecks and quenched intrinsic frequency heterogeneities at many different scales, gives rise to frustrated synchronization, metastability, and chimera-like states, resulting in a very rich and complex phenomenology. We uncover the origin of the dynamic freezing behind these features by using spectral graph theory and discuss how the emerging complex synchronization patterns relate to the need for the brain to access –in a robust though flexible way– a large variety of functional attractors and dynamical repertoires without ad hoc fine-tuning to a critical point.}}, 
pages = {5990}, 
number = {1}, 
volume = {4}, 
keywords = {}
}
@article{tononi1994a, 
year = {1994}, 
title = {{A measure for brain complexity: relating functional segregation and integration in the nervous system.}}, 
author = {Tononi, G and Sporns, O and Edelman, G M}, 
journal = {Proceedings of the National Academy of Sciences}, 
issn = {0027-8424}, 
doi = {10.1073/pnas.91.11.5033}, 
pmid = {8197179}, 
pmcid = {PMC43925}, 
abstract = {{In brains of higher vertebrates, the functional segregation of local areas that differ in their anatomy and physiology contrasts sharply with their global integration during perception and behavior. In this paper, we introduce a measure, called neural complexity (CN), that captures the interplay between these two fundamental aspects of brain organization. We express functional segregation within a neural system in terms of the relative statistical independence of small subsets of the system and functional integration in terms of significant deviations from independence of large subsets. CN is then obtained from estimates of the average deviation from statistical independence for subsets of increasing size. CN is shown to be high when functional segregation coexists with integration and to be low when the components of a system are either completely independent (segregated) or completely dependent (integrated). We apply this complexity measure in computer simulations of cortical areas to examine how some basic principles of neuroanatomical organization constrain brain dynamics. We show that the connectivity patterns of the cerebral cortex, such as a high density of connections, strong local connectivity organizing cells into neuronal groups, patchiness in the connectivity among neuronal groups, and prevalent reciprocal connections, are associated with high values of CN. The approach outlined here may prove useful in analyzing complexity in other biological domains such as gene regulation and embryogenesis.}}, 
pages = {5033--5037}, 
number = {11}, 
volume = {91}, 
keywords = {}
}
@article{ashwin1999transverse, 
year = {1999}, 
title = {{Transverse instability for non-normal parameters}}, 
author = {Ashwin, Peter and Covas, Eurico and Tavakol, Reza}, 
journal = {Nonlinearity}, 
issn = {0951-7715}, 
doi = {10.1088/0951-7715/12/3/009}, 
abstract = {{We consider the behaviour of attractors near invariant subspaces on varying a parameter that does not preserve the dynamics in the invariant subspace but is otherwise generic, in a smooth dynamical system. We refer to such a parameter as ``non-normal''. If there is chaos in the invariant subspace that is not structurally stable, this has the effect of ``blurring out'' blowout bifurcations over a range of parameter values that we show can have positive measure in parameter space. Associated with such blowout bifurcations are bifurcations to attractors displaying a new type of intermittency that is phenomenologically similar to on-off intermittency, but where the intersection of the attractor by the invariant subspace is larger than a minimal attractor. The presence of distinct repelling and attracting invariant sets leads us to refer to this as ``in-out'' intermittency. Such behaviour cannot appear in systems where the transverse dynamics is a skew product over the system on the invariant subspace. We characterise in-out intermittency in terms of its structure in phase space and in terms of invariants of the dynamics obtained from a Markov model of the attractor. This model predicts a scaling of the length of laminar phases that is similar to that for on-off intermittency but which has some differences.}}, 
pages = {563--577}, 
number = {3}, 
volume = {12}, 
keywords = {}
}
@article{platt1993onoff, 
year = {1993}, 
title = {{On-off intermittency: A mechanism for bursting}}, 
author = {Platt, N and Spiegel, E A and Tresser, C}, 
journal = {Physical Review Letters}, 
issn = {0031-9007}, 
doi = {10.1103/physrevlett.70.279}, 
pmid = {10054072}, 
abstract = {{On-off intermittency is an aperiodic switching between static, or laminar, behavior and chaotic bursts of oscillation. It can be generated by systems having an unstable invariant (or quasi-invariant) manifold, within which is found a suitable attractor. We clarify the roles of such attractors in producing intermittency, provide examples, and relate them to previous work.}}, 
pages = {279--282}, 
number = {3}, 
volume = {70}, 
keywords = {}
}
@article{ashwin2001influence, 
year = {2001}, 
rating = {4}, 
title = {{Influence of noise on scalings for in-out intermittency}}, 
author = {Ashwin, Peter and Covas, Eurico and Tavakol, Reza}, 
journal = {Physical Review E}, 
issn = {1539-3755}, 
doi = {10.1103/physreve.64.066204}, 
pmid = {11736265}, 
abstract = {{We study the effects of noise on a recently discovered form of intermittency, referred to as in-out intermittency. This type of intermittency, which reduces to on-off in systems with a skew product structure, has been found in the dynamics of maps, (ODE) and (PDE) simulations that have symmetries. It shows itself in the form of trajectories that spend a long time near a symmetric state interspersed with short bursts away from symmetry. In contrast to on-off intermittency, there are clearly distinct mechanisms of approach towards and away from the symmetric state, and this needs to be taken into account in order to properly model the long time statistics. We do this by using a diffusion-type equation with a delay integral boundary condition. This model is validated by considering the statistics of a two-dimensional map with and without the addition of noise.}}, 
pages = {066204}, 
number = {6}, 
volume = {64}, 
keywords = {}
}
@article{cenis1997symmetry, 
year = {1997}, 
title = {{Symmetry between laminar and burst phases for on-off intermittency}}, 
author = {Čenys, A. and Anagnostopoulos, A. N. and Bleris, G. L.}, 
journal = {Physical Review E}, 
issn = {1539-3755}, 
doi = {10.1103/physreve.56.2592}, 
abstract = {{It is demonstrated both analytically and numerically that a symmetry exists between laminar and burst phases of on-off intermittency. The symmetry is a specific feature of on-off intermittency. It does not exist for the other types of regular Pomeau-Manneville and crisis-induced intermittency. A diffusional model, which incorporates reflecting barriers representing noise and nonlinearity, predicts the same scaling for the laminar and the burst lengths near the blowout bifurcation point. The symmetry of the scaling properties is demonstrated numerically for two systems exhibiting on-off intermittency, namely, the discrete three-dimensional Hénon map and the unidirectionally coupled Rössler oscillators.}}, 
pages = {2592--2596}, 
number = {3}, 
volume = {56}, 
keywords = {}
}
@article{grebogi1983crises, 
year = {1983}, 
title = {{Crises, sudden changes in chaotic attractors, and transient chaos}}, 
author = {Grebogi, Celso and Ott, Edward and Yorke, James A.}, 
journal = {Physica D: Nonlinear Phenomena}, 
issn = {0167-2789}, 
doi = {10.1016/0167-2789(83)90126-4}, 
abstract = {{The occurrence of sudden qualitative changes of chaotic dynamics as a parameter is varied is discussed and illustrated. It is shown that such changes may result from the collision of an unstable periodic orbit and a coexisting chaotic attractor. We call such collisions crises. Phenomena associated with crises include sudden changes in the size of chaotic attractors, sudden appearances of chaotic attractors (a possible route to chaos), and sudden destructions of chaotic attractors and their basins. This paper presents examples illustrating that crisis events are prevalent in many circumstances and systems, and that, just past a crisis, certain characteristic statistical behavior (whose type depends on the type of crisis) occurs. In particular the phenomenon of chaotic transients is investigated. The examples discussed illustrate crises in progressively higher dimension and include the one-dimensional quadratic map, the (two-dimensional) Hénon map, systems of ordinary differential equations in three dimensions and a three-dimensional map. In the case of our study of the three-dimensional map a new route to chaos is proposed which is possible only in invertible maps or flows of dimension at least three or four, respectively. Based on the examples presented the following conjecture is proposed: almost all sudden changes in the size of chaotic attractors and almost all sudden destruction or creations of chaotic attractors and their basins are due to crises.}}, 
pages = {181--200}, 
number = {1-3}, 
volume = {7}, 
keywords = {}
}
@article{ishii1986breakdown, 
year = {1986}, 
title = {{Breakdown of chaos symmetry and intermittency in the double-well potential system}}, 
author = {Ishii, Hiroaki and Fujisaka, Hirokazu and Inoue, Masayoshi}, 
journal = {Physics Letters A}, 
issn = {0375-9601}, 
doi = {10.1016/0375-9601(86)90590-6}, 
abstract = {{The chaos-chaos transition in a one-particle system in the symmetric double-well potential under an external periodic field is studied from the viewpoint of the breakdown of the chaos symmetry and the development of the intermittency characteristics. It is found that the similarity exponent introduced to analyze the intermittency characteristics satisfies a scaling law near the transition point.}}, 
pages = {257--263}, 
number = {6}, 
volume = {116}, 
keywords = {}
}
@article{kuznetsov, 
year = {2004}, 
title = {{Elements of Applied Bifurcation Theory}}, 
author = {Kuznetsov, Yuri A.}, 
journal = {Applied Mathematical Sciences}, 
issn = {0066-5452}, 
doi = {10.1007/978-1-4757-3978-7}, 
keywords = {}
}
@article{10.1001/jamapsychiatry.2017.0273, 
year = {2017}, 
title = {{Consciousness as Sequential Dynamics, Robustness, and Mental Disorders}}, 
author = {Rabinovich, Mikhail I. and Varona, Pablo}, 
journal = {JAMA Psychiatry}, 
issn = {2168-622X}, 
doi = {10.1001/jamapsychiatry.2017.0273}, 
pmid = {28564683}, 
pages = {771}, 
number = {8}, 
volume = {74}, 
keywords = {}
}
@article{10.3389/fncom.2011.00024, 
year = {2011}, 
title = {{Robust Transient Dynamics and Brain Functions}}, 
author = {Rabinovich, Mikhail I. and Varona, Pablo}, 
journal = {Frontiers in Computational Neuroscience}, 
doi = {10.3389/fncom.2011.00024}, 
pmid = {21716642}, 
pmcid = {PMC3116137}, 
abstract = {{In the last few decades several concepts of dynamical systems theory (DST) have guided psychologists, cognitive scientists, and neuroscientists to rethink about sensory motor behavior and embodied cognition. A critical step in the progress of DST application to the brain (supported by modern methods of brain imaging and multi-electrode recording techniques) has been the transfer of its initial success in motor behavior to mental function, i.e., perception, emotion, and cognition. Open questions from research in genetics, ecology, brain sciences, etc., have changed DST itself and lead to the discovery of a new dynamical phenomenon, i.e., reproducible and robust transients that are at the same time sensitive to informational signals. The goal of this review is to describe a new mathematical framework – heteroclinic sequential dynamics – to understand self-organized activity in the brain that can explain certain aspects of robust itinerant behavior. Specifically, we discuss a hierarchy of coarse-grain models of mental dynamics in the form of kinetic equations of modes. These modes compete for resources at three levels: (i) within the same modality, (ii) among different modalities from the same family (like perception), and (iii) among modalities from different families (like emotion and cognition). The analysis of the conditions for robustness, i.e., the structural stability of transient (sequential) dynamics, give us the possibility to explain phenomena like the finite capacity of our sequential working memory – a vital cognitive function –, and to find specific dynamical signatures – different kinds of instabilities – of several brain functions and mental diseases.}}, 
pages = {24}, 
volume = {5}, 
keywords = {}
}
@article{nowotny2007dynamical, 
year = {2007}, 
title = {{Dynamical Origin of Independent Spiking and Bursting Activity in Neural Microcircuits}}, 
author = {Nowotny, Thomas and Rabinovich, Mikhail I}, 
journal = {Physical Review Letters}, 
issn = {0031-9007}, 
doi = {10.1103/physrevlett.98.128106}, 
pmid = {17501162}, 
abstract = {{The relationship between spiking and bursting dynamics is a key question in neuroscience, particularly in understanding the origins of different neural coding strategies and the mechanisms of motor command generation and neural circuit coordination. Experiments indicate that spiking and bursting dynamics can be independent. We hypothesize that different mechanisms for spike and burst generation, intrinsic neuron dynamics for spiking and a modulational network instability for bursting, are the origin of this independence. We tested the hypothesis in a detailed dynamical analysis of a minimal inhibitory neural microcircuit (motif) of three reciprocally connected Hodgkin-Huxley neurons. We reduced this high-dimensional dynamical system to a rate model and showed that both systems have identical bifurcations from tonic spiking to burst generation, which, therefore, does not depend on the details of spiking activity.}}, 
pages = {128106}, 
number = {12}, 
volume = {98}, 
keywords = {}
}
@article{li2009burst, 
year = {2009}, 
title = {{Burst Spiking of a Single Cortical Neuron Modifies Global Brain State}}, 
author = {Li, Cheng-yu T. and Poo, Mu-ming and Dan, Yang}, 
journal = {Science}, 
issn = {0036-8075}, 
doi = {10.1126/science.1169957}, 
pmid = {19407203}, 
pmcid = {PMC2913066}, 
abstract = {{Different global patterns of brain activity are associated with distinct arousal and behavioral states of an animal, but how the brain rapidly switches between different states remains unclear. We here report that repetitive high-frequency burst spiking of a single rat cortical neuron could trigger a switch between the cortical states resembling slow-wave and rapid–eye-movement sleep. This is reflected in the switching of the membrane potential of the stimulated neuron from slow UP/DOWN oscillations to a persistent-UP state or vice versa, with concurrent changes in the temporal pattern of cortical local field potential (LFP) recorded several millimeters away. These results point to the power of single cortical neurons in modulating the behavioral state of an animal.}}, 
pages = {643--646}, 
number = {5927}, 
volume = {324}, 
keywords = {}
}
@article{carlson2011sample, 
year = {2011}, 
title = {{Sample-to-sample fluctuations in real-network ensembles}}, 
author = {Carlson, Nicole and Kim, Dong-Hee and Motter, Adilson E.}, 
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science}, 
issn = {1054-1500}, 
doi = {10.1063/1.3602223}, 
pmid = {21721783}, 
eprint = {1111.6118}, 
abstract = {{Network modeling based on ensemble averages tacitly assumes that the networks meant to be modeled are typical in the ensemble. Previous research on network eigenvalues, which govern a range of dynamical phenomena, has shown that this is indeed the case for uncorrelated networks with minimum degree ≥ 3. Here, we focus on real networks, which generally have both structural correlations and low-degree nodes. We show that: (i) the ensemble distribution of the dynamically most important eigenvalues can be not only broad and far apart from the real eigenvalue but also highly structured, often with a multimodal rather than a bell-shaped form; (ii) these interesting properties are found to be due to low-degree nodes, mainly those with degree ≤ 3, and network communities, which is a common form of structural correlation found in real networks. In addition to having implications for ensemble-based approaches, this shows that low-degree nodes may have a stronger influence on collective dynamics than previously anticipated from the study of computer-generated networks.}}, 
pages = {025105}, 
number = {2}, 
volume = {21}, 
keywords = {}
}
@article{mihara2022sparsity, 
year = {2022}, 
title = {{Sparsity-driven synchronization in oscillator networks}}, 
author = {Mihara, Antonio and Medeiros, Everton S. and Zakharova, Anna and Medrano-T, Rene O.}, 
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science}, 
issn = {1054-1500}, 
doi = {10.1063/5.0074008}, 
pmid = {35364836}, 
eprint = {2111.13583}, 
abstract = {{The emergence of synchronized behavior is a direct consequence of networking dynamical systems. Naturally, strict instances of this phenomenon, such as the states of complete synchronization, are favored or even ensured in networks with a high density of connections. Conversely, in sparse networks, the system state-space is often shared by a variety of coexistent solutions. Consequently, the convergence to complete synchronized states is far from being certain. In this scenario, we report the surprising phenomenon in which completely synchronized states are made the sole attractor of sparse networks by removing network links, the sparsity-driven synchronization. This phenomenon is observed numerically for nonlocally coupled Kuramoto networks and verified analytically for locally coupled ones. In addition, we unravel the bifurcation scenario underlying the network transition to completely synchronized behavior. Furthermore, we present a simple procedure, based on the bifurcations in the thermodynamic limit, that determines the minimum number of links to be removed in order to ensure complete synchronization. Finally, we propose an application of the reported phenomenon as a control scheme to drive complete synchronization in high connectivity networks.}}, 
pages = {033114}, 
number = {3}, 
volume = {32}, 
keywords = {}
}
@article{10.1063/1.4959146, 
year = {2016}, 
title = {{Stochastic basins of attraction for metastable states}}, 
author = {Serdukova, Larissa and Zheng, Yayun and Duan, Jinqiao and Kurths, Jürgen}, 
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science}, 
issn = {1054-1500}, 
doi = {10.1063/1.4959146}, 
pmid = {27475077}, 
abstract = {{Basin of attraction of a stable equilibrium point is an effective concept for stability analysis in deterministic systems; however, it does not contain information on the external perturbations that may affect it. Here we introduce the concept of stochastic basin of attraction (SBA) by incorporating a suitable probabilistic notion of basin. We define criteria for the size of the SBA based on the escape probability, which is one of the deterministic quantities that carry dynamical information and can be used to quantify dynamical behavior of the corresponding stochastic basin of attraction. SBA is an efficient tool to describe the metastable phenomena complementing the known exit time, escape probability, or relaxation time. Moreover, the geometric structure of SBA gives additional insight into the system's dynamical behavior, which is important for theoretical and practical reasons. This concept can be used not only in models with small noise intensity but also with noise whose amplitude is proportional or in general is a function of an order parameter. As an application of our main results, we analyze a three potential well system perturbed by two types of noise: Brownian motion and non-Gaussian α-stable Lévy motion. Our main conclusions are that the thermal fluctuations stabilize the metastable system with an asymmetric three-well potential but have the opposite effect for a symmetric one. For Lévy noise with larger jumps and lower jump frequencies ( α = 0.5) metastability is enhanced for both symmetric and asymmetric potentials.}}, 
pages = {073117}, 
number = {7}, 
volume = {26}, 
keywords = {}
}
@article{10.1007/bf02219225, 
year = {1997}, 
title = {{Random attractors}}, 
author = {Crauel, Hans and Debussche, Arnaud and Flandoli, Franco}, 
journal = {Journal of Dynamics and Differential Equations}, 
issn = {1040-7294}, 
doi = {10.1007/bf02219225}, 
abstract = {{In this paper, we generalize the notion of an attractor for the stochastic dynamical system introduced in [7]. We prove that the stochastic attractor satisfies most of the properties satisfied by the usual attractor in the theory of deterministic dynamical systems. We also show that our results apply to the stochastic Navier-Stokes equation, the white noise-driven Burgers equation, and a nonlinear stochastic wave equation.}}, 
pages = {307--341}, 
number = {2}, 
volume = {9}, 
keywords = {}
}
@article{rossi2022github, 
year = {2022}, 
title = {{Repository for dynamical malleability code}}, 
author = {Rossi, Kalel}, 
journal = {Github Repository}, 
url = {https://github.com/KalelR/dynamicalmalleability}, 
keywords = {}
}
@book{olivieri2005large, 
year = {2005}, 
title = {{Large Deviations and Metastability}}, 
author = {Olivieri, Enzo and Vares, Maria Eulália}, 
isbn = {978-0-521-59163-8}, 
abstract = {{The van der Waals–Maxwell theory Metastability is a relevant phenomenon for thermodynamic systems close to a first order phase transition. Examples are supercooled vapours and liquids, super-saturated vapours and solutions, as well as ferromagnets in the part of the hysteresis loop where the magnetization is opposite to the external magnetic field. A metastable state occurs when some thermodynamic parameter such as the temperature, pressure or magnetic field is changed from a value giving rise to a stable state with a unique phase, say X, to one for which at least part of the system should be in some new equilibrium phase Y. Then, in particular experimental situations, instead of undergoing the phase transition, the system goes over continuously into a ‘false’ equilibrium state with a unique phase X′, far from Y but actually close to the initial equilibrium phase X. It is this apparent equilibrium situation that is called a ‘metastable state’. Its properties are very similar to those of the stable equilibrium state; for example for a supersaturated vapour one can determine the pressure experimentally as a function of the temperature and the specific volume. We speak of the ‘metastable branch’ of the isothermal curve. The distinguishing feature of metastability is that, eventually, either via an external perturbation or via a spontaneous fluctuation, a nucleus of the new phase appears, starting an irreversible process which leads to the stable equilibrium state Y, where the phase transition has taken place.}}, 
series = {Encyclopedia of Mathematics and its Applications}, 
publisher = {Cambridge University Press}, 
address = {Cambridge}, 
keywords = {}, 
doi = {10.1017/cbo9780511543272.005}
}
@article{ashwin2011criteria, 
year = {2011}, 
title = {{Criteria for robustness of heteroclinic cycles in neural microcircuits}}, 
author = {Ashwin, Peter and Karabacak, Ozkan and Nowotny, Thomas}, 
journal = {The Journal of Mathematical Neuroscience}, 
issn = {2190-8567}, 
doi = {10.1186/2190-8567-1-13}, 
pmid = {22656192}, 
pmcid = {PMC3365877}, 
abstract = {{We introduce a test for robustness of heteroclinic cycles that appear in neural microcircuits modeled as coupled dynamical cells. Robust heteroclinic cycles (RHCs) can appear as robust attractors in Lotka-Volterra-type winnerless competition (WLC) models as well as in more general coupled and/or symmetric systems. It has been previously suggested that RHCs may be relevant to a range of neural activities, from encoding and binding to spatio-temporal sequence generation. The robustness or otherwise of such cycles depends both on the coupling structure and the internal structure of the neurons. We verify that robust heteroclinic cycles can appear in systems of three identical cells, but only if we require perturbations to preserve some invariant subspaces for the individual cells. On the other hand, heteroclinic attractors can appear robustly in systems of four or more identical cells for some symmetric coupling patterns, without restriction on the internal dynamics of the cells.}}, 
pages = {13}, 
number = {1}, 
volume = {1}, 
keywords = {}
}
@article{jones2007natural, 
year = {2007}, 
title = {{Natural stimuli evoke dynamic sequences of states in sensory cortical ensembles}}, 
author = {Jones, Lauren M. and Fontanini, Alfredo and Sadacca, Brian F. and Miller, Paul and Katz, Donald B.}, 
journal = {Proceedings of the National Academy of Sciences}, 
issn = {0027-8424}, 
doi = {10.1073/pnas.0705546104}, 
pmid = {18000059}, 
pmcid = {PMC2141852}, 
abstract = {{Although temporal coding is a frequent topic of neurophysiology research, trial-to-trial variability in temporal codes is typically dismissed as noise and thought to play no role in sensory function. Here, we show that much of this supposed “noise” faithfully reflects stimulus-related processes carried out in coherent neural networks. Cortical neurons responded to sensory stimuli by progressing through sequences of states, identifiable only in examinations of simultaneously recorded ensembles. The specific times at which ensembles transitioned from state to state varied from trial to trial, but the state sequences were reliable and stimulus-specific. Thus, the characterization of ensemble responses in terms of state sequences captured facets of sensory processing that are missing from, and obscured in, other analyses. This work provides evidence that sensory neurons act as parts of a systems-level dynamic process, the nature of which can best be appreciated through observation of distributed ensembles.}}, 
pages = {18772--18777}, 
number = {47}, 
volume = {104}, 
keywords = {}
}
@article{10.1088/1367-2630/aaf0d7, 
year = {2018}, 
title = {{Characterizing abrupt transitions in stochastic dynamics}}, 
author = {Lehnertz, Klaus and Zabawa, Lina and Tabar, M Reza Rahimi}, 
journal = {New Journal of Physics}, 
doi = {10.1088/1367-2630/aaf0d7}, 
abstract = {{Data sampled at discrete times appears as a succession of discontinuous jumps, even if the underlying trajectory is continuous. We analytically derive a criterion that allows one to check whether for a given, even noisy time series the underlying process has a continuous (diffusion) trajectory or has jump discontinuities. This enables one to detect and characterize abrupt changes (jump events) in given time series. The proposed criterion is validated numerically using synthetic continuous and discontinuous time series. We demonstrate applicability of our criterion to distinguish diffusive and jumpy behavior by a data-driven inference of higher-order conditional moments from empirical observations.}}, 
pages = {113043}, 
number = {11}, 
volume = {20}, 
keywords = {}
}
@article{jercog2017updown, 
year = {2017}, 
title = {{UP-DOWN cortical dynamics reflect state transitions in a bistable network}}, 
author = {Jercog, Daniel and Roxin, Alex and Barthó, Peter and Luczak, Artur and Compte, Albert and Rocha, Jaime de la}, 
journal = {eLife}, 
doi = {10.7554/elife.22425}, 
pmid = {28826485}, 
pmcid = {PMC5582872}, 
abstract = {{In the idling brain, neuronal circuits transition between periods of sustained firing (UP state) and quiescence (DOWN state), a pattern the mechanisms of which remain unclear. Here we analyzed spontaneous cortical population activity from anesthetized rats and found that UP and DOWN durations were highly variable and that population rates showed no significant decay during UP periods. We built a network rate model with excitatory (E) and inhibitory (I) populations exhibiting a novel bistable regime between a quiescent and an inhibition-stabilized state of arbitrarily low rate. Fluctuations triggered state transitions, while adaptation in E cells paradoxically caused a marginal decay of E-rate but a marked decay of I-rate in UP periods, a prediction that we validated experimentally. A spiking network implementation further predicted that DOWN-to-UP transitions must be caused by synchronous high-amplitude events. Our findings provide evidence of bistable cortical networks that exhibit non-rhythmic state transitions when the brain rests.}}, 
pages = {e22425}, 
volume = {6}, 
keywords = {}
}
@article{mazor2005transient, 
year = {2005}, 
rating = {5}, 
title = {{Transient Dynamics versus Fixed Points in Odor Representations by Locust Antennal Lobe Projection Neurons}}, 
author = {Mazor, Ofer and Laurent, Gilles}, 
journal = {Neuron}, 
issn = {0896-6273}, 
doi = {10.1016/j.neuron.2005.09.032}, 
pmid = {16301181}, 
abstract = {{Projection neurons (PNs) in the locust antennal lobe exhibit odor-specific dynamic responses. We studied a PN population, stimulated with five odorants and pulse durations between 0.3 and 10 s. Odor representations were characterized as time series of vectors of PN activity, constructed from the firing rates of all PNs in successive 50 ms time bins. Odor representations by the PN population can be described as trajectories in PN state space with three main phases: an on transient, lasting 1–2 s; a fixed point, stable for at least 8 s; and an off transient, lasting a few seconds as activity returns to baseline. Whereas all three phases are odor specific, optimal stimulus separation occurred during the transients rather than the fixed points. In addition, the PNs’ own target neurons respond least when their PN-population input stabilized at a fixed point. Steady-state measures of activity thus seem inappropriate to understand the neural code in this system.}}, 
pages = {661--673}, 
number = {4}, 
volume = {48}, 
keywords = {}
}
@article{10.1016/j.neuron.2017.05.025, 
year = {2017}, 
title = {{Neural Manifolds for the Control of Movement}}, 
author = {Gallego, Juan A. and Perich, Matthew G. and Miller, Lee E. and Solla, Sara A.}, 
journal = {Neuron}, 
issn = {0896-6273}, 
doi = {10.1016/j.neuron.2017.05.025}, 
pmid = {28595054}, 
pmcid = {PMC6122849}, 
abstract = {{The analysis of neural dynamics in several brain cortices has consistently uncovered low-dimensional manifolds that capture a significant fraction of neural variability. These neural manifolds are spanned by specific patterns of correlated neural activity, the “neural modes.” We discuss a model for neural control of movement in which the time-dependent activation of these neural modes is the generator of motor behavior. This manifold-based view of motor cortex may lead to a better understanding of how the brain controls movement.}}, 
pages = {978--984}, 
number = {5}, 
volume = {94}, 
keywords = {}
}
@article{popa2009constracting, 
year = {2009}, 
title = {{Contrasting Activity Profile of Two Distributed Cortical Networks as a Function of Attentional Demands}}, 
author = {Popa, D and Popescu, A T and Pare, D}, 
journal = {Journal of Neuroscience}, 
issn = {0270-6474}, 
doi = {10.1523/jneurosci.4867-08.2009}, 
pmid = {19176827}, 
pmcid = {PMC2667329}, 
abstract = {{Recent human functional MRI (fMRI) studies have revealed that two widely distributed groups of cortical areas display inverse changes in activity when attentional demands increase, with one group showing higher (task-on) and the second lower (task-off) blood oxygen level-dependent (BOLD) signals. Moreover, task-on and task-off regions also exhibit slow (<0.2 Hz) inversely correlated fluctuations in BOLD signal at rest. However, the neuronal correlates of these reciprocal BOLD signal fluctuations are unknown. Here, we addressed this question using simultaneous recordings of unit activity and local field potentials (LFPs) in the cat homologues of task-on and task-off regions. In all states of vigilance, LFP power was lower in task-off than task-on regions with no difference in firing rates. Both sets of regions displayed slow (0.5-0.15 Hz) cyclical modulations in LFP power in all frequency bands but with large and variable phase differences such that task-on and task-off regions were often anticorrelated. Inversely correlated LFP power fluctuations were state-dependent in that they were much more frequent in waking and paradoxical sleep than in slow-wave sleep. Moreover, consistent with fMRI findings, when attentional demands increased, LFP power in task-on and task-off regions changed in opposite directions, further augmenting and decreasing, respectively. At odds with previous fMRI studies, however, the decreased LFP power in task-off regions was associated with increased firing rates, suggesting that the engagement of task-off regions might not be reduced but in fact enhanced during attention.}}, 
pages = {1191--1201}, 
number = {4}, 
volume = {29}, 
keywords = {}
}
@article{10.1523/jneurosci.2249-05.2005, 
year = {2005}, 
title = {{The Role of Sensory Network Dynamics in Generating a Motor Program}}, 
author = {Levi, Rafael and Varona, Pablo and Arshavsky, Yuri I and Rabinovich, Mikhail I and Selverston, Allen I}, 
journal = {Journal of Neuroscience}, 
issn = {0270-6474}, 
doi = {10.1523/jneurosci.2249-05.2005}, 
pmid = {16237184}, 
pmcid = {PMC6725745}, 
abstract = {{Sensory input plays a major role in controlling motor responses during most behavioral tasks. The vestibular organs in the marine mollusk Clione, the statocysts, react to the external environment and continuously adjust the tail and wing motor neurons to keep the animal oriented vertically. However, we suggested previously that during hunting behavior, the intrinsic dynamics of the statocyst network produce a spatiotemporal pattern that may control the motor system independently of environmental cues. Once the response is triggered externally, the collective activation of the statocyst neurons produces a complex sequential signal. In the behavioral context of hunting, such network dynamics may be the main determinant of an intricate spatial behavior. Here, we show that (1) during fictive hunting, the population activity of the statocyst receptors is correlated positively with wing and tail motor output suggesting causality, (2) that fictive hunting can be evoked by electrical stimulation of the statocyst network, and (3) that removal of even a few individual statocyst receptors critically changes the fictive hunting motor pattern. These results indicate that the intrinsic dynamics of a sensory network, even without its normal cues, can organize a motor program vital for the survival of the animal.}}, 
pages = {9807--9815}, 
number = {42}, 
volume = {25}, 
keywords = {}
}
@article{10.1152/jn.00753.2003, 
year = {2004}, 
title = {{Dual Sensory-Motor Function for a Molluskan Statocyst Network}}, 
author = {Levi, R. and Varona, P. and Arshavsky, Y. I. and Rabinovich, M. I. and Selverston, A. I.}, 
journal = {Journal of Neurophysiology}, 
issn = {0022-3077}, 
doi = {10.1152/jn.00753.2003}, 
pmid = {14507988}, 
abstract = {{In mollusks, statocyst receptor cells (SRCs) interact with each other forming a neural network; their activity is determined by both the animal's orientation in the gravitational field and multimodal inputs. These two facts suggest that the function of the statocysts is not limited to sensing the animal's orientation. We studied the role of the statocysts in the organization of search motion during hunting behavior in the marine mollusk, Clione limacina. When hunting, Clione swims along a complex trajectory including numerous twists and turns confined within a definite space. Search-like behavior could be evoked pharmacologically by physostigmine; application of physostigmine to the isolated CNS produced “fictive search behavior” monitored by recordings from wing and tail nerves. Both in behavioral and in vitro experiments, we found that the statocysts are necessary for search behavior. The motor program typical of searching could not be produced after removing the statocysts. Simultaneous recordings from single SRCs and motor nerves showed that there was a correlation between the SRCs activity and search episodes. This correlation occurred even though the preparation was fixed and, therefore the sensory stimulus was constant. The excitation of individual SRCs could in some cases precede the beginning of search episodes. A biologically based model showed that, theoretically, the hunting search motor program could be generated by the statocyst receptor network due to its intrinsic dynamics. The results presented support for the idea that the statocysts are actively involved in the production of the motor program underlying search movements during hunting behavior.}}, 
pages = {336--345}, 
number = {1}, 
volume = {91}, 
keywords = {}
}
@article{10.1063/1.1498155, 
year = {2002}, 
title = {{Winnerless competition between sensory neurons generates chaos: A possible mechanism for molluscan hunting behavior}}, 
author = {Varona, Pablo and Rabinovich, Mikhail I. and Selverston, Allen I. and Arshavsky, Yuri I.}, 
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science}, 
issn = {1054-1500}, 
doi = {10.1063/1.1498155}, 
pmid = {12779595}, 
abstract = {{In the presence of prey, the marine mollusk Clione limacina exhibits search behavior, i.e., circular motions whose plane and radius change in a chaotic-like manner. We have formulated a dynamical model of the chaotic hunting behavior of Clione based on physiological in vivo and in vitro experiments. The model includes a description of the action of the cerebral hunting interneuron on the receptor neurons of the gravity sensory organ, the statocyst. A network of six receptor model neurons with Lotka–Volterra-type dynamics and nonsymmetric inhibitory interactions has no simple static attractors that correspond to winner take all phenomena. Instead, the winnerless competition induced by the hunting neuron displays hyperchaos with two positive Lyapunov exponents. The origin of the chaos is related to the interaction of two clusters of receptor neurons that are described with two heteroclinic loops in phase space. We hypothesize that the chaotic activity of the receptor neurons can drive the complex behavior of Clione observed during hunting.}}, 
pages = {672--677}, 
number = {3}, 
volume = {12}, 
keywords = {}
}
@article{ito2008dynamics, 
year = {2007}, 
title = {{Dynamics of spontaneous transitions between global brain states}}, 
author = {Ito, Junji and Nikolaev, Andrey R. and Leeuwen, Cees van}, 
journal = {Human Brain Mapping}, 
issn = {1065-9471}, 
doi = {10.1002/hbm.20316}, 
pmid = {17315223}, 
pmcid = {PMC6871463}, 
abstract = {{Phase patterns of human scalp alpha EEG activity show spontaneous transitions between different globally phase‐synchronized states. We studied the dynamical properties of these transitions using the method of symbolic dynamics. We found greater predictability (deterministicity) and heterogeneity in the dynamics than what was expected from corresponding surrogate series in which linear correlations are retained. A possible explanation of these observations within the framework of chaotic itinerancy is discussed. Hum Brain Mapp, 2007. © 2007 Wiley‐Liss, Inc.}}, 
pages = {904--913}, 
number = {9}, 
volume = {28}, 
keywords = {}
}
@article{10.1016/j.neuron.2013.01.031, 
year = {2013}, 
title = {{Making Waves: Initiation and Propagation of Corticothalamic Ca2+ Waves In Vivo}}, 
author = {Stroh, Albrecht and Adelsberger, Helmuth and Groh, Alexander and Rühlmann, Charlotta and Fischer, Sebastian and Schierloh, Anja and Deisseroth, Karl and Konnerth, Arthur}, 
journal = {Neuron}, 
issn = {0896-6273}, 
doi = {10.1016/j.neuron.2013.01.031}, 
pmid = {23522048}, 
abstract = {{Corticothalamic slow oscillations of neuronal activity determine internal brain states. At least in the cortex, the electrical activity is associated with large neuronal Ca2+ transients. Here we implemented an optogenetic approach to explore causal features of the generation of slow oscillation-associated Ca2+ waves in the in vivo mouse brain. We demonstrate that brief optogenetic stimulation (3–20 ms) of a local group of layer 5 cortical neurons is sufficient for the induction of global brain Ca2+ waves. These Ca2+ waves are evoked in an all-or-none manner, exhibit refractoriness during repetitive stimulation, and propagate over long distances. By local optogenetic stimulation, we demonstrate that evoked Ca2+ waves initially invade the cortex, followed by a secondary recruitment of the thalamus. Together, our results establish that synchronous activity in a small cluster of layer 5 cortical neurons can initiate a global neuronal wave of activity suited for long-range corticothalamic integration.}}, 
pages = {1136--1150}, 
number = {6}, 
volume = {77}, 
keywords = {}
}
@article{marder2001central, 
year = {2001}, 
title = {{Central pattern generators and the control of rhythmic movements}}, 
author = {Marder, Eve and Bucher, Dirk}, 
journal = {Current Biology}, 
issn = {0960-9822}, 
doi = {10.1016/s0960-9822(01)00581-4}, 
pmid = {11728329}, 
abstract = {{Central pattern generators are neuronal circuits that when activated can produce rhythmic motor patterns such as walking, breathing, flying, and swimming in the absence of sensory or descending inputs that carry specific timing information. General principles of the organization of these circuits and their control by higher brain centers have come from the study of smaller circuits found in invertebrates. Recent work on vertebrates highlights the importance of neuro-modulatory control pathways in enabling spinal cord and brain stem circuits to generate meaningful motor patterns. Because rhythmic motor patterns are easily quantified and studied, central pattern generators will provide important testing grounds for understanding the effects of numerous genetic mutations on behavior. Moreover, further understanding of the modulation of spinal cord circuitry used in rhythmic behaviors should facilitate the development of new treatments to enhance recovery after spinal cord damage.}}, 
pages = {R986--R996}, 
number = {23}, 
volume = {11}, 
keywords = {}
}
@article{michel2017eeg, 
year = {2017}, 
title = {{EEG microstates as a tool for studying the temporal dynamics of whole-brain neuronal networks: A review}}, 
author = {Michel, Christoph M. and Koenig, Thomas}, 
journal = {NeuroImage}, 
issn = {1053-8119}, 
doi = {10.1016/j.neuroimage.2017.11.062}, 
pmid = {29196270}, 
abstract = {{The present review discusses a well-established method for characterizing resting-state activity of the human brain using multichannel electroencephalography (EEG). This method involves the examination of electrical microstates in the brain, which are defined as successive short time periods during which the configuration of the scalp potential field remains semi-stable, suggesting quasi-simultaneity of activity among the nodes of large-scale networks. A few prototypic microstates, which occur in a repetitive sequence across time, can be reliably identified across participants. Researchers have proposed that these microstates represent the basic building blocks of the chain of spontaneous conscious mental processes, and that their occurrence and temporal dynamics determine the quality of mentation. Several studies have further demonstrated that disturbances of mental processes associated with neurological and psychiatric conditions manifest as changes in the temporal dynamics of specific microstates. Combined EEG-fMRI studies and EEG source imaging studies have indicated that EEG microstates are closely associated with resting-state networks as identified using fMRI. The scale-free properties of the time series of EEG microstates explain why similar networks can be observed at such different time scales. The present review will provide an overview of these EEG microstates, available methods for analysis, the functional interpretations of findings regarding these microstates, and their behavioral and clinical correlates.}}, 
pages = {577--593}, 
number = {Pt B}, 
volume = {180}, 
keywords = {}
}
@article{rabinovich2008transientdynamics, 
year = {2008}, 
title = {{Transient Dynamics for Neural Processing}}, 
author = {Rabinovich, Misha and Huerta, Ramon and Laurent, Gilles}, 
journal = {Science}, 
issn = {0036-8075}, 
doi = {10.1126/science.1155564}, 
pmid = {18599763}, 
pages = {48--50}, 
number = {5885}, 
volume = {321}, 
keywords = {}
}
@article{dehaene2005ongoing, 
year = {2005}, 
title = {{Ongoing Spontaneous Activity Controls Access to Consciousness: A Neuronal Model for Inattentional Blindness}}, 
author = {Dehaene, Stanislas and Changeux, Jean-Pierre}, 
journal = {PLoS Biology}, 
issn = {1544-9173}, 
doi = {10.1371/journal.pbio.0030141}, 
pmid = {15819609}, 
pmcid = {PMC1074751}, 
abstract = {{Even in the absence of sensory inputs, cortical and thalamic neurons can show structured patterns of ongoing spontaneous activity, whose origins and functional significance are not well understood. We use computer simulations to explore the conditions under which spontaneous activity emerges from a simplified model of multiple interconnected thalamocortical columns linked by long-range, top-down excitatory axons, and to examine its interactions with stimulus-induced activation. Simulations help characterize two main states of activity. First, spontaneous gamma-band oscillations emerge at a precise threshold controlled by ascending neuromodulator systems. Second, within a spontaneously active network, we observe the sudden “ignition” of one out of many possible coherent states of high-level activity amidst cortical neurons with long-distance projections. During such an ignited state, spontaneous activity can block external sensory processing. We relate those properties to experimental observations on the neural bases of endogenous states of consciousness, and particularly the blocking of access to consciousness that occurs in the psychophysical phenomenon of “inattentional blindness,” in which normal subjects intensely engaged in mental activity fail to notice salient but irrelevant sensory stimuli. Although highly simplified, the generic properties of a minimal network may help clarify some of the basic cerebral phenomena underlying the autonomy of consciousness.}}, 
pages = {e141}, 
number = {5}, 
volume = {3}, 
keywords = {}
}
@article{mashour2020conscious, 
year = {2020}, 
title = {{Conscious Processing and the Global Neuronal Workspace Hypothesis}}, 
author = {Mashour, George A. and Roelfsema, Pieter and Changeux, Jean-Pierre and Dehaene, Stanislas}, 
journal = {Neuron}, 
issn = {0896-6273}, 
doi = {10.1016/j.neuron.2020.01.026}, 
pmid = {32135090}, 
pmcid = {PMC8770991}, 
abstract = {{We review the central tenets and neuroanatomical basis of the global neuronal workspace (GNW) hypothesis, which attempts to account for the main scientific observations regarding the elementary mechanisms of conscious processing in the human brain. The GNW hypothesis proposes that, in the conscious state, a non-linear network ignition associated with recurrent processing amplifies and sustains a neural representation, allowing the corresponding information to be globally accessed by local processors. We examine this hypothesis in light of recent data that contrast brain activity evoked by either conscious or non-conscious contents, as well as during conscious or non-conscious states, particularly general anesthesia. We also discuss the relationship between the intertwined concepts of conscious processing, attention, and working memory.}}, 
pages = {776--798}, 
number = {5}, 
volume = {105}, 
keywords = {}
}
@article{seidemann1996simultaneously, 
year = {1996}, 
title = {{Simultaneously recorded single units in the frontal cortex go through sequences of discrete and stable states in monkeys performing a delayed localization task}}, 
author = {Seidemann, E and Meilijson, I and Abeles, M and Bergman, H and Vaadia, E}, 
journal = {The Journal of Neuroscience}, 
issn = {0270-6474}, 
doi = {10.1523/jneurosci.16-02-00752.1996}, 
pages = {752--768}, 
number = {2}, 
volume = {16}, 
keywords = {}
}
@article{pomeau1980intermittent, 
year = {1980}, 
title = {{Intermittent transition to turbulence in dissipative dynamical systems}}, 
author = {Pomeau, Yves and Manneville, Paul}, 
journal = {Communications in Mathematical Physics}, 
issn = {0010-3616}, 
doi = {10.1007/bf01197757}, 
abstract = {{We study some simple dissipative dynamical systems exhibiting a transition from a stable periodic behavior to a chaotic one. At that transition, the inverse coherence time grows continuously from zero due to the random occurrence of widely separated bursts in the time record.}}, 
pages = {189--197}, 
number = {2}, 
volume = {74}, 
keywords = {}
}
@article{abeles1995cortical, 
year = {1995}, 
title = {{Cortical activity flips among quasi-stationary states.}}, 
author = {Abeles, M and Bergman, H and Gat, I and Meilijson, I and Seidemann, E and Tishby, N and Vaadia, E}, 
journal = {Proceedings of the National Academy of Sciences}, 
issn = {0027-8424}, 
doi = {10.1073/pnas.92.19.8616}, 
pmid = {7567985}, 
pmcid = {PMC41017}, 
abstract = {{Parallel recordings of spike trains of several single cortical neurons in behaving monkeys were analyzed as a hidden Markov process. The parallel spike trains were considered as a multivariate Poisson process whose vector firing rates change with time. As a consequence of this approach, the complete recording can be segmented into a sequence of a few statistically discriminated hidden states, whose dynamics are modeled as a first-order Markov chain. The biological validity and benefits of this approach were examined in several independent ways: (i) the statistical consistency of the segmentation and its correspondence to the behavior of the animals; (ii) direct measurement of the collective flips of activity, obtained by the model; and (iii) the relation between the segmentation and the pair-wise short-term cross-correlations between the recorded spike trains. Comparison with surrogate data was also carried out for each of the above examinations to assure their significance. Our results indicated the existence of well-separated states of activity, within which the firing rates were approximately stationary. With our present data we could reliably discriminate six to eight such states. The transitions between states were fast and were associated with concomitant changes of firing rates of several neurons. Different behavioral modes and stimuli were consistently reflected by different states of neural activity. Moreover, the pair-wise correlations between neurons varied considerably between the different states, supporting the hypothesis that these distinct states were brought about by the cooperative action of many neurons.}}, 
pages = {8616--8620}, 
number = {19}, 
volume = {92}, 
keywords = {}
}
@book{argyrisbook, 
year = {2015}, 
title = {{An Exploration of Dynamical Systems and Chaos}}, 
author = {Argyris, John H. and Faust, Gunter and Haase, Maria and Friedrich, Rudolf}, 
publisher = {Springer Berlin, Heidelberg}, 
keywords = {}, 
edition = {2}, 
doi = {10.1007/978-3-662-46042-9}
}
@book{callen1991thermodynamics, 
year = {1991}, 
title = {{Thermodynamics and an Introduction to Thermostatistics}}, 
author = {Callen, Herbert B.}, 
isbn = {978-0-471-86256-7}, 
publisher = {Wiley}, 
keywords = {}, 
edition = {2}
}
@article{kartanak2014route, 
year = {2014}, 
title = {{Route to extreme events in excitable systems}}, 
author = {Karnatak, Rajat and Ansmann, Gerrit and Feudel, Ulrike and Lehnertz, Klaus}, 
journal = {Physical Review E}, 
issn = {1539-3755}, 
doi = {10.1103/physreve.90.022917}, 
pmid = {25215809}, 
eprint = {1408.6439}, 
abstract = {{Systems of FitzHugh–Nagumo units with different coupling topologies are capable of self-generating and -terminating strong deviations from their regular dynamics that can be regarded as extreme events due to their rareness and recurrent occurrence. Here we demonstrate the crucial role of an interior crisis in the emergence of extreme events. In parameter space we identify this interior crisis as the organizing center of the dynamics by employing concepts of mixed-mode oscillations and of leaking chaotic systems. We find that extreme events occur in certain regions in parameter space, and we show the robustness of this phenomenon with respect to the system size.}}, 
pages = {022917}, 
number = {2}, 
volume = {90}, 
keywords = {}
}
@article{luczak2007sequential, 
year = {2007}, 
title = {{Sequential structure of neocortical spontaneous activity in vivo}}, 
author = {Luczak, Artur and Barthó, Peter and Marguet, Stephan L. and Buzsáki, György and Harris, Kenneth D.}, 
journal = {Proceedings of the National Academy of Sciences}, 
issn = {0027-8424}, 
doi = {10.1073/pnas.0605643104}, 
pmid = {17185420}, 
pmcid = {PMC1765463}, 
abstract = {{Even in the absence of sensory stimulation, the neocortex shows complex spontaneous activity patterns, often consisting of alternating “DOWN” states of generalized neural silence and “UP” states of massive, persistent network activity. To investigate how this spontaneous activity propagates through neuronal assemblies in vivo, we simultaneously recorded populations of 50–200 cortical neurons in layer V of anesthetized and awake rats. Each neuron displayed a virtually unique spike pattern during UP states, with diversity seen amongst both putative pyramidal cells and interneurons, reflecting a complex but stereotypically organized sequential spread of activation through local cortical networks. Spike timing was most precise during the first ≈100 ms after UP state onset, and decayed as UP states progressed. A subset of UP states propagated as traveling waves, but waves passing a given point in either direction initiated similar local sequences, suggesting local networks as the substrate of sequential firing patterns. A search for repeating motifs indicated that their occurrence and structure was predictable from neurons' individual latencies to UP state onset. We suggest that these stereotyped patterns arise from the interplay of intrinsic cellular conductances and local circuit properties.}}, 
pages = {347--352}, 
number = {1}, 
volume = {104}, 
keywords = {}
}
@article{wenzel2019acute, 
year = {2019}, 
title = {{Acute Focal Seizures Start As Local Synchronizations of Neuronal Ensembles}}, 
author = {Wenzel, Michael and Hamm, Jordan P and Peterka, Darcy S and Yuste, Rafael}, 
journal = {The Journal of Neuroscience}, 
issn = {0270-6474}, 
doi = {10.1523/jneurosci.3176-18.2019}, 
pmid = {31427393}, 
pmcid = {PMC6807279}, 
abstract = {{Understanding seizure formation and spread remains a critical goal of epilepsy research. We used fast in vivo two-photon calcium imaging in male mouse neocortex to reconstruct, with single-cell resolution, the dynamics of acute (4-aminopyridine) focal cortical seizures as they originate within a spatially confined seizure initiation site (intrafocal region), and subsequently propagate into neighboring cortical areas (extrafocal region). We find that seizures originate as local neuronal ensembles within the initiation site. This abnormal hyperactivity engages increasingly larger areas in a saltatory fashion until it breaks into neighboring cortex, where it proceeds smoothly and is then detected electrophysiologically (LFP). Interestingly, PV inhibitory interneurons have spatially heterogeneous activity in intrafocal and extrafocal territories, ruling out a simple role of inhibition in seizure formation and spread. We propose a two-step model for the progression of focal seizures, where neuronal ensembles activate first, generating a microseizure, followed by widespread neural activation in a traveling wave through neighboring cortex during macroseizures.SIGNIFICANCE STATEMENT We have used calcium imaging in mouse sensory cortex in vivo to reconstruct the onset of focal seizures elicited by local injection of the chemoconvulsant 4-aminopyridine. We demonstrate at cellular resolution that acute focal seizures originate as increasingly synchronized local neuronal ensembles. Because of its spatial confinement, this process may at first be undetectable even by nearby LFP electrodes. Further, we establish spatial footprints of local neural subtype activity that correspond to consecutive steps of seizure microprogression. Such footprints could facilitate determining the recording location (e.g., inside/outside an epileptogenic focus) in high-resolution studies, even in the absence of a priori knowledge about where exactly a seizure started.}}, 
pages = {8562--8575}, 
number = {43}, 
volume = {39}, 
keywords = {}
}
@article{curtis2015initiation, 
year = {2015}, 
title = {{Initiation, Propagation, and Termination of Partial (Focal) Seizures}}, 
author = {Curtis, Marco de and Avoli, Massimo}, 
journal = {Cold Spring Harbor Perspectives in Medicine}, 
doi = {10.1101/cshperspect.a022368}, 
pmid = {26134843}, 
pmcid = {PMC4484951}, 
abstract = {{The neurophysiological patterns that correlate with partial (focal) seizures are well defined in humans by standard electroencephalogram (EEG) and presurgical depth electrode recordings. Seizure patterns with similar features are reproduced in animal models of partial seizures and epilepsy. However, the network determinants that support interictal spikes, as well as the initiation, progression, and termination of seizures, are still elusive. Recent findings show that inhibitory networks are prominently involved at the onset of these seizures, and that extracellular changes in potassium contribute to initiate and sustain seizure progression. The end of a partial seizure correlates with an increase in network synchronization, which possibly involves both excitatory and inhibitory mechanisms.}}, 
pages = {a022368}, 
number = {7}, 
volume = {5}, 
keywords = {}
}
@article{lorenz1963deterministic, 
year = {1963}, 
title = {{Deterministic Nonperiodic Flow}}, 
author = {Lorenz and Edward, N.}, 
journal = {Journal of the Atmospheric Sciences}, 
issn = {0022-4928}, 
doi = {10.1175/1520-0469(1963)020<0130:dnf>2.0.co;2}, 
abstract = {{Finite systems of deterministic ordinary nonlinear differential equations may be designed to represent forced dissipative hydrodynamic flow. Solutions of these equations can be identified with trajectories in phase space. For those systems with bounded solutions, it is found that nonperiodic solutions are ordinarily unstable with respect to small modifications, so that slightly differing initial states can evolve into considerably different states. Systems with bounded solutions are shown to possess bounded numerical solutions. A simple system representing cellular convection is solved numerically. All of the solutions are found to be unstable, and almost all of them are nonperiodic. The feasibility of very-long-range weather prediction is examined in the light of these results.}}, 
pages = {130--141}, 
number = {2}, 
volume = {20}, 
keywords = {}
}
@article{danisch2021makie, 
year = {2021}, 
title = {{Makie.jl: Flexible high-performance data visualization for Julia}}, 
author = {Danisch, Simon and Krumbiegel, Julius}, 
journal = {Journal of Open Source Software}, 
doi = {10.21105/joss.03349}, 
pages = {3349}, 
number = {65}, 
volume = {6}, 
keywords = {}
}
@article{fernandez2020sleep, 
year = {2020}, 
title = {{Sleep Spindles: Mechanisms and Functions}}, 
author = {Fernandez, Laura M. J. and Lüthi, Anita}, 
journal = {Physiological Reviews}, 
issn = {0031-9333}, 
doi = {10.1152/physrev.00042.2018}, 
pmid = {31804897}, 
abstract = {{Sleep spindles are burstlike signals in the electroencephalogram (EEG) of the sleeping mammalian brain and electrical surface correlates of neuronal oscillations in thalamus. As one of the most inheritable sleep EEG signatures, sleep spindles probably reflect the strength and malleability of thalamocortical circuits that underlie individual cognitive profiles. We review the characteristics, organization, regulation, and origins of sleep spindles and their implication in non-rapid-eye-movement sleep (NREMS) and its functions, focusing on human and rodent. Spatially, sleep spindle-related neuronal activity appears on scales ranging from small thalamic circuits to functional cortical areas, and generates a cortical state favoring intracortical plasticity while limiting cortical output. Temporally, sleep spindles are discrete events, part of a continuous power band, and elements grouped on an infraslow time scale over which NREMS alternates between continuity and fragility. We synthesize diverse and seemingly unlinked functions of sleep spindles for sleep architecture, sensory processing, synaptic plasticity, memory formation, and cognitive abilities into a unifying sleep spindle concept, according to which sleep spindles 1) generate neural conditions of large-scale functional connectivity and plasticity that outlast their appearance as discrete EEG events, 2) appear preferentially in thalamic circuits engaged in learning and attention-based experience during wakefulness, and 3) enable a selective reactivation and routing of wake-instated neuronal traces between brain areas such as hippocampus and cortex. Their fine spatiotemporal organization reflects NREMS as a physiological state coordinated over brain and body and may indicate, if not anticipate and ultimately differentiate, pathologies in sleep and neurodevelopmental, -degenerative, and -psychiatric conditions.}}, 
pages = {805--868}, 
number = {2}, 
volume = {100}, 
keywords = {}
}
@article{morris1981voltage, 
year = {1981}, 
title = {{Voltage oscillations in the barnacle giant muscle fiber}}, 
author = {Morris, C. and Lecar, H.}, 
journal = {Biophysical Journal}, 
issn = {0006-3495}, 
doi = {10.1016/s0006-3495(81)84782-0}, 
pmid = {7260316}, 
pmcid = {PMC1327511}, 
abstract = {{Barnacle muscle fibers subjected to constant current stimulation produce a variety of types of oscillatory behavior when the internal medium contains the Ca++ chelator EGTA. Oscillations are abolished if Ca++ is removed from the external medium, or if the K+ conductance is blocked. Available voltage-clamp data indicate that the cell's active conductance systems are exceptionally simple. Given the complexity of barnacle fiber voltage behavior, this seems paradoxical. This paper presents an analysis of the possible modes of behavior available to a system of two noninactivating conductance mechanisms, and indicates a good correspondence to the types of behavior exhibited by barnacle fiber. The differential equations of a simple equivalent circuit for the fiber are dealt with by means of some of the mathematical techniques of nonlinear mechanics. General features of the system are (a) a propensity to produce damped or sustained oscillations over a rather broad parameter range, and (b) considerable latitude in the shape of the oscillatory potentials. It is concluded that for cells subject to changeable parameters (either from cell to cell or with time during cellular activity), a system dominated by two noninactivating conductances can exhibit varied oscillatory and bistable behavior.}}, 
pages = {193--213}, 
number = {1}, 
volume = {35}, 
keywords = {}
}
@article{10.1103/physreve.71.036151, 
year = {2005}, 
title = {{Onset of synchronization in large networks of coupled oscillators}}, 
author = {Restrepo, Juan G. and Ott, Edward and Hunt, Brian R.}, 
journal = {Physical Review E}, 
issn = {1539-3755}, 
doi = {10.1103/physreve.71.036151}, 
pmid = {15903537}, 
eprint = {cond-mat/0411202}, 
abstract = {{We study the transition from incoherence to coherence in large networks of coupled phase oscillators. We present various approximations that describe the behavior of an appropriately defined order parameter past the transition and generalize recent results for the critical coupling strength. We find that, under appropriate conditions, the coupling strength at which the transition occurs is determined by the largest eigenvalue of the adjacency matrix. We show how, with an additional assumption, a mean-field approximation recently proposed is recovered from our results. We test our theory with numerical simulations and find that it describes the transition when our assumptions are satisfied. We find that our theory describes the transition well in situations in which the mean-field approximation fails. We study the finite-size effects caused by nodes with small degree and find that they cause the critical coupling strength to increase.}}, 
pages = {036151}, 
number = {3}, 
volume = {71}, 
keywords = {}
}
@article{10.1103/physreve.100.042302, 
year = {2019}, 
title = {{Onset of synchronization of Kuramoto oscillators in scale-free networks}}, 
author = {Peron, Thomas and Resende, Bruno Messias F. de and Mata, Angélica S. and Rodrigues, Francisco A. and Moreno, Yamir}, 
journal = {Physical Review E}, 
issn = {2470-0045}, 
doi = {10.1103/physreve.100.042302}, 
pmid = {31770973}, 
eprint = {1905.02256}, 
abstract = {{Despite the great attention devoted to the study of phase oscillators on complex networks in the last two decades, it remains unclear whether scale-free networks exhibit a nonzero critical coupling strength for the onset of synchronization in the thermodynamic limit. Here, we systematically compare predictions from the heterogeneous degree mean-field (HMF) and the quenched mean-field (QMF) approaches to extensive numerical simulations on large networks. We provide compelling evidence that the critical coupling vanishes as the number of oscillators increases for scale-free networks characterized by a power-law degree distribution with an exponent 23, we show that the critical coupling remains finite, in agreement with HMF calculations and highlight phenomenological differences between critical properties of phase oscillators and epidemic models on scale-free networks. Finally, we also discuss at length a key choice when studying synchronization phenomena in complex networks, namely, how to normalize the coupling between oscillators.}}, 
pages = {042302}, 
number = {4}, 
volume = {100}, 
keywords = {}
}
@article{10.1209/0295-5075/107/60006, 
year = {2014}, 
title = {{Mean-field theory of assortative networks of phase oscillators}}, 
author = {Restrepo, Juan G. and Ott, Edward}, 
journal = {Europhysics Letters}, 
issn = {0295-5075}, 
doi = {10.1209/0295-5075/107/60006}, 
eprint = {1407.5725}, 
abstract = {{Employing the Kuramoto model as an illustrative example, we show how the use of the mean-field approximation can be applied to large networks of phase oscillators with assortativity. We then use the ansatz of Ott and Antonsen (Chaos, 19 (2008) 037113) to reduce the mean-field kinetic equations to a system of ordinary differential equations. The resulting formulation is illustrated by application to a network Kuramoto problem with degree assortativity and correlation between the node degrees and the natural oscillation frequencies. Good agreement is found between the solutions of the reduced set of ordinary differential equations obtained from our theory and full simulations of the system. These results highlight the ability of our method to capture all the phase transitions (bifurcations) and system attractors. One interesting result is that degree assortativity can induce transitions from a steady macroscopic state to a temporally oscillating macroscopic state through both (presumed) Hopf and SNIPER (saddle-node, infinite period) bifurcations. Possible use of these techniques to a broad class of phase oscillator network problems is discussed.}}, 
pages = {60006}, 
number = {6}, 
volume = {107}, 
keywords = {}
}
@article{hildebrand2007kinetic, 
year = {2007}, 
title = {{Kinetic Theory of Coupled Oscillators}}, 
author = {Hildebrand, Eric J. and Buice, Michael A. and Chow, Carson C.}, 
journal = {Physical Review Letters}, 
issn = {0031-9007}, 
doi = {10.1103/physrevlett.98.054101}, 
pmid = {17358861}, 
pmcid = {PMC2561959}, 
eprint = {nlin/0612029}, 
abstract = {{We present an approach for the description of fluctuations that are due to finite system size induced correlations in the Kuramoto model of coupled oscillators. We construct a hierarchy for the moments of the density of oscillators that is analogous to the Bogoliubov-Born-Green-Kirkwood-Yvon hierarchy in the kinetic theory of plasmas and gases. To calculate the lowest order system size effect, we truncate this hierarchy at second order and solve the resulting closed equations for the two-oscillator correlation function around the incoherent state. We use this correlation function to compute the fluctuations of the order parameter, including the effect of transients, and compare this computation with numerical simulations.}}, 
pages = {054101}, 
number = {5}, 
volume = {98}, 
keywords = {}
}
@article{10.1103/physreve.91.032814, 
year = {2015}, 
title = {{Critical behavior of the relaxation rate, the susceptibility, and a pair correlation function in the Kuramoto model on scale-free networks}}, 
author = {Yoon, S. and Sindaci, M. Sorbaro and Goltsev, A. V. and Mendes, J. F. F.}, 
journal = {Physical Review E}, 
issn = {1539-3755}, 
doi = {10.1103/physreve.91.032814}, 
pmid = {25871164}, 
eprint = {1411.4810}, 
abstract = {{We study the impact of network heterogeneity on relaxation dynamics of the Kuramoto model on uncorrelated complex networks with scale-free degree distributions. Using the Ott-Antonsen method and the annealed-network approach, we find that the critical behavior of the relaxation rate near the synchronization phase transition does not depend on network heterogeneity and critical slowing down takes place at the critical point when the second moment of the degree distribution is finite. In the case of a complete graph we obtain an explicit result for the relaxation rate when the distribution of natural frequencies is Lorentzian. We also find a response of the Kuramoto model to an external field and show that the susceptibility of the model is inversely proportional to the relaxation rate. We reveal that network heterogeneity strongly impacts a field dependence of the relaxation rate and the susceptibility when the network has a divergent fourth moment of degree distribution. We introduce a pair correlation function of phase oscillators and show that it has a sharp peak at the critical point, signaling emergence of long-range correlations. Our numerical simulations of the Kuramoto model support our analytical results.}}, 
pages = {032814}, 
number = {3}, 
volume = {91}, 
keywords = {}
}
@article{10.1073/pnas.1212134110, 
year = {2013}, 
title = {{Synchronization in complex oscillator networks and smart grids}}, 
author = {Dörfler, Florian and Chertkov, Michael and Bullo, Francesco}, 
journal = {Proceedings of the National Academy of Sciences}, 
issn = {0027-8424}, 
doi = {10.1073/pnas.1212134110}, 
pmid = {23319658}, 
pmcid = {PMC3568350}, 
eprint = {1208.0045}, 
abstract = {{The emergence of synchronization in a network of coupled oscillators is a fascinating topic in various scientific disciplines. A widely adopted model of a coupled oscillator network is characterized by a population of heterogeneous phase oscillators, a graph describing the interaction among them, and diffusive and sinusoidal coupling. It is known that a strongly coupled and sufficiently homogeneous network synchronizes, but the exact threshold from incoherence to synchrony is unknown. Here, we present a unique, concise, and closed-form condition for synchronization of the fully nonlinear, nonequilibrium, and dynamic network. Our synchronization condition can be stated elegantly in terms of the network topology and parameters or equivalently in terms of an intuitive, linear, and static auxiliary system. Our results significantly improve upon the existing conditions advocated thus far, they are provably exact for various interesting network topologies and parameters; they are statistically correct for almost all networks; and they can be applied equally to synchronization phenomena arising in physics and biology as well as in engineered oscillator networks, such as electrical power networks. We illustrate the validity, the accuracy, and the practical applicability of our results in complex network scenarios and in smart grid applications.}}, 
pages = {2005--2010}, 
number = {6}, 
volume = {110}, 
keywords = {}
}
@article{fernandez2022emergence, 
year = {2022}, 
title = {{Emergence of explosive synchronization bombs in networks of oscillators}}, 
author = {Arola-Fernández, Lluís and Faci-Lázaro, Sergio and Skardal, Per Sebastian and Boghiu, Emanuel-Cristian and Gómez-Gardeñes, Jesús and Arenas, Alex}, 
journal = {Communications Physics}, 
doi = {10.1038/s42005-022-01039-2}, 
eprint = {2203.03728}, 
abstract = {{Research on network percolation and synchronization has deepened our understanding of abrupt changes in the macroscopic properties of complex engineered and natural systems. While explosive percolation emerges from localized structural perturbations that delay the formation of a connected component, explosive synchronization is usually studied by fine-tuning of global parameters. Here, we introduce the concept of synchronization bombs as large networks of heterogeneous oscillators that abruptly transit from incoherence to phase-locking (or vice-versa) by adding (or removing) one or a few links. We build these bombs by optimizing global synchrony with decentralized information in a competitive percolation process driven by a local rule, and show their occurrence in systems of Kuramoto –periodic– and Rössler –chaotic– oscillators and in a model of cardiac pacemaker cells, providing an analytical characterization in the Kuramoto case. Our results propose a self-organized approach to design and control abrupt transitions in adaptive biological systems and electronic circuits, and place explosive synchronization and percolation under the same mechanistic framework. Synchronization bombs are large networks of coupled heterogeneous oscillators that operate in a bistable regime and abruptly transit from incoherence to synchronization by adding one or a few links. Self-organized synchronization bombs would be useful to understand switch mechanisms in biological systems, and to design networks to operate in this regime.}}, 
pages = {264}, 
number = {1}, 
volume = {5}, 
keywords = {}
}
@article{hancock2018model, 
year = {2018}, 
title = {{Model reduction for Kuramoto models with complex topologies}}, 
author = {Hancock, Edward J. and Gottwald, Georg A.}, 
journal = {Physical Review E}, 
issn = {2470-0045}, 
doi = {10.1103/physreve.98.012307}, 
pmid = {30110852}, 
eprint = {1804.07444}, 
abstract = {{Synchronization of coupled oscillators is a ubiquitous phenomenon, occurring in topics ranging from biology and physics to social networks and technology. A fundamental and long-time goal in the study of synchronization has been to find low-order descriptions of complex oscillator networks and their collective dynamics. However, for the Kuramoto model, the most widely used model of coupled oscillators, this goal has remained surprisingly challenging, in particular for finite-size networks. Here, we propose a model reduction framework that effectively captures synchronization behavior in complex network topologies. This framework generalizes a collective coordinates approach for all-to-all networks [G. A. Gottwald, Chaos 25, 053111 (2015)CHAOEH1054-150010.1063/1.4921295] by incorporating the graph Laplacian matrix in the collective coordinates. We first derive low dimensional evolution equations for both clustered and nonclustered oscillator networks. We then demonstrate in numerical simulations for Erdős-Rényi networks that the collective coordinates capture the synchronization behavior in both finite-size networks as well as in the thermodynamic limit, even in the presence of interacting clusters.}}, 
pages = {012307}, 
number = {1}, 
volume = {98}, 
keywords = {}
}
@article{zhang2021basins, 
year = {2021}, 
title = {{Basins with Tentacles}}, 
author = {Zhang, Yuanzhao and Strogatz, Steven H.}, 
journal = {Physical Review Letters}, 
issn = {0031-9007}, 
doi = {10.1103/physrevlett.127.194101}, 
pmid = {34797139}, 
eprint = {2106.05709}, 
abstract = {{To explore basin geometry in high-dimensional dynamical systems, we consider a ring of identical Kuramoto oscillators. Many attractors coexist in this system; each is a twisted periodic orbit characterized by a winding number q, with basin size proportional to e-kq2. We uncover the geometry behind this size distribution and find the basins are octopuslike, with nearly all their volume in the tentacles, not the head of the octopus (the ball-like region close to the attractor). We present a simple geometrical reason why basins with tentacles should be common in high-dimensional systems.}}, 
pages = {194101}, 
number = {19}, 
volume = {127}, 
keywords = {}
}
@article{lafranceschina2015impact, 
year = {2015}, 
title = {{Impact of weak excitatory synapses on chaotic transients in a diffusively coupled Morris-Lecar neuronal network}}, 
author = {Lafranceschina, Jacopo and Wackerbauer, Renate}, 
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science}, 
issn = {1054-1500}, 
doi = {10.1063/1.4907193}, 
pmid = {25637930}, 
abstract = {{Spatiotemporal chaos collapses to either a rest state or a propagating pulse solution in a ring network of diffusively coupled, excitable Morris-Lecar neurons. Weak excitatory synapses can increase the Lyapunov exponent, expedite the collapse, and promote the collapse to the rest state rather than the pulse state. A single traveling pulse solution may no longer be asymptotic for certain combinations of network topology and (weak) coupling strengths, and initiate spatiotemporal chaos. Multiple pulses can cause chaos initiation due to diffusive and synaptic pulse-pulse interaction. In the presence of chaos initiation, intermittent spatiotemporal chaos exists until typically a collapse to the rest state.}}, 
pages = {013119}, 
number = {1}, 
volume = {25}, 
keywords = {}
}
@article{taylor2012there, 
year = {2012}, 
title = {{There is no non-zero stable fixed point for dense networks in the homogeneous Kuramoto model}}, 
author = {Taylor, Richard}, 
journal = {Journal of Physics A: Mathematical and Theoretical}, 
issn = {1751-8121}, 
doi = {10.1088/1751-8113/45/5/055102}, 
eprint = {1109.4451}, 
abstract = {{This paper is concerned with the existence of multiple stable fixed point solutions of the homogeneous Kuramoto model. We develop a necessary condition for the existence of stable fixed points for the general network Kuramoto model. This condition is applied to show that for sufficiently dense n-node networks, with node degrees at least 0.9395(n−1), the homogeneous (equal frequencies) model has only one stable fixed point solution over the full space of phase angles in the range −π to π. This is the zero fixed point solution defined by all phase angle differences being zero. This result, together with existing research, proves a conjecture of Verwoerd and Mason (2007 Proc. of the American Control Conf. pp 4613–8) that for the complete network and the homogeneous model, the zero fixed point has a basin of attraction consisting of the entire space minus a set of measure zero. The necessary conditions are also tested to see how close to sufficiency they might be by applying them to a class of regular degree networks studied by Wiley et al (2006 Chaos 16 015103).}}, 
pages = {055102}, 
number = {5}, 
volume = {45}, 
keywords = {}
}
@article{budzinski2019synchronous, 
year = {2019}, 
title = {{Synchronous patterns and intermittency in a network induced by the rewiring of connections and coupling}}, 
author = {Budzinski, R. C. and Boaretto, B. R. R. and Prado, T. L. and Viana, R. L. and Lopes, S. R.}, 
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science}, 
issn = {1054-1500}, 
doi = {10.1063/1.5128495}, 
pmid = {31893641}, 
abstract = {{The connection architecture plays an important role in the synchronization of networks, where the presence of local and nonlocal connection structures are found in many systems, such as the neural ones. Here, we consider a network composed of chaotic bursting oscillators coupled through a Watts-Strogatz-small-world topology. The influence of coupling strength and rewiring of connections is studied when the network topology is varied from regular to small-world to random. In this scenario, we show two distinct nonstationary transitions to phase synchronization: one induced by the increase in coupling strength and another resulting from the change from local connections to nonlocal ones. Besides this, there are regions in the parameter space where the network depicts a coexistence of different bursting frequencies where nonstationary zig-zag fronts are observed. Regarding the analyses, we consider two distinct methodological approaches: one based on the phase association to the bursting activity where the Kuramoto order parameter is used and another based on recurrence quantification analysis where just a time series of the network mean field is required.}}, 
pages = {123132}, 
number = {12}, 
volume = {29}, 
keywords = {}
}
@article{humphries2008network, 
year = {2008}, 
title = {{Network ‘Small-World-Ness’: A Quantitative Method for Determining Canonical Network Equivalence}}, 
author = {Humphries, Mark D. and Gurney, Kevin}, 
journal = {PLoS ONE}, 
doi = {10.1371/journal.pone.0002051}, 
pmid = {18446219}, 
pmcid = {PMC2323569}, 
abstract = {{Many technological, biological, social, and information networks fall into the broad class of ‘small-world’ networks: they have tightly interconnected clusters of nodes, and a shortest mean path length that is similar to a matched random graph (same number of nodes and edges). This semi-quantitative definition leads to a categorical distinction (‘small/not-small’) rather than a quantitative, continuous grading of networks, and can lead to uncertainty about a network's small-world status. Moreover, systems described by small-world networks are often studied using an equivalent canonical network model – the Watts-Strogatz (WS) model. However, the process of establishing an equivalent WS model is imprecise and there is a pressing need to discover ways in which this equivalence may be quantified. We defined a precise measure of ‘small-world-ness’ S based on the trade off between high local clustering and short path length. A network is now deemed a ‘small-world’ if S>1 - an assertion which may be tested statistically. We then examined the behavior of S on a large data-set of real-world systems. We found that all these systems were linked by a linear relationship between their S values and the network size n. Moreover, we show a method for assigning a unique Watts-Strogatz (WS) model to any real-world network, and show analytically that the WS models associated with our sample of networks also show linearity between S and n. Linearity between S and n is not, however, inevitable, and neither is S maximal for an arbitrary network of given size. Linearity may, however, be explained by a common limiting growth process. We have shown how the notion of a small-world network may be quantified. Several key properties of the metric are described and the use of WS canonical models is placed on a more secure footing.}}, 
pages = {e2051}, 
number = {4}, 
volume = {3}, 
keywords = {}
}
@article{telesford2011the, 
year = {2011}, 
title = {{The Ubiquity of Small-World Networks}}, 
author = {Telesford, Qawi K. and Joyce, Karen E. and Hayasaka, Satoru and Burdette, Jonathan H. and Laurienti, Paul J.}, 
journal = {Brain Connectivity}, 
issn = {2158-0014}, 
doi = {10.1089/brain.2011.0038}, 
pmid = {22432451}, 
pmcid = {PMC3604768}, 
abstract = {{Small-world networks, according to Watts and Strogatz, are a class of networks that are “highly clustered, like regular lattices, yet have small characteristic path lengths, like random graphs.” These characteristics result in networks with unique properties of regional specialization with efficient information transfer. Social networks are intuitive examples of this organization, in which cliques or clusters of friends being interconnected but each person is really only five or six people away from anyone else. Although this qualitative definition has prevailed in network science theory, in application, the standard quantitative application is to compare path length (a surrogate measure of distributed processing) and clustering (a surrogate measure of regional specialization) to an equivalent random network. It is demonstrated here that comparing network clustering to that of a random network can result in aberrant findings and that networks once thought to exhibit small-world properties may not. We propose a new small-world metric, ω (omega), which compares network clustering to an equivalent lattice network and path length to a random network, as Watts and Strogatz originally described. Example networks are presented that would be interpreted as small-world when clustering is compared to a random network but are not small-world according to ω. These findings have important implications in network science because small-world networks have unique topological properties, and it is critical to accurately distinguish them from networks without simultaneous high clustering and short path length.}}, 
pages = {367--375}, 
number = {5}, 
volume = {1}, 
keywords = {}
}
@incollection{rotstein2014mixedmode, 
year = {2014}, 
title = {{Mixed-Mode Oscillations in Single Neurons}}, 
author = {Rotstein, Horacio G.}, 
editor = {Dieter, Jaeger and Ranu, Jung}, 
booktitle = {Encyclopedia of Computational Neuroscience}, 
pages = {1--9}, 
series = {Encyclopedia of Computational Neuroscience}, 
publisher = {Springer New York, NY}, 
keywords = {}, 
doi = {10.1007/978-1-4614-7320-6\_31-1}
}
@article{tsuda2009hypotheses, 
year = {2009}, 
title = {{Hypotheses on the functional roles of chaotic transitory dynamics}}, 
author = {Tsuda, Ichiro}, 
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science}, 
issn = {1054-1500}, 
doi = {10.1063/1.3076393}, 
pmid = {19335017}, 
abstract = {{In contrast to the conventional static view of the brain, recent experimental data show that an alternative view is necessary for an appropriate interpretation of its function. Some selected problems concerning the cortical transitory dynamics are discussed. For the first time, we propose five scenarios for the appearance of chaotic itinerancy, which provides typical transitory dynamics. Second, we describe the transitory behaviors that have been observed in human and animal brains. Finally, we propose nine hypotheses on the functional roles of such dynamics, focusing on the dynamics embedded in data and the dynamical interpretation of brain activity within the framework of cerebral hermeneutics.}}, 
pages = {015113}, 
number = {1}, 
volume = {19}, 
keywords = {}
}
@article{freeman2003evidence, 
year = {2003}, 
title = {{Evidence from human scalp electroencephalograms of global chaotic itinerancy}}, 
author = {Freeman and Walter, J.}, 
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science}, 
issn = {1054-1500}, 
doi = {10.1063/1.1596553}, 
pmid = {12946200}, 
abstract = {{My objective of this study was to find evidence of chaotic itinerancy in human brains by means of noninvasive recording of the electroencephalogram (EEG) from the scalp of normal subjects. My premise was that chaotic itinerancy occurs in sequences of cortical states marked by state transitions that appear as temporal discontinuities in neural activity patterns. I based my study on unprecedented advances in spatial and temporal resolution of the phase of oscillations in scalp EEG. The spatial resolution was enhanced by use of a high-density curvilinear array of 64 electrodes, 189 mm in length, with 3 mm spacing. The temporal resolution was advanced to the limit provided by the digitizing step, here 5 ms, by use of the Hilbert transform. The numerical derivative of the analytic phase revealed plateaus in phase that lasted on the order of 0.1 s and repeated at rates in the theta (3–7 Hz) or alpha (7–12 Hz) ranges. The plateaus were bracketed by sudden jumps in phase that usually took place within 1 to 2 digitizing steps. The jumps were commonly synchronized in each cerebral hemisphere over distances of up to 189 mm, irrespective of the orientation of the array. The jumps were usually not synchronized across the midline separating the hemisphere or across the sulcus between the frontal and parietal lobes. I believe that the widespread synchrony of the jumps in analytic phase manifest a metastable cortical state in accord with the theory of self-organized criticality. The jumps appear to be subcritical bifurcations. They reflect the aperiodic evolution of brain states through sequences of attractors that on access support the experience of remembering.}}, 
pages = {1067--1077}, 
number = {3}, 
volume = {13}, 
keywords = {}
}
@article{sakurai2016recruitment, 
year = {2016}, 
title = {{Recruitment of Polysynaptic Connections Underlies Functional Recovery of a Neural Circuit after Lesion}}, 
author = {Sakurai, Akira and Tamvacakis, Arianna N. and Katz, Paul S.}, 
journal = {eNeuro}, 
pmid = {27570828}, 
pmcid = {PMC4999536}, 
abstract = {{The recruitment of additional neurons to neural circuits often occurs in accordance with changing functional demands. Here we found that synaptic recruitment plays a key role in functional recovery after neural injury. Disconnection of a brain commissure in the nudibranch mollusc, Tritonia diomedea, impairs swimming behavior by eliminating particular synapses in the central pattern generator (CPG) underlying the rhythmic swim motor pattern. However, the CPG functionally recovers within a day after the lesion. The strength of a spared inhibitory synapse within the CPG from Cerebral Neuron 2 (C2) to Ventral Swim Interneuron B (VSI) determines the level of impairment caused by the lesion, which varies among individuals. In addition to this direct synaptic connection, there are polysynaptic connections from C2 and Dorsal Swim Interneurons to VSI that provide indirect excitatory drive but play only minor roles under normal conditions. After disconnecting the pedal commissure (Pedal Nerve 6), the recruitment of polysynaptic excitation became a major source of the excitatory drive to VSI. Moreover, the amount of polysynaptic recruitment, which changed over time, differed among individuals and correlated with the degree of recovery of the swim motor pattern. Thus, functional recovery was mediated by an increase in the magnitude of polysynaptic excitatory drive, compensating for the loss of direct excitation. Since the degree of susceptibility to injury corresponds to existing individual variation in the C2 to VSI synapse, the recovery relied upon the extent to which the network reorganized to incorporate additional synapses.}}, 
number = {4}, 
volume = {3}, 
keywords = {}
}
@article{rossi2022repository, 
year = {2023}, 
title = {{Repository for metastability}}, 
author = {Rossi, K. L.}, 
journal = {GitHub repository}, 
url = {https://github.com/ComplexNetworks-jl/MetastableDynamics}, 
note = {https://github.com/ComplexNetworks-jl/MetastableDynamics}, 
keywords = {}
}
@article{babloyantz1986low, 
year = {1986}, 
title = {{Low-dimensional chaos in an instance of epilepsy.}}, 
author = {Babloyantz, A and Destexhe, A}, 
journal = {Proceedings of the National Academy of Sciences}, 
issn = {0027-8424}, 
doi = {10.1073/pnas.83.10.3513}, 
pmid = {3085091}, 
pmcid = {PMC323547}, 
abstract = {{Using a time series obtained from the electroencephalogram recording of a human epileptic seizure, we show the existence of a chaotic attractor, the latter being the direct consequence of the deterministic nature of brain activity. This result is compared with other attractors seen in normal human brain dynamics. A sudden jump is observed between the dimensionalities of these brain attractors (4.05 +/- 0.05 for deep sleep) and the very low dimensionality of the epileptic state (2.05 +/- 0.09). The evaluation of the autocorrelation function and of the largest Lyapunov exponent allows us to sharpen further the main features of underlying dynamics. Possible implications in biological and medical research are briefly discussed.}}, 
pages = {3513--3517}, 
number = {10}, 
volume = {83}, 
keywords = {}
}
@article{bittracher2021dimensionality, 
year = {2021}, 
title = {{Dimensionality Reduction of Complex Metastable Systems via Kernel Embeddings of Transition Manifolds}}, 
author = {Bittracher, Andreas and Klus, Stefan and Hamzi, Boumediene and Koltai, Péter and Schütte, Christof}, 
journal = {Journal of Nonlinear Science}, 
issn = {0938-8974}, 
doi = {10.1007/s00332-020-09668-z}, 
abstract = {{We present a novel kernel-based machine learning algorithm for identifying the low-dimensional geometry of the effective dynamics of high-dimensional multiscale stochastic systems. Recently, the authors developed a mathematical framework for the computation of optimal reaction coordinates of such systems that is based on learning a parameterization of a low-dimensional transition manifold in a certain function space. In this article, we enhance this approach by embedding and learning this transition manifold in a reproducing kernel Hilbert space, exploiting the favorable properties of kernel embeddings. Under mild assumptions on the kernel, the manifold structure is shown to be preserved under the embedding, and distortion bounds can be derived. This leads to a more robust and more efficient algorithm compared to the previous parameterization approaches.}}, 
pages = {3}, 
number = {1}, 
volume = {31}, 
keywords = {}
}
@article{bittracher2018transition, 
year = {2018}, 
title = {{Transition Manifolds of Complex Metastable Systems}}, 
author = {Bittracher, Andreas and Koltai, Péter and Klus, Stefan and Banisch, Ralf and Dellnitz, Michael and Schütte, Christof}, 
journal = {Journal of Nonlinear Science}, 
issn = {0938-8974}, 
doi = {10.1007/s00332-017-9415-0}, 
pmid = {29527099}, 
pmcid = {PMC5835149}, 
eprint = {1704.08927}, 
abstract = {{We consider complex dynamical systems showing metastable behavior, but no local separation of fast and slow time scales. The article raises the question of whether such systems exhibit a low-dimensional manifold supporting its effective dynamics. For answering this question, we aim at finding nonlinear coordinates, called reaction coordinates, such that the projection of the dynamics onto these coordinates preserves the dominant time scales of the dynamics. We show that, based on a specific reducibility property, the existence of good low-dimensional reaction coordinates preserving the dominant time scales is guaranteed. Based on this theoretical framework, we develop and test a novel numerical approach for computing good reaction coordinates. The proposed algorithmic approach is fully local and thus not prone to the curse of dimension with respect to the state space of the dynamics. Hence, it is a promising method for data-based model reduction of complex dynamical systems such as molecular dynamics.}}, 
pages = {471--512}, 
number = {2}, 
volume = {28}, 
keywords = {}
}
@article{john2022it, 
year = {2022}, 
title = {{It’s about time: Linking dynamical systems with human neuroimaging to understand the brain}}, 
author = {John, Yohan J. and Sawyer, Kayle S. and Srinivasan, Karthik and Müller, Eli J. and Munn, Brandon R. and Shine, James M.}, 
journal = {Network Neuroscience}, 
doi = {10.1162/netn\_a\_00230}, 
abstract = {{The study of dynamical systems offers a powerful framework for interpreting neuroimaging data from a range of different contexts, however, as a field, we have yet to fully embrace the power of this approach. Here, we offer a brief overview of some key terms from the dynamical systems literature, and then highlight three ways in which neuroimaging studies can begin to embrace the dynamical systems approach: by shifting from local to global descriptions of activity, by moving from static to dynamic analyses, and by transitioning from descriptive to generative models of neural activity patterns.}}, 
pages = {960--979}, 
number = {4}, 
volume = {6}, 
keywords = {}
}
@article{hramov2006onoff, 
year = {2006}, 
title = {{On-off intermittency in time series of spontaneous paroxysmal activity in rats with genetic absence epilepsy}}, 
author = {Hramov, Alexander and Koronovskii, Alexey A. and Midzyanovskaya, I. S. and Sitnikova, E. and Rijn, C. M. van}, 
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science}, 
issn = {1054-1500}, 
doi = {10.1063/1.2360505}, 
pmid = {17199389}, 
abstract = {{In the present paper we consider the on-off intermittency phenomena observed in time series of spontaneous paroxysmal activity in rats with genetic absence epilepsy. The method to register and analyze the electroencephalogram with the help of continuous wavelet transform is also suggested.}}, 
pages = {043111}, 
number = {4}, 
volume = {16}, 
keywords = {}
}
@article{medeiros2016trapping, 
year = {2017}, 
title = {{Trapping Phenomenon Attenuates the Consequences of Tipping Points for Limit Cycles}}, 
author = {Medeiros, Everton S. and Caldas, Iberê L. and Baptista, Murilo S. and Feudel, Ulrike}, 
journal = {Scientific Reports}, 
doi = {10.1038/srep42351}, 
pmid = {28181582}, 
pmcid = {PMC5299408}, 
abstract = {{Nonlinear dynamical systems may be exposed to tipping points, critical thresholds at which small changes in the external inputs or in the system’s parameters abruptly shift the system to an alternative state with a contrasting dynamical behavior. While tipping in a fold bifurcation of an equilibrium is well understood, much less is known about tipping of oscillations (limit cycles) though this dynamics are the typical response of many natural systems to a periodic external forcing, like e.g. seasonal forcing in ecology and climate sciences. We provide a detailed analysis of tipping phenomena in periodically forced systems and show that, when limit cycles are considered, a transient structure, so-called channel, plays a fundamental role in the transition. Specifically, we demonstrate that trajectories crossing such channel conserve, for a characteristic time, the twisting behavior of the stable limit cycle destroyed in the fold bifurcation of cycles. As a consequence, this channel acts like a “ghost” of the limit cycle destroyed in the critical transition and instead of the expected abrupt transition we find a smooth one. This smoothness is also the reason that it is difficult to precisely determine the transition point employing the usual indicators of tipping points, like critical slowing down and flickering.}}, 
pages = {42351}, 
number = {1}, 
volume = {7}, 
keywords = {}
}
@book{tabar2019analysis, 
year = {2019}, 
title = {{Analysis and Data-Based Reconstruction of Complex Nonlinear Dynamical Systems, Using the Methods of Stochastic Processes}}, 
author = {Tabar, M. Reza Rahini}, 
isbn = {9783030184711}, 
series = {Understanding Complex Systems}, 
publisher = {Springer Cham}, 
keywords = {}
}
@article{voss2004nonlinear, 
year = {2004}, 
title = {{Nonlinear dynamical system identification from uncertain and indicrect measurements}}, 
author = {Voss, Henning U. and Timmer, Jens and Kurths, Jürgen}, 
journal = {International Journal of Bifurcation and Chaos}, 
issn = {0218-1274}, 
doi = {10.1142/s0218127404010345}, 
abstract = {{We review the problem of estimating parameters and unobserved trajectory components from noisy time series measurements of continuous nonlinear dynamical systems. It is first shown that in parameter estimation techniques that do not take the measurement errors explicitly into account, like regression approaches, noisy measurements can produce inaccurate parameter estimates. Another problem is that for chaotic systems the cost functions that have to be minimized to estimate states and parameters are so complex that common optimization routines may fail. We show that the inclusion of information about the time-continuous nature of the underlying trajectories can improve parameter estimation considerably. Two approaches, which take into account both the errors-in-variables problem and the problem of complex cost functions, are described in detail: shooting approaches and recursive estimation techniques. Both are demonstrated on numerical examples.}}, 
pages = {1905--1933}, 
number = {06}, 
volume = {14}, 
keywords = {}
}
@article{anvari2016disentangling, 
year = {2016}, 
title = {{Disentangling the stochastic behavior of complex time series}}, 
author = {Anvari, Mehrnaz and Tabar, M. Reza Rahimi and Peinke, Joachim and Lehnertz, Klaus}, 
journal = {Scientific Reports}, 
doi = {10.1038/srep35435}, 
pmid = {27759055}, 
pmcid = {PMC5069951}, 
abstract = {{Complex systems involving a large number of degrees of freedom, generally exhibit non-stationary dynamics, which can result in either continuous or discontinuous sample paths of the corresponding time series. The latter sample paths may be caused by discontinuous events – or jumps – with some distributed amplitudes, and disentangling effects caused by such jumps from effects caused by normal diffusion processes is a main problem for a detailed understanding of stochastic dynamics of complex systems. Here we introduce a non-parametric method to address this general problem. By means of a stochastic dynamical jump-diffusion modelling, we separate deterministic drift terms from different stochastic behaviors, namely diffusive and jumpy ones, and show that all of the unknown functions and coefficients of this modelling can be derived directly from measured time series. We demonstrate appli- cability of our method to empirical observations by a data-driven inference of the deterministic drift term and of the diffusive and jumpy behavior in brain dynamics from ten epilepsy patients. Particularly these different stochastic behaviors provide extra information that can be regarded valuable for diagnostic purposes.}}, 
pages = {35435}, 
number = {1}, 
volume = {6}, 
keywords = {}
}
@article{yetton2018quantifying, 
year = {2018}, 
title = {{Quantifying sleep architecture dynamics and individual differences using big data and Bayesian networks}}, 
author = {Yetton, Benjamin D. and McDevitt, Elizabeth A. and Cellini, Nicola and Shelton, Christian and Mednick, Sara C.}, 
journal = {PLoS ONE}, 
doi = {10.1371/journal.pone.0194604}, 
pmid = {29641599}, 
pmcid = {PMC5894981}, 
abstract = {{The pattern of sleep stages across a night (sleep architecture) is influenced by biological, behavioral, and clinical variables. However, traditional measures of sleep architecture such as stage proportions, fail to capture sleep dynamics. Here we quantify the impact of individual differences on the dynamics of sleep architecture and determine which factors or set of factors best predict the next sleep stage from current stage information. We investigated the influence of age, sex, body mass index, time of day, and sleep time on static (e.g. minutes in stage, sleep efficiency) and dynamic measures of sleep architecture (e.g. transition probabilities and stage duration distributions) using a large dataset of 3202 nights from a non-clinical population. Multi-level regressions show that sex effects duration of all Non-Rapid Eye Movement (NREM) stages, and age has a curvilinear relationship for Wake After Sleep Onset (WASO) and slow wave sleep (SWS) minutes. Bayesian network modeling reveals sleep architecture depends on time of day, total sleep time, age and sex, but not BMI. Older adults, and particularly males, have shorter bouts (more fragmentation) of Stage 2, SWS, and they transition less frequently to these stages. Additionally, we showed that the next sleep stage and its duration can be optimally predicted by the prior 2 stages and age. Our results demonstrate the potential benefit of big data and Bayesian network approaches in quantifying static and dynamic architecture of normal sleep.}}, 
pages = {e0194604}, 
number = {4}, 
volume = {13}, 
keywords = {}
}
@article{townsend2015emergence, 
year = {2015}, 
title = {{Emergence of Complex Wave Patterns in Primate Cerebral Cortex}}, 
author = {Townsend, Rory G. and Solomon, Selina S. and Chen, Spencer C. and Pietersen, Alexander N.J. and Martin, Paul R. and Solomon, Samuel G. and Gong, Pulin}, 
journal = {The Journal of Neuroscience}, 
issn = {0270-6474}, 
doi = {10.1523/jneurosci.4509-14.2015}, 
pmid = {25788682}, 
pmcid = {PMC4363391}, 
abstract = {{Slow brain rhythms are attributed to near-simultaneous (synchronous) changes in activity in neuron populations in the brain. Because they are slow and widespread, synchronous rhythms have not been considered crucial for information processing in the waking state. Here we adapted methods from turbulence physics to analyze δ-band (1–4 Hz) rhythms in local field potential (LFP) activity, in multielectrode recordings from cerebral cortex in anesthetized marmoset monkeys. We found that synchrony contributes only a small fraction (less than one-fourth) to the local spatiotemporal structure of δ-band signals. Rather, δ-band activity is dominated by propagating plane waves and spatiotemporal structures, which we call complex waves. Complex waves are manifest at submillimeter spatial scales, and millisecond-range temporal scales. We show that complex waves can be characterized by their relation to phase singularities within local nerve cell networks. We validate the biological relevance of complex waves by showing that nerve cell spike rates are higher in presence of complex waves than in the presence of synchrony and that there are nonrandom patterns of evolution from one type of complex wave to another. We conclude that slow brain rhythms predominantly indicate spatiotemporally organized activity in local nerve cell circuits, not synchronous activity within and across brain regions.}}, 
pages = {4657--4662}, 
number = {11}, 
volume = {35}, 
keywords = {}
}
@article{velazquez1999type, 
year = {1999}, 
title = {{Type III intermittency in human partial epilepsy}}, 
author = {Velazquez, J. L. Perez and Khosravani, Houman and Lozano, Andres and Bardakjian, Berj. L. and Carlen, Peter L. and Wennberg, Richard}, 
journal = {European Journal of Neuroscience}, 
issn = {0953-816X}, 
doi = {10.1046/j.1460-9568.1999.00688.x}, 
pmid = {10383646}, 
abstract = {{A rigorous characterization of the dynamic regimes underlying human seizures is needed to understand, and possibly control, the transition to seizure. Intra‐ or extracranial brain electrical activity was recorded in five patients with partial epilepsy, and the interictal and ictal activity analysed to determine the dynamics of seizures. We constructed first‐return one‐dimensional maps by fitting the scatter plots of interpeak intervals. The features of the mapping indicated that type III intermittency is the dynamic charateristic of the ictal events. This was confirmed using histograms of the durations of the regular phases during seizures. The intermittent regime explains the abrupt transitions observed during ictal events in terms of transient stabilization of the unstable steady state.}}, 
pages = {2571--2576}, 
number = {7}, 
volume = {11}, 
keywords = {}
}
@article{caruso2023single, 
year = {2018}, 
title = {{Single neurons may encode simultaneous stimuli by switching between activity patterns}}, 
author = {Caruso, Valeria C. and Mohl, Jeff T. and Glynn, Christopher and Lee, Jungah and Willett, Shawn M. and Zaman, Azeem and Ebihara, Akinori F. and Estrada, Rolando and Freiwald, Winrich A. and Tokdar, Surya T. and Groh, Jennifer M.}, 
journal = {Nature Communications}, 
doi = {10.1038/s41467-018-05121-8}, 
pmid = {30006598}, 
pmcid = {PMC6045601}, 
abstract = {{How the brain preserves information about multiple simultaneous items is poorly understood. We report that single neurons can represent multiple stimuli by interleaving signals across time. We record single units in an auditory region, the inferior colliculus, while monkeys localize 1 or 2 simultaneous sounds. During dual-sound trials, we find that some neurons fluctuate between firing rates observed for each single sound, either on a whole-trial or on a sub-trial timescale. These fluctuations are correlated in pairs of neurons, can be predicted by the state of local field potentials prior to sound onset, and, in one monkey, can predict which sound will be reported first. We find corroborating evidence of fluctuating activity patterns in a separate dataset involving responses of inferotemporal cortex neurons to multiple visual stimuli. Alternation between activity patterns corresponding to each of multiple items may therefore be a general strategy to enhance the brain processing capacity, potentially linking such disparate phenomena as variable neural firing, neural oscillations, and limits in attentional/memory capacity. The neural mechanisms through which neurons represent simultaneously presented stimuli are not well understood. Here the authors demonstrate that the two stimuli are alternately encoded through fluctuations in the activity patterns of single neurons.}}, 
pages = {2715}, 
number = {1}, 
volume = {9}, 
keywords = {}
}
@article{hartle2017transient, 
year = {2017}, 
title = {{Transient chaos and associated system-intrinsic switching of spacetime patterns in two synaptically coupled layers of Morris-Lecar neurons}}, 
author = {Hartle, Harrison and Wackerbauer, Renate}, 
journal = {Physical Review E}, 
issn = {2470-0045}, 
doi = {10.1103/physreve.96.032223}, 
pmid = {29347029}, 
abstract = {{Spatiotemporal chaos collapses to either a rest state or a propagating pulse solution in a single layer of diffusively coupled, excitable Morris-Lecar neurons. Weak synaptic coupling of two such layers reveals system intrinsic switching of spatiotemporal activity patterns within and between the layers at irregular times. Within a layer, switching sequences include spatiotemporal chaos, erratic and regular pulse propagation, spontaneous network wide neuron activity, and rest state. A momentary substantial reduction in neuron activity in one layer can reinitiate transient spatiotemporal chaos in the other layer, which can induce a swap of spatiotemporal chaos with a pulse state between the layers. Presynaptic input maximizes the distance between propagating pulses, in contrast to pulse merging in the absence of synapses.}}, 
pages = {032223}, 
number = {3}, 
volume = {96}, 
keywords = {}
}
@article{kaminker2019alternating, 
year = {2019}, 
title = {{Alternating activity patterns and a chimeralike state in a network of globally coupled excitable Morris-Lecar neurons}}, 
author = {Kaminker, Vitaliy and Wackerbauer, Renate}, 
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science}, 
issn = {1054-1500}, 
doi = {10.1063/1.5093483}, 
pmid = {31154794}, 
abstract = {{Spatiotemporal chaos collapses to either a rest state or a propagating pulse in a ring network of diffusively coupled, excitable Morris–Lecar neurons. Adding global varying synaptic coupling to the ring network reveals complex transient behavior. Spatiotemporal chaos collapses into a transient pulse that reinitiates spatiotemporal chaos to allow sequential pattern switching until a collapse to the rest state. A domain of irregular neuron activity coexists with a domain of inactive neurons forming a transient chimeralike state. Transient spatial localization of the chimeralike state is observed for stronger synapses.}}, 
pages = {053121}, 
number = {5}, 
volume = {29}, 
keywords = {}
}
@article{keplinger2014transient, 
year = {2014}, 
title = {{Transient spatiotemporal chaos in the Morris-Lecar neuronal ring network}}, 
author = {Keplinger, Keegan and Wackerbauer, Renate}, 
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science}, 
issn = {1054-1500}, 
doi = {10.1063/1.4866974}, 
pmid = {24697388}, 
abstract = {{Transient behavior is thought to play an integral role in brain functionality. Numerical simulations of the firing activity of diffusively coupled, excitable Morris-Lecar neurons reveal transient spatiotemporal chaos in the parameter regime below the saddle-node on invariant circle bifurcation point. The neighborhood of the chaotic saddle is reached through perturbations of the rest state, in which few initially active neurons at an effective spatial distance can initiate spatiotemporal chaos. The system escapes from the neighborhood of the chaotic saddle to either the rest state or to a state of pulse propagation. The lifetime of the chaotic transients is manipulated in a statistical sense through a singular application of a synchronous perturbation to a group of neurons.}}, 
pages = {013126}, 
number = {1}, 
volume = {24}, 
keywords = {}
}
@article{contreras1996control, 
year = {1996}, 
title = {{Control of Spatiotemporal Coherence of a Thalamic Oscillation by Corticothalamic Feedback}}, 
author = {Contreras, Diego and Destexhe, Alain and Sejnowski, Terrence J. and Steriade, Mircea}, 
journal = {Science}, 
issn = {0036-8075}, 
doi = {10.1126/science.274.5288.771}, 
pmid = {8864114}, 
abstract = {{The mammalian thalamus is the gateway to the cortex for most sensory modalities. Nearly all thalamic nuclei also receive massive feedback projections from the cortical region to which they project. In this study, the spatiotemporal properties of synchronized thalamic spindle oscillations (7 to 14 hertz) were investigated in barbiturate-anesthetized cats, before and after removal of the cortex. After complete ipsilateral decortication, the long-range synchronization of thalamic spindles in the intact cortex hemisphere changed into disorganized patterns with low spatiotemporal coherence. Local thalamic synchrony was still present, as demonstrated by dual intracellular recordings from nearby neurons. In the cortex, synchrony was insensitive to the disruption of horizontal intracortical connections. These results indicate that the global coherence of thalamic oscillations is determined by corticothalamic projections.}}, 
pages = {771--774}, 
number = {5288}, 
volume = {274}, 
keywords = {}
}
@article{steriade1993thalamocortical, 
year = {1993}, 
title = {{Thalamocortical Oscillations in the Sleeping and Aroused Brain}}, 
author = {Steriade, Mircea and McCormick, David A. and Sejnowski, Terrence J.}, 
journal = {Science}, 
issn = {0036-8075}, 
doi = {10.1126/science.8235588}, 
pmid = {8235588}, 
abstract = {{Sleep is characterized by synchronized events in billions of synaptically coupled neurons in thalamocortical systems. The activation of a series of neuromodulatory transmitter systems during awakening blocks low-frequency oscillations, induces fast rhythms, and allows the brain to recover full responsiveness. Analysis of cortical and thalamic networks at many levels, from molecules to single neurons to large neuronal assemblies, with a variety of techniques, ranging from intracellular recordings in vivo and in vitro to computer simulations, is beginning to yield insights into the mechanisms of the generation, modulation, and function of brain oscillations.}}, 
pages = {679--685}, 
number = {5134}, 
volume = {262}, 
keywords = {}
}
@article{poulet2008internal, 
year = {2008}, 
title = {{Internal brain state regulates membrane potential synchrony in barrel cortex of behaving mice}}, 
author = {Poulet, James F. A. and Petersen, Carl C. H.}, 
journal = {Nature}, 
issn = {0028-0836}, 
doi = {10.1038/nature07150}, 
pmid = {18633351}, 
abstract = {{Differences in synchronized activity in cortical neurons characterize different brain states, and are thought to be fundamental mechanisms of neural computation. James Poulet and Carl Petersen now show using dual whole-cell recordings from somatosensory barrel cortex in behaving mice, that the membrane potential of nearby neurons is highly correlated during quiet wakefulness but this correlation is reduced when the mice were actively whisking — a stereotypic back-and-forth movement of the whickers used to explore the environment. This suggests that internal brain states dynamically regulate cortical membrane potential synchrony during behaviour, defining different modes of cortical processing. Differences in synchronized activity in cortical neurons characterize different brain states. Petersen and colleagues now show that in mice the membrane potential of nearby neurons is highly correlated during quiet wakefulness but this correlation is reduced when mice are actively whisking. This suggests that internal brain states dynamically regulate cortical membrane potential synchrony during behaviour. Internal brain states form key determinants for sensory perception, sensorimotor coordination and learning1,2. A prominent reflection of different brain states in the mammalian central nervous system is the presence of distinct patterns of cortical synchrony, as revealed by extracellular recordings of the electroencephalogram, local field potential and action potentials. Such temporal correlations of cortical activity are thought to be fundamental mechanisms of neuronal computation3,4,5,6,7,8,9,10,11. However, it is unknown how cortical synchrony is reflected in the intracellular membrane potential (Vm) dynamics of behaving animals. Here we show, using dual whole-cell recordings from layer 2/3 primary somatosensory barrel cortex in behaving mice, that the Vm of nearby neurons is highly correlated during quiet wakefulness. However, when the mouse is whisking, an internally generated state change reduces the Vm correlation, resulting in a desynchronized local field potential and electroencephalogram. Action potential activity was sparse during both quiet wakefulness and active whisking. Single action potentials were driven by a large, brief and specific excitatory input that was not present in the Vm of neighbouring cells. Action potential initiation occurs with a higher signal-to-noise ratio during active whisking than during quiet periods. Therefore, we show that an internal brain state dynamically regulates cortical membrane potential synchrony during behaviour and defines different modes of cortical processing.}}, 
pages = {881--885}, 
number = {7206}, 
volume = {454}, 
keywords = {}
}
@article{jouvet1979does, 
year = {1979}, 
title = {{What does a cat dream about?}}, 
author = {Jouvet, Michel}, 
journal = {Trends in Neurosciences}, 
issn = {0166-2236}, 
doi = {10.1016/0166-2236(79)90110-3}, 
abstract = {{When the neural systems which are responsible for postural atonia during paradoxical sleep are destroyed, sleeping cats periodically display stereotyped motor activity, revealing a rich repertoire of non-goal-directed ‘oneiric behaviour’.}}, 
pages = {280--282}, 
volume = {2}, 
keywords = {}
}
@article{desroches2012mixed, 
year = {2012}, 
title = {{Mixed-Mode Oscillations with Multiple Time Scales}}, 
author = {Desroches, Mathieu and Guckenheimer, John and Krauskopf, Bernd and Kuehn, Christian and Osinga, Hinke M. and Wechselberger, Martin}, 
journal = {SIAM Review}, 
issn = {0036-1445}, 
doi = {10.1137/100791233}, 
abstract = {{Mixed-mode oscillations (MMOs) are trajectories of a dynamical system in which there is an alternation between oscillations of distinct large and small amplitudes. MMOs have been observed and studied for over thirty years in chemical, physical, and biological systems. Few attempts have been made thus far to classify different patterns of MMOs, in contrast to the classification of the related phenomena of bursting oscillations. This paper gives a survey of different types of MMOs, concentrating its analysis on MMOs whose small-amplitude oscillations are produced by a local, multiple-time-scale mechanism. Recent work gives substantially improved insight into the mathematical properties of these mechanisms. In this survey, we unify diverse observations about MMOs and establish a systematic framework for studying their properties. Numerical methods for computing different types of invariant manifolds and their intersections are an important aspect of the analysis described in this paper.}}, 
pages = {211--288}, 
number = {2}, 
volume = {54}, 
keywords = {}
}
@article{lang2023temporal, 
year = {2023}, 
title = {{Temporal progression along discrete coding states during decision-making in the mouse gustatory cortex}}, 
author = {Lang, Liam and Camera, Giancarlo La and Fontanini, Alfredo}, 
journal = {PLOS Computational Biology}, 
issn = {1553-734X}, 
doi = {10.1371/journal.pcbi.1010865}, 
pmid = {36749734}, 
pmcid = {PMC9904478}, 
abstract = {{The mouse gustatory cortex (GC) is involved in taste-guided decision-making in addition to sensory processing. Rodent GC exhibits metastable neural dynamics during ongoing and stimulus-evoked activity, but how these dynamics evolve in the context of a taste-based decision-making task remains unclear. Here we employ analytical and modeling approaches to i) extract metastable dynamics in ensemble spiking activity recorded from the GC of mice performing a perceptual decision-making task; ii) investigate the computational mechanisms underlying GC metastability in this task; and iii) establish a relationship between GC dynamics and behavioral performance. Our results show that activity in GC during perceptual decision-making is metastable and that this metastability may serve as a substrate for sequentially encoding sensory, abstract cue, and decision information over time. Perturbations of the model’s metastable dynamics indicate that boosting inhibition in different coding epochs differentially impacts network performance, explaining a counterintuitive effect of GC optogenetic silencing on mouse behavior.}}, 
pages = {e1010865}, 
number = {2}, 
volume = {19}, 
keywords = {}
}
@article{wang202150, 
year = {2021}, 
title = {{50 years of mnemonic persistent activity: quo vadis?}}, 
author = {Wang and Xiao-Jing}, 
journal = {Trends in Neurosciences}, 
issn = {0166-2236}, 
doi = {10.1016/j.tins.2021.09.001}, 
pmid = {34654556}, 
pmcid = {PMC9087306}, 
abstract = {{Half a century ago persistent spiking activity in the neocortex was discovered to be a neural substrate of working memory. Since then scientists have sought to understand this core cognitive function across biological and computational levels. Studies are reviewed here that cumulatively lend support to a synaptic theory of recurrent circuits for mnemonic persistent activity that depends on various cellular and network substrates and is mathematically described by a multiple-attractor network model. Crucially, a mnemonic attractor state of the brain is consistent with temporal variations and heterogeneity across neurons in a subspace of population activity. Persistent activity should be broadly understood as a contrast to decaying transients. Mechanisms in the absence of neural firing ('activity-silent state') are suitable for passive short-term memory but not for working memory – which is characterized by executive control for filtering out distractors, limited capacity, and internal manipulation of information.}}, 
pages = {888--902}, 
number = {11}, 
volume = {44}, 
keywords = {}
}
@article{khona2022attractor, 
year = {2022}, 
title = {{Attractor and integrator networks in the brain}}, 
author = {Khona, Mikail and Fiete, Ila R.}, 
journal = {Nature Reviews Neuroscience}, 
issn = {1471-003X}, 
doi = {10.1038/s41583-022-00642-0}, 
pmid = {36329249}, 
abstract = {{In this Review, we describe the singular success of attractor neural network models in describing how the brain maintains persistent activity states for working memory, corrects errors and integrates noisy cues. We consider the mechanisms by which simple and forgetful units can organize to collectively generate dynamics on the long timescales required for such computations. We discuss the myriad potential uses of attractor dynamics for computation in the brain, and showcase notable examples of brain systems in which inherently low-dimensional continuous-attractor dynamics have been concretely and rigorously identified. Thus, it is now possible to conclusively state that the brain constructs and uses such systems for computation. Finally, we highlight recent theoretical advances in understanding how the fundamental trade-offs between robustness and capacity and between structure and flexibility can be overcome by reusing and recombining the same set of modular attractors for multiple functions, so they together produce representations that are structurally constrained and robust but exhibit high capacity and are flexible. Attractor network dynamics can support several computations performed by the brain. In their Review, Khona and Fiete introduce different attractor dynamics and their computational utility, describe evidence of attractor networks across the brain and explain how such networks could be recombined to increase their flexibility and versatility.}}, 
pages = {744--766}, 
number = {12}, 
volume = {23}, 
keywords = {}
}
@article{pisarchik, 
year = {2022}, 
title = {{Multistability in Physical and Living Systems, Characterization and Applications}}, 
author = {Pisarchik, Alexander N. and Hramov, Alexander E.}, 
journal = {Springer Series in Synergetics}, 
issn = {0172-7389}, 
doi = {10.1007/978-3-030-98396-3}, 
keywords = {}
}
@article{10.3389/fncom.2023.1137015, 
year = {2023}, 
title = {{New insights into binocular rivalry from the reconstruction of evolving percepts using model network dynamics}}, 
author = {Barkdoll, Kenneth and Lu, Yuhua and Barranca, Victor J.}, 
journal = {Frontiers in Computational Neuroscience}, 
issn = {1662-5188}, 
doi = {10.3389/fncom.2023.1137015}, 
pmid = {37034441}, 
pmcid = {PMC10079880}, 
abstract = {{When the two eyes are presented with highly distinct stimuli, the resulting visual percept generally switches every few seconds between the two monocular images in an irregular fashion, giving rise to a phenomenon known as binocular rivalry. While a host of theoretical studies have explored potential mechanisms for binocular rivalry in the context of evoked model dynamics in response to simple stimuli, here we investigate binocular rivalry directly through complex stimulus reconstructions based on the activity of a two-layer neuronal network model with competing downstream pools driven by disparate monocular stimuli composed of image pixels. To estimate the dynamic percept, we derive a linear input-output mapping rooted in the non-linear network dynamics and iteratively apply compressive sensing techniques for signal recovery. Utilizing a dominance metric, we are able to identify when percept alternations occur and use data collected during each dominance period to generate a sequence of percept reconstructions. We show that despite the approximate nature of the input-output mapping and the significant reduction in neurons downstream relative to stimulus pixels, the dominant monocular image is well-encoded in the network dynamics and improvements are garnered when realistic spatial receptive field structure is incorporated into the feedforward connectivity. Our model demonstrates gamma-distributed dominance durations and well obeys Levelt's four laws for how dominance durations change with stimulus strength, agreeing with key recurring experimental observations often used to benchmark rivalry models. In light of evidence that individuals with autism exhibit relatively slow percept switching in binocular rivalry, we corroborate the ubiquitous hypothesis that autism manifests from reduced inhibition in the brain by systematically probing our model alternation rate across choices of inhibition strength. We exhibit sufficient conditions for producing binocular rivalry in the context of natural scene stimuli, opening a clearer window into the dynamic brain computations that vary with the generated percept and a potential path toward further understanding neurological disorders.}}, 
pages = {1137015}, 
volume = {17}, 
keywords = {}
}
@article{benigno2023waves, 
year = {2023}, 
title = {{Waves traveling over a map of visual space can ignite short-term predictions of sensory input}}, 
author = {Benigno, Gabriel B. and Budzinski, Roberto C. and Davis, Zachary W. and Reynolds, John H. and Muller, Lyle}, 
journal = {Nature Communications}, 
doi = {10.1038/s41467-023-39076-2}, 
pmid = {37296131}, 
pmcid = {PMC10256723}, 
abstract = {{Recent analyses have found waves of neural activity traveling across entire visual cortical areas in awake animals. These traveling waves modulate the excitability of local networks and perceptual sensitivity. The general computational role of these spatiotemporal patterns in the visual system, however, remains unclear. Here, we hypothesize that traveling waves endow the visual system with the capacity to predict complex and naturalistic inputs. We present a network model whose connections can be rapidly and efficiently trained to predict individual natural movies. After training, a few input frames from a movie trigger complex wave patterns that drive accurate predictions many frames into the future solely from the network’s connections. When the recurrent connections that drive waves are randomly shuffled, both traveling waves and the ability to predict are eliminated. These results suggest traveling waves may play an essential computational role in the visual system by embedding continuous spatiotemporal structures over spatial maps. Waves of neural activity travel across single regions in the visual cortex, but their computational role is unclear. Here, the authors present a neural network model demonstrating that waves traveling over retinotopic maps can enable short-term predictions of future inputs.}}, 
pages = {3409}, 
number = {1}, 
volume = {14}, 
keywords = {}
}
@article{10.1103/physreve.62.2644, 
year = {2000}, 
title = {{Synchronous behavior of two coupled electronic neurons}}, 
author = {Pinto, R. D. and Varona, P. and Volkovskii, A. R. and Szücs, A. and Abarbanel, Henry D. I. and Rabinovich, M. I.}, 
journal = {Physical Review E}, 
issn = {1539-3755}, 
doi = {10.1103/physreve.62.2644}, 
pmid = {11088744}, 
eprint = {nlin/0001020}, 
abstract = {{We report on experimental studies of synchronization phenomena in a pair of analog electronic neurons (ENs). The ENs were designed to reproduce the observed membrane voltage oscillations of isolated biological neurons from the stomatogastric ganglion of the California spiny lobster Panulirus interruptus. The ENs are simple analog circuits which integrate four-dimensional differential equations representing fast and slow subcellular mechanisms that produce the characteristic regular/chaotic spiking–bursting behavior of these cells. In this paper we study their dynamical behavior as we couple them in the same configurations as we have done for their counterpart biological neurons. The interconnections we use for these neural oscillators are both direct electrical connections and excitatory and inhibitory chemical connections: each realized by analog circuitry and suggested by biological examples. We provide here quantitative evidence that the ENs and the biological neurons behave similarly when coupled in the same manner. They each display well defined bifurcations in their mutual synchronization and regularization. We report briefly on an experiment on coupled biological neurons and four-dimensional ENs, which provides further ground for testing the validity of our numerical and electronic models of individual neural behavior. Our experiments as a whole present interesting new examples of regularization and synchronization in coupled nonlinear oscillators.}}, 
pages = {2644--2656}, 
number = {2}, 
volume = {62}, 
keywords = {}
}
@article{datseris2023framework, 
year = {2023}, 
title = {{Framework for global stability analysis of dynamical systems}}, 
author = {Datseris, George and Rossi, Kalel Luiz and Wagemakers, Alexandre}, 
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science}, 
issn = {1054-1500}, 
doi = {10.1063/5.0159675}, 
pmid = {37499248}, 
eprint = {2304.12786}, 
abstract = {{Dynamical systems that are used to model power grids, the brain, and other physical systems can exhibit coexisting stable states known as attractors. A powerful tool to understand such systems, as well as to better predict when they may “tip” from one stable state to the other, is global stability analysis. It involves identifying the initial conditions that converge to each attractor, known as the basins of attraction, measuring the relative volume of these basins in state space, and quantifying how these fractions change as a system parameter evolves. By improving existing approaches, we present a comprehensive framework that allows for global stability analysis of dynamical systems. Notably, our framework enables the analysis to be made efficiently and conveniently over a parameter range. As such, it becomes an essential tool for stability analysis of dynamical systems that goes beyond local stability analysis offered by alternative frameworks. We demonstrate the effectiveness of our approach on a variety of models, including climate, power grids, ecosystems, and more. Our framework is available as simple-to-use open-source code as part of the DynamicalSystems.jl library.}}, 
pages = {073151}, 
number = {7}, 
volume = {33}, 
keywords = {}
}
@article{rossi2022shifts, 
year = {2023}, 
title = {{Shifts in global network dynamics due to small changes at single nodes}}, 
author = {Rossi, Kalel L. and Budzinski, Roberto C. and Boaretto, Bruno R. R. and Muller, Lyle E. and Feudel, Ulrike}, 
journal = {Physical Review Research}, 
doi = {10.1103/physrevresearch.5.013220}, 
abstract = {{Understanding the sensitivity of a system's behavior with respect to parameter changes is essential for many applications. This sensitivity may be desired—for instance, in the brain, where a large repertoire of different dynamics, particularly different synchronization patterns, is crucial—or may be undesired—for instance, in power grids, where disruptions to synchronization may lead to blackouts. In this paper, we show that networks of coupled phase oscillators with nonlinear interactions can acquire a very large and complicated sensitivity to changes made in either their units' parameters or in their connections. Even modifications made to a parameter of a single unit can radically alter the global dynamics of the network in an unpredictable manner. This occurs over a wide parameter region, around the network's transitions to phase synchronization. We argue that this is a widespread phenomenon that can be expected in real-world systems, extending even beyond networks of oscillators.}}, 
pages = {013220}, 
number = {1}, 
volume = {5}, 
keywords = {}
}
@article{10.48550/arxiv.2307.16113, 
year = {2023}, 
title = {{Dynamics of Minimal Networks of Limit Cycle Oscillators}}, 
author = {Biju, Andrea Elizabeth and Srikanth, Sneha and Manoj, Krishna and Pawar, Samadhan A and Sujith, R I}, 
journal = {arXiv}, 
doi = {10.48550/arxiv.2307.16113}, 
eprint = {2307.16113}, 
abstract = {{The framework of mutually coupled oscillators on a network has served as a convenient tool for investigating the impact of various parameters on the dynamics of real-world systems. Compared to large networks of oscillators, minimal networks are more susceptible to changes in coupling parameters, the number of oscillators, and network topologies. In this study, we systematically explore the influence of these parameters on the dynamics of a minimal network comprising Stuart-Landau oscillators coupled with a distance-dependent time delay. We examine three network topologies: ring, chain, and star. Specifically, for ring networks, we study the effects of increasing nonlocality from local to global coupling on the overall dynamics of the system. Our findings reveal the existence of various synchronized states, including splay and cluster states, a partially synchronized state such as chimeric quasiperiodicity, and an oscillation quenching state such as amplitude death in these networks. Moreover, through an analysis of long-lived transients, we discover novel amplitude-modulated states within ring networks. Interestingly, we observe that increasing nonlocality diminishes the influence of the number of oscillators on the overall behavior in these networks. Furthermore, we note that chain networks, unlike ring networks, do not exhibit perfect synchrony among the coupled oscillators. In contrast, star networks demonstrate greater stability and are unaffected by the number of oscillators within the network. The insights from this study deepen our understanding of the dynamics of minimal networks and have implications for various fields, ranging from biology to engineering.}}, 
keywords = {}
}
@article{nandan2022cells, 
year = {2022}, 
title = {{Cells use molecular working memory to navigate in changing chemoattractant fields}}, 
author = {Nandan, Akhilesh and Das, Abhishek and Lott, Robert and Koseska, Aneta}, 
journal = {eLife}, 
doi = {10.7554/elife.76825}, 
pmid = {35666122}, 
pmcid = {PMC9282860}, 
abstract = {{In order to migrate over large distances, cells within tissues and organisms rely on sensing local gradient cues which are irregular, conflicting, and changing over time and space. The mechanism how they generate persistent directional migration when signals are disrupted, while still remaining adaptive to signal’s localization changes remain unknown. Here, we find that single cells utilize a molecular mechanism akin to a working memory to satisfy these two opposing demands. We derive theoretically that this is characteristic for receptor networks maintained away from steady states. Time-resolved live-cell imaging of Epidermal growth factor receptor (EGFR) phosphorylation dynamics shows that cells transiently memorize position of encountered signals via slow-escaping remnant of the polarized signaling state, a dynamical ‘ghost’, driving memory-guided persistent directional migration. The metastability of this state further enables migrational adaptation when encountering new signals. We thus identify basic mechanism of real-time computations underlying cellular navigation in changing chemoattractant fields.}}, 
pages = {e76825}, 
volume = {11}, 
keywords = {}
}
@article{nandan2023non, 
year = {2023}, 
title = {{Non-asymptotic transients away from steady states determine cellular responsiveness to dynamic spatial-temporal signals}}, 
author = {Nandan, Akhilesh and Koseska, Aneta}, 
journal = {PLOS Computational Biology}, 
issn = {1553-734X}, 
doi = {10.1371/journal.pcbi.1011388}, 
pmid = {37578988}, 
pmcid = {PMC10449117}, 
abstract = {{Majority of the theory on cell polarization and the understanding of cellular sensing and responsiveness to localized chemical cues has been based on the idea that non-polarized and polarized cell states can be represented by stable asymptotic switching between them. The existing model classes that describe the dynamics of signaling networks underlying polarization are formulated within the framework of autonomous systems. However these models do not simultaneously capture both, robust maintenance of polarized state longer than the signal duration, and retained responsiveness to signals with complex spatial-temporal distribution. Based on recent experimental evidence for criticality organization of biochemical networks, we challenge the current concepts and demonstrate that non-asymptotic signaling dynamics arising at criticality uniquely ensures optimal responsiveness to changing chemoattractant fields. We provide a framework to characterize non-asymptotic dynamics of system’s state trajectories through a non-autonomous treatment of the system, further emphasizing the importance of (long) transient dynamics, as well as the necessity to change the mathematical formalism when describing biological systems that operate in changing environments.}}, 
pages = {e1011388}, 
number = {8}, 
volume = {19}, 
keywords = {}
}
@article{10.1371/journal.pone.0221401, 
year = {2019}, 
title = {{Spontaneous termination of chaotic spiral wave dynamics in human cardiac ion channel models}}, 
author = {Aron, Marcel and Herzog, Sebastian and Parlitz, Ulrich and Luther, Stefan and Lilienkamp, Thomas}, 
journal = {PLoS ONE}, 
doi = {10.1371/journal.pone.0221401}, 
pmid = {31461472}, 
pmcid = {PMC6713330}, 
abstract = {{Chaotic spiral or scroll wave dynamics can be found in diverse systems. In cardiac dynamics, spiral or scroll waves of electrical excitation determine the dynamics during life-threatening arrhythmias like ventricular fibrillation. In numerical studies it was found that chaotic episodes of spiral and scroll waves can be transient, thus they terminate spontaneously. We show in this study that this behavior can also be observed using models which describe the ion channel dynamics of human cardiomyocytes (Bueno-Orovio-Cherry-Fenton model and the Ten Tusscher-Noble-Noble-Panfilov model). For both models we find that the average lifetime of the chaotic transients grows exponentially with the system size. With this behavior, we classify the systems into the group of type-II supertransients. We observe a significant difference of the breakup behavior between the models, which results in a distinct dynamics during the final phase just before the termination. The observation of a (temporally) stable single-spiral state affects the prevailing description of the dynamics of type-II supertransients as being “quasi-stationary” and also the feasibility of predicting the spontaneous termination of the spiral wave dynamics. In the long term, the relation between the breakup behavior of spiral waves and properties of chaotic transients like predictability or average transient lifetime may contribute to an improved understanding and classification of cardiac arrhythmias.}}, 
pages = {e0221401}, 
number = {8}, 
volume = {14}, 
keywords = {}
}
@article{10.1098/rsif.2012.0434, 
year = {2012}, 
title = {{Quasi-potential landscape in complex multi-stable systems}}, 
author = {Zhou, Joseph Xu and Aliyu, M. D. S. and Aurell, Erik and Huang, Sui}, 
journal = {Journal of The Royal Society Interface}, 
issn = {1742-5689}, 
doi = {10.1098/rsif.2012.0434}, 
pmid = {22933187}, 
pmcid = {PMC3481575}, 
abstract = {{The developmental dynamics of multicellular organisms is a process that takes place in a multi-stable system in which each attractor state represents a cell type, and attractor transitions correspond to cell differentiation paths. This new understanding has revived the idea of a quasi-potential landscape, first proposed by Waddington as a metaphor. To describe development, one is interested in the ‘relative stabilities’ of N attractors (N > 2). Existing theories of state transition between local minima on some potential landscape deal with the exit part in the transition between two attractors in pair-attractor systems but do not offer the notion of a global potential function that relates more than two attractors to each other. Several ad hoc methods have been used in systems biology to compute a landscape in non-gradient systems, such as gene regulatory networks. Here we present an overview of currently available methods, discuss their limitations and propose a new decomposition of vector fields that permits the computation of a quasi-potential function that is equivalent to the Freidlin–Wentzell potential but is not limited to two attractors. Several examples of decomposition are given, and the significance of such a quasi-potential function is discussed.}}, 
pages = {3539--3553}, 
number = {77}, 
volume = {9}, 
keywords = {}
}
@article{kuhlmann2018seizure, 
year = {2018}, 
title = {{Seizure prediction — ready for a new era}}, 
author = {Kuhlmann, Levin and Lehnertz, Klaus and Richardson, Mark P. and Schelter, Björn and Zaveri, Hitten P.}, 
journal = {Nature Reviews Neurology}, 
issn = {1759-4758}, 
doi = {10.1038/s41582-018-0055-2}, 
pmid = {30131521}, 
abstract = {{Epilepsy is a common disorder characterized by recurrent seizures. An overwhelming majority of people with epilepsy regard the unpredictability of seizures as a major issue. More than 30 years of international effort have been devoted to the prediction of seizures, aiming to remove the burden of unpredictability and to couple novel, time-specific treatment to seizure prediction technology. A highly influential review published in 2007 concluded that insufficient evidence indicated that seizures could be predicted. Since then, several advances have been made, including successful prospective seizure prediction using intracranial EEG in a small number of people in a trial of a real-time seizure prediction device. In this Review, we examine advances in the field, including EEG databases, seizure prediction competitions, the prospective trial mentioned and advances in our understanding of the mechanisms of seizures. We argue that these advances, together with statistical evaluations, set the stage for a resurgence in efforts towards the development of seizure prediction methodologies. We propose new avenues of investigation involving a synergy between mechanisms, models, data, devices and algorithms and refine the existing guidelines for the development of seizure prediction technology to instigate development of a solution that removes the burden of the unpredictability of seizures. In this Review, the authors consider advances over the past decade that have set the stage for a resurgence in attempts to predict seizures in epilepsy, and they propose new avenues of investigation that combine mechanisms, models, data, devices and algorithms. One clinical trial has shown that prospective seizure prediction in humans is possible.Databases of EEG data provide a standard reference for comparison of seizure prediction algorithms and for hypothesis generation.Competitions provide a platform for identification of the best seizure prediction algorithms.The network theory of epilepsy, multimodal recording techniques, long-term monitoring and computational modelling are providing new approaches to seizure prediction.The field is ready for a large-scale clinical trial of seizure prediction. One clinical trial has shown that prospective seizure prediction in humans is possible. Databases of EEG data provide a standard reference for comparison of seizure prediction algorithms and for hypothesis generation. Competitions provide a platform for identification of the best seizure prediction algorithms. The network theory of epilepsy, multimodal recording techniques, long-term monitoring and computational modelling are providing new approaches to seizure prediction. The field is ready for a large-scale clinical trial of seizure prediction.}}, 
pages = {618--630}, 
number = {10}, 
volume = {14}, 
keywords = {}
}
@article{froyland2005statistically, 
year = {2005}, 
title = {{Statistically optimal almost-invariant sets}}, 
author = {Froyland, Gary}, 
journal = {Physica D: Nonlinear Phenomena}, 
issn = {0167-2789}, 
doi = {10.1016/j.physd.2004.11.008}, 
abstract = {{Chaotic dynamical systems are often transitive, although this transitivity is sometimes very weak. It is of interest to divide the phase space into large regions, between which there is relatively little communication of trajectories. We present fast, simple algorithms to find such divisions. The present work builds on the results of Froyland and Dellnitz [G. Froyland, M. Dellnitz, Detecting and locating near-optimal almost-invariant sets and cycles, SIAM J. Sci. Comput. 24 (6) (2003) 1839–1863], focussing on a statistical description of transitivity that takes into account the fact that trajectories tend to visit different regions of phase space with different frequencies. The new work takes advantage of theoretical results from the theory of reversible Markov chains. A new adaptive algorithm is put forward to efficiently deal with situations where the boundaries of the weakly communicating regions are complicated. This algorithm is illustrated with the standard map. Relevant convergence results are proven.}}, 
pages = {205--219}, 
number = {3-4}, 
volume = {200}, 
keywords = {}
}
@article{dellnitz2003congestion, 
year = {2003}, 
title = {{Symbolic and Numerical Scientific Computation, Second International Conference, SNSC 2001, Hagenberg, Austria, September 12–14, 2001. Revised Papers}}, 
author = {Dellnitz, Michael and Preis, Robert}, 
journal = {Lecture Notes in Computer Science}, 
issn = {0302-9743}, 
doi = {10.1007/3-540-45084-x\_8}, 
abstract = {{An almost invariant set of a dynamical system is a subset of state space where typical trajectories stay for a long period of time before they enter other parts of state space. These sets are an important characteristic for analyzing the macroscopic behavior of a given dynamical system. For instance, recently the identification of almost invariant sets has successfully been used in the context of the approximation of so-called chemical conformations for molecules. In this paper we propose new numerical and algorithmic tools for the identification of the number and the location of almost invariant sets in state space. These techniques are based on the use of set oriented numerical methods by which a graph is created which models the underlying dynamical behavior. In a second step graph theoretic methods are utilized in order to both identify the number of almost invariant sets and for an approximation of these sets. These algorithmic methods make use of the notion of congestion which is a quantity specifying bottlenecks in the graph. We apply these new techniques to the analysis of the dynamics of the molecules Pentane and Hexane. Our computational results are compared to analytical bounds which again are based on the congestion but also on spectral information on the transition matrix for the underlying graph.}}, 
pages = {183--209}, 
keywords = {}
}
@article{froyland2003detecting, 
year = {2003}, 
title = {{Detecting and Locating Near-Optimal Almost-Invariant Sets and Cycles}}, 
author = {Froyland, Gary and Dellnitz, Michael}, 
journal = {SIAM Journal on Scientific Computing}, 
issn = {1064-8275}, 
doi = {10.1137/s106482750238911x}, 
abstract = {{The behaviors of trajectories of nonlinear dynamical systems are notoriously hard to characterize and predict. Rather than characterizing dynamical behavior at the level of trajectories, we consider following the evolution of sets. There are often collections of sets that behave in a very predictable way, in spite of the fact that individual trajectories are entirely unpredictable. Such special collections of sets are invisible to studies of long trajectories. We describe a global set-oriented method to detect and locate these large dynamical structures. Our approach is a marriage of new ideas in modern dynamical systems theory and the novel application of graph dissection algorithms.}}, 
pages = {1839--1863}, 
number = {6}, 
volume = {24}, 
keywords = {}
}
@article{froyland2009almost, 
year = {2009}, 
title = {{Almost-invariant sets and invariant manifolds — Connecting probabilistic and geometric descriptions of coherent structures in flows}}, 
author = {Froyland, Gary and Padberg, Kathrin}, 
journal = {Physica D: Nonlinear Phenomena}, 
issn = {0167-2789}, 
doi = {10.1016/j.physd.2009.03.002}, 
abstract = {{We study the transport and mixing properties of flows in a variety of settings, connecting the classical geometrical approach via invariant manifolds with a probabilistic approach via transfer operators. For non-divergent fluid-like flows, we demonstrate that eigenvectors of numerical transfer operators efficiently decompose the domain into invariant regions. For dissipative chaotic flows such a decomposition into invariant regions does not exist; instead, the transfer operator approach detects almost-invariant sets. We demonstrate numerically that the boundaries of these almost-invariant regions are predominantly comprised of segments of co-dimension 1 invariant manifolds. For a mixing periodically driven fluid-like flow we show that while sets bounded by stable and unstable manifolds are almost-invariant, the transfer operator approach can identify almost-invariant sets with smaller mass leakage. Thus the transport mechanism of lobe dynamics need not correspond to minimal transport.The transfer operator approach is purely probabilistic; it directly determines those regions that minimally mix with their surroundings. The almost-invariant regions are identified via eigenvectors of a transfer operator and are ranked by the corresponding eigenvalues in the order of the sets’ invariance or “leakiness”. While we demonstrate that the almost-invariant sets are often bounded by segments of invariant manifolds, without such a ranking it is not at all clear which intersections of invariant manifolds form the major barriers to mixing. Furthermore, in some cases invariant manifolds do not bound sets of minimal leakage.Our transfer operator constructions are very simple and fast to implement; they require a sample of short trajectories, followed by eigenvector calculations of a sparse matrix.}}, 
pages = {1507--1523}, 
number = {16}, 
volume = {238}, 
keywords = {}
}
@article{laje2013robust, 
year = {2013}, 
title = {{Robust timing and motor patterns by taming chaos in recurrent neural networks}}, 
author = {Laje, Rodrigo and Buonomano, Dean V}, 
journal = {Nature Neuroscience}, 
issn = {1097-6256}, 
doi = {10.1038/nn.3405}, 
pmid = {23708144}, 
pmcid = {PMC3753043}, 
eprint = {1210.2104}, 
abstract = {{Here the authors describe a recurrent neural network model that tells time on the order of seconds and generates complex spatiotemporal motor patterns in the presence of high levels of noise. Robustness is achieved through the tuning of the recurrent connections, which produces stable patterns in the face of perturbations. The brain's ability to tell time and produce complex spatiotemporal motor patterns is critical for anticipating the next ring of a telephone or playing a musical instrument. One class of models proposes that these abilities emerge from dynamically changing patterns of neural activity generated in recurrent neural networks. However, the relevant dynamic regimes of recurrent networks are highly sensitive to noise; that is, chaotic. We developed a firing rate model that tells time on the order of seconds and generates complex spatiotemporal patterns in the presence of high levels of noise. This is achieved through the tuning of the recurrent connections. The network operates in a dynamic regime that exhibits coexisting chaotic and locally stable trajectories. These stable patterns function as 'dynamic attractors' and provide a feature that is characteristic of biological systems: the ability to 'return' to the pattern being generated in the face of perturbations.}}, 
pages = {925--933}, 
number = {7}, 
volume = {16}, 
keywords = {}
}
@article{10.1038/s41598-022-14397-2, 
year = {2022}, 
title = {{Network structure from a characterization of interactions in complex systems}}, 
author = {Rings, Thorsten and Bröhl, Timo and Lehnertz, Klaus}, 
journal = {Scientific Reports}, 
doi = {10.1038/s41598-022-14397-2}, 
pmid = {35817803}, 
pmcid = {PMC9273794}, 
abstract = {{Many natural and man-made complex dynamical systems can be represented by networks with vertices representing system units and edges the coupling between vertices. If edges of such a structural network are inaccessible, a widely used approach is to identify them with interactions between vertices, thereby setting up a functional network. However, it is an unsolved issue if and to what extent important properties of a functional network on the global and the local scale match those of the corresponding structural network. We address this issue by deriving functional networks from characterizing interactions in paradigmatic oscillator networks with widely-used time-series-analysis techniques for various factors that alter the collective network dynamics. Surprisingly, we find that particularly key constituents of functional networks—as identified with betweenness and eigenvector centrality—coincide with ground truth to a high degree, while global topological and spectral properties—clustering coefficient, average shortest path length, assortativity, and synchronizability—clearly deviate. We obtain similar concurrences for an empirical network. Our findings are of relevance for various scientific fields and call for conceptual and methodological refinements to further our understanding of the relationship between structure and function of complex dynamical systems.}}, 
pages = {11742}, 
number = {1}, 
volume = {12}, 
keywords = {}
}
@article{boettiger2013early, 
year = {2013}, 
title = {{Early warning signals: the charted and uncharted territories}}, 
author = {Boettiger, Carl and Ross, Noam and Hastings, Alan}, 
journal = {Theoretical Ecology}, 
issn = {1874-1738}, 
doi = {10.1007/s12080-013-0192-6}, 
eprint = {1305.6700}, 
abstract = {{The realization that complex systems such as ecological communities can collapse or shift regimes suddenly and without rapid external forcing poses a serious challenge to our understanding and management of the natural world. The potential to identify early warning signals that would allow researchers and managers to predict such events before they happen has therefore been an invaluable discovery that offers a way forward in spite of such seemingly unpredictable behavior. Research into early warning signals has demonstrated that it is possible to define and detect such early warning signals in advance of a transition in certain contexts. Here, we describe the pattern emerging as research continues to explore just how far we can generalize these results. A core of examples emerges that shares three properties: the phenomenon of rapid regime shifts, a pattern of “critical slowing down” that can be used to detect the approaching shift, and a mechanism of bifurcation driving the sudden change. As research has expanded beyond these core examples, it is becoming clear that not all systems that show regime shifts exhibit critical slowing down, or vice versa. Even when systems exhibit critical slowing down, statistical detection is a challenge. We review the literature that explores these edge cases and highlight the need for (a) new early warning behaviors that can be used in cases where rapid shifts do not exhibit critical slowing down; (b) the development of methods to identify which behavior might be an appropriate signal when encountering a novel system, bearing in mind that a positive indication for some systems is a negative indication in others; and (c) statistical methods that can distinguish between signatures of early warning behaviors and noise.}}, 
pages = {255--264}, 
number = {3}, 
volume = {6}, 
keywords = {}
}
@article{10.1038/s41567-023-02020-8, 
year = {2023}, 
title = {{Emergent stability in complex network dynamics}}, 
author = {Meena, Chandrakala and Hens, Chittaranjan and Acharyya, Suman and Haber, Simcha and Boccaletti, Stefano and Barzel, Baruch}, 
journal = {Nature Physics}, 
issn = {1745-2473}, 
doi = {10.1038/s41567-023-02020-8}, 
eprint = {2007.04890}, 
abstract = {{The stable functionality of networked systems is a hallmark of their natural ability to coordinate between their multiple interacting components. Yet, real-world networks often appear random and highly irregular, raising the question of what are the naturally emerging organizing principles of complex system stability. The answer is encoded within the system’s stability matrix—the Jacobian—but is hard to retrieve, due to the scale and diversity of the relevant systems, their broad parameter space and their nonlinear interaction dynamics. Here we introduce the dynamic Jacobian ensemble, which allows us to systematically investigate the fixed-point dynamics of a range of relevant network-based models. Within this ensemble, we find that complex systems exhibit discrete stability classes. These range from asymptotically unstable (where stability is unattainable) to sensitive (where stability abides within a bounded range of system parameters). Alongside these two classes, we uncover a third asymptotically stable class in which a sufficiently large and heterogeneous network acquires a guaranteed stability, independent of its microscopic parameters and robust against external perturbation. Hence, in this ensemble, two of the most ubiquitous characteristics of real-world networks—scale and heterogeneity—emerge as natural organizing principles to ensure fixed-point stability in the face of changing environmental conditions. Despite looking highly irregular, most real-world networks exhibit natural stability to external perturbations. A study of the properties of the stability matrix of networks now sheds light on the principles underlying this emerging stability.}}, 
pages = {1033--1042}, 
number = {7}, 
volume = {19}, 
keywords = {}
}
@article{rings2019traceability, 
year = {2019}, 
title = {{Traceability and dynamical resistance of precursor of extreme events}}, 
author = {Rings, Thorsten and Mazarei, Mahmood and Akhshi, Amin and Geier, Christian and Tabar, M. Reza Rahimi and Lehnertz, Klaus}, 
journal = {Scientific Reports}, 
doi = {10.1038/s41598-018-38372-y}, 
pmid = {30741977}, 
pmcid = {PMC6370838}, 
abstract = {{Extreme events occur in a variety of natural, technical, and societal systems and often have catastrophic consequences. Their low-probability, high-impact nature has recently triggered research into improving our understanding of generating mechanisms, providing early warnings as well as developing control strategies. For the latter to be effective, knowledge about dynamical resistance of a system prior to an extreme event is of utmost importance. Here we introduce a novel time-series-based and non-perturbative approach to efficiently monitor dynamical resistance and apply it to high-resolution observations of brain activities from 43 subjects with uncontrollable epileptic seizures. We gain surprising insights into pre-seizure dynamical resistance of brains that also provide important clues for success or failure of measures for seizure prevention. The novel resistance monitoring perspective advances our understanding of precursor dynamics in complex spatio-temporal systems with potential applications in refining control strategies.}}, 
pages = {1744}, 
number = {1}, 
volume = {9}, 
keywords = {}
}
@article{wilkat2019no, 
year = {2019}, 
title = {{No evidence for critical slowing down prior to human epileptic seizures}}, 
author = {Wilkat, Theresa and Rings, Thorsten and Lehnertz, Klaus}, 
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science}, 
issn = {1054-1500}, 
doi = {10.1063/1.5122759}, 
pmid = {31575122}, 
eprint = {1908.08973}, 
abstract = {{There is an ongoing debate whether generic early warning signals for critical transitions exist that can be applied across diverse systems. The human epileptic brain is often considered as a prototypical system, given the devastating and, at times, even life-threatening nature of the extreme event epileptic seizure. More than three decades of international effort has successfully identified predictors of imminent seizures. However, the suitability of typically applied early warning indicators for critical slowing down, namely, variance and lag-1 autocorrelation, for indexing seizure susceptibility is still controversially discussed. Here, we investigated long-term, multichannel recordings of brain dynamics from 28 subjects with epilepsy. Using a surrogate-based evaluation procedure of sensitivity and specificity of time-resolved estimates of early warning indicators, we found no evidence for critical slowing down prior to 105 epileptic seizures.}}, 
pages = {091104}, 
number = {9}, 
volume = {29}, 
keywords = {}
}
@article{froyland2018robust, 
year = {2018}, 
title = {{Robust FEM-Based Extraction of Finite-Time Coherent Sets Using Scattered, Sparse, and Incomplete Trajectories}}, 
author = {Froyland, Gary and Junge, Oliver}, 
journal = {SIAM Journal on Applied Dynamical Systems}, 
doi = {10.1137/17m1129738}, 
pages = {1891--1924}, 
number = {2}, 
volume = {17}, 
keywords = {}
}
@article{hildegard2023heteroclinic, 
year = {2023}, 
title = {{Heteroclinic networks for brain dynamics}}, 
author = {Meyer-Ortmanns, Hildegard}, 
journal = {Frontiers in Network Physiology}, 
doi = {10.3389/fnetp.2023.1276401}, 
pmid = {38020242}, 
pmcid = {PMC10663269}, 
abstract = {{Heteroclinic networks are a mathematical concept in dynamic systems theory that is suited to describe metastable states and switching events in brain dynamics. The framework is sensitive to external input and, at the same time, reproducible and robust against perturbations. Solutions of the corresponding differential equations are spatiotemporal patterns that are supposed to encode information both in space and time coordinates. We focus on the concept of winnerless competition as realized in generalized Lotka–Volterra equations and report on results for binding and chunking dynamics, synchronization on spatial grids, and entrainment to heteroclinic motion. We summarize proposals of how to design heteroclinic networks as desired in view of reproducing experimental observations from neuronal networks and discuss the subtle role of noise. The review is on a phenomenological level with possible applications to brain dynamics, while we refer to the literature for a rigorous mathematical treatment. We conclude with promising perspectives for future research.}}, 
pages = {1276401}, 
volume = {3}, 
keywords = {}
}
@article{aravind2023on, 
year = {2023}, 
title = {{On relaxation times of heteroclinic dynamics}}, 
author = {Aravind, Manaoj and Meyer-Ortmanns, Hildegard}, 
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science}, 
issn = {1054-1500}, 
doi = {10.1063/5.0166803}, 
pmid = {37903407}, 
abstract = {{Heteroclinic dynamics provide a suitable framework for describing transient dynamics such as cognitive processes in the brain. It is appreciated for being well reproducible and at the same time highly sensitive to external input. It is supposed to capture features of switching statistics between metastable states in the brain. Beyond the high sensitivity, a further desirable feature of these dynamics is to enable a fast adaptation to new external input. In view of this, we analyze relaxation times of heteroclinic motion toward a new resting state, when oscillations in heteroclinic networks are arrested by a quench of a bifurcation parameter from a parameter regime of oscillations to a regime of equilibrium states. As it turns out, the relaxation is underdamped and depends on the nesting of the attractor space, the size of the attractor’s basin of attraction, the depth of the quench, and the level of noise. In the case of coupled heteroclinic units, it depends on the coupling strength, the coupling type, and synchronization between different units. Depending on how these factors are combined, finite relaxation times may support or impede a fast switching to new external input. Our results also shed some light on the discussion of how the stability of a system changes with its complexity.}}, 
pages = {103138}, 
number = {10}, 
volume = {33}, 
keywords = {}
}
@article{koch2023beyond, 
year = {2023}, 
title = {{Beyond fixed points: transient quasi-stable dynamics emerging from ghost channels and ghost cycles}}, 
author = {Koch, Daniel and Nandan, Akhilesh and Ramesan, Gayathri and Koseska, Aneta}, 
journal = {arXiv}, 
doi = {10.48550/arxiv.2309.17201}, 
eprint = {2309.17201}, 
abstract = {{Dynamical description of natural systems has generally focused on fixed points, with saddles and saddle-based phase space objects such as heteroclinic channels and heteroclinic cycles being central concepts behind the emergence of quasi-stable dynamics or long transients. Reliable and robust quasi-stable dynamics observed for real, inherently noisy systems is, however, not met by saddle-based dynamics, as demonstrated here. Generalizing the notion of ghost states, we provide a complementary framework for emergence of sequential quasi-stable dynamics that does not rely on (un)stable fixed points, but rather on slow directed flows on ghost manifolds from which ghost channels and ghost cycles are generated. Moreover, we show that these novel phase space objects are an emergent property of a broad class of models, typically used for description of natural systems.}}, 
keywords = {}
}
@article{john2022it, 
year = {2022}, 
title = {{It’s about time: Linking dynamical systems with human neuroimaging to understand the brain}}, 
author = {John, Yohan J. and Sawyer, Kayle S. and Srinivasan, Karthik and Müller, Eli J. and Munn, Brandon R. and Shine, James M.}, 
journal = {Network Neuroscience}, 
doi = {10.1162/netn\_a}, 
abstract = {{The study of dynamical systems offers a powerful framework for interpreting neuroimaging data from a range of different contexts, however, as a field, we have yet to fully embrace the power of this approach. Here, we offer a brief overview of some key terms from the dynamical systems literature, and then highlight three ways in which neuroimaging studies can begin to embrace the dynamical systems approach: by shifting from local to global descriptions of activity, by moving from static to dynamic analyses, and by transitioning from descriptive to generative models of neural activity patterns.}}, 
pages = {960--979}, 
number = {4}, 
volume = {6}, 
keywords = {}
}
@article{Fingelkurts.2006, 
year = {2006}, 
title = {{MAPPING OF BRAIN OPERATIONAL ARCHITECTONICS}}, 
author = {Fingelkurts, A. and Fingelkurts, A.}, 
journal = {undefined}, 
keywords = {}
}
@misc{Kelso.1995, 
author = {Kelso, Scott}, 
title = {{Dynamic Patterns | The MIT Press}}, 
url = {https://mitpress.mit.edu/books/dynamic-patterns}, 
abstract = {{foreword by Hermann Haken For the past twenty years Scott Kelso's research has focused on extending the physical concepts of self- organization and the mathematical tools of nonlinear dynamics to understand how human beings (and human brains) perceive, intend, learn, control, and coordinate complex behaviors. In this book Kelso proposes a new, general framework within which to connect brain, mind, and behavior.Kelso's prescription for mental life breaks dramatically with the classical computational approach that is still the operative framework for many newer psychological and neurophysiological studies. His core thesis is that the creation and evolution of patterned behavior at all levels—from neurons to mind—is governed by the generic processes of self-organization. Both human brain and behavior are shown to exhibit features of pattern-forming dynamical systems, including multistability, abrupt phase transitions, crises, and intermittency.Dynamic Patterns brings together different aspects of this approach to the study of human behavior, using simple experimental examples and illustrations to convey essential concepts, strategies, and methods, with a minimum of mathematics.Kelso begins with a general account of dynamic pattern formation. He then takes up behavior, focusing initially on identifying pattern-forming instabilities in human sensorimotor coordination. Moving back and forth between theory and experiment, he establishes the notion that the same pattern-forming mechanisms apply regardless of the component parts involved (parts of the body, parts of the nervous system, parts of society) and the medium through which the parts are coupled. Finally, employing the latest techniques to observe spatiotemporal patterns of brain activity, Kelso shows that the human brain is fundamentally a pattern forming dynamical system, poised on the brink of instability. Self-organization thus underlies the cooperative action of neurons that produces human behavior in all its forms.}}, 
urldate = {2021-05-19}, 
publisher = {The MIT Press}, 
language = {en}, 
note = {Publisher: The MIT Press}, 
keywords = {}
}
@article{beggs2003neuronal, 
year = {2003}, 
title = {{Neuronal avalanches in neocortical circuits}}, 
author = {Beggs, John M and Plenz, Dietmar}, 
journal = {Journal of neuroscience}, 
pages = {11167--11177}, 
number = {35}, 
volume = {23}, 
keywords = {}
}
@article{girardi2021brain, 
year = {2021}, 
title = {{Brain criticality beyond avalanches: open problems and how to approach them}}, 
author = {Girardi-Schappo, Mauricio}, 
journal = {Journal of Physics: Complexity}, 
pages = {031003}, 
number = {3}, 
volume = {2}, 
keywords = {}
}
@article{chialvo2010emergent, 
year = {2010}, 
title = {{Emergent complex neural dynamics}}, 
author = {Chialvo, Dante R}, 
journal = {Nature physics}, 
pages = {744--750}, 
number = {10}, 
volume = {6}, 
keywords = {}
}
@article{Kelso, 
title = {{TOWARD A COMPLEMENTARY NEUROSCIENCE: METASTABLE COORDINATION DYNAMICS OF THE BRAIN}}, 
author = {Kelso, J A Scott and Tognoli, Emmanuelle}, 
abstract = {{Metastability has been proposed as a new principle of behavioral and brain function and may point the way to a truly complementary neuroscience. From elementary coordination dynamics we show explicitly that metastability is a result of a symmetry breaking caused by the subtle interplay of two forces: the tendency of the components to couple together and the tendency of the components to express their intrinsic independent behavior. The metastable regime reconciles the well-known tendencies of specialized brain regions to express their autonomy (segregation) and the tendencies for those regions to work together as a synergy (integration). Integration \textbackslashtextasciitilde segregation is just one of the complementary pairs (denoted by the tilde (\textbackslashtextbackslashtextasciitilde) symbol) to emerge from the science of coordination dynamics. We discuss metastability in the brain by describing the favorable conditions existing for its emergence and by deriving some predictions for its empirical characterization in neurophysiological recordings.}}, 
pages = {23}, 
language = {en}, 
keywords = {}
}
@article{brinkman2022metastable, 
year = {2022}, 
title = {{Metastable dynamics of neural circuits and networks}}, 
author = {Brinkman, B. A. W. and Yan, H. and Maffei, A. and Park, I. M. and Fontanini, A. and Wang, J. and Camera, G. La}, 
journal = {Applied Physics Reviews}, 
issn = {1931-9401}, 
doi = {10.1063/5.0062603}, 
pmid = {35284030}, 
pmcid = {PMC8900181}, 
eprint = {2110.03025}, 
abstract = {{Cortical neurons emit seemingly erratic trains of action potentials or “spikes,” and neural network dynamics emerge from the coordinated spiking activity within neural circuits. These rich dynamics manifest themselves in a variety of patterns, which emerge spontaneously or in response to incoming activity produced by sensory inputs. In this Review, we focus on neural dynamics that is best understood as a sequence of repeated activations of a number of discrete hidden states. These transiently occupied states are termed “metastable” and have been linked to important sensory and cognitive functions. In the rodent gustatory cortex, for instance, metastable dynamics have been associated with stimulus coding, with states of expectation, and with decision making. In frontal, parietal, and motor areas of macaques, metastable activity has been related to behavioral performance, choice behavior, task difficulty, and attention. In this article, we review the experimental evidence for neural metastable dynamics together with theoretical approaches to the study of metastable activity in neural circuits. These approaches include (i) a theoretical framework based on non-equilibrium statistical physics for network dynamics; (ii) statistical approaches to extract information about metastable states from a variety of neural signals; and (iii) recent neural network approaches, informed by experimental results, to model the emergence of metastable dynamics. By discussing these topics, we aim to provide a cohesive view of how transitions between different states of activity may provide the neural underpinnings for essential functions such as perception, memory, expectation, or decision making, and more generally, how the study of metastable neural activity may advance our understanding of neural circuit function in health and disease.}}, 
pages = {011313}, 
number = {1}, 
volume = {9}, 
keywords = {}
}
@article{jacobs2023hypersindy, 
year = {2023}, 
title = {{HyperSINDy: Deep Generative Modeling of Nonlinear Stochastic Governing Equations}}, 
author = {Jacobs, Mozes and Brunton, Bingni W and Brunton, Steven L and Kutz, J Nathan and Raut, Ryan V}, 
journal = {arXiv}, 
doi = {10.48550/arxiv.2310.04832}, 
eprint = {2310.04832}, 
abstract = {{The discovery of governing differential equations from data is an open frontier in machine learning. The sparse identification of nonlinear dynamics (SINDy) \textbackslashcitep\{brunton\_discovering\_2016\} framework enables data-driven discovery of interpretable models in the form of sparse, deterministic governing laws. Recent works have sought to adapt this approach to the stochastic setting, though these adaptations are severely hampered by the curse of dimensionality. On the other hand, Bayesian-inspired deep learning methods have achieved widespread success in high-dimensional probabilistic modeling via computationally efficient approximate inference techniques, suggesting the use of these techniques for efficient stochastic equation discovery. Here, we introduce HyperSINDy, a framework for modeling stochastic dynamics via a deep generative model of sparse governing equations whose parametric form is discovered from data. HyperSINDy employs a variational encoder to approximate the distribution of observed states and derivatives. A hypernetwork \textbackslashcitep\{ha\_hypernetworks\_2016\} transforms samples from this distribution into the coefficients of a differential equation whose sparse form is learned simultaneously using a trainable binary mask \textbackslashcitep\{louizos\_learning\_2018\}. Once trained, HyperSINDy generates stochastic dynamics via a differential equation whose coefficients are driven by a Gaussian white noise. In experiments, HyperSINDy accurately recovers ground truth stochastic governing equations, with learned stochasticity scaling to match that of the data. Finally, HyperSINDy provides uncertainty quantification that scales to high-dimensional systems. Taken together, HyperSINDy offers a promising framework for model discovery and uncertainty quantification in real-world systems, integrating sparse equation discovery methods with advances in statistical machine learning and deep generative modeling.}}, 
keywords = {}
}
@article{sussillo2013opening, 
year = {2013}, 
title = {{Opening the Black Box: Low-Dimensional Dynamics in High-Dimensional Recurrent Neural Networks}}, 
author = {Sussillo, David and Barak, Omri}, 
journal = {Neural Computation}, 
issn = {0899-7667}, 
doi = {10.1162/neco\_a\_00409}, 
pmid = {23272922}, 
abstract = {{Recurrent neural networks (RNNs) are useful tools for learning nonlinear relationships between time-varying inputs and outputs with complex temporal dependencies. Recently developed algorithms have been successful at training RNNs to perform a wide variety of tasks, but the resulting networks have been treated as black boxes: their mechanism of operation remains unknown. Here we explore the hypothesis that fixed points, both stable and unstable, and the linearized dynamics around them, can reveal crucial aspects of how RNNs implement their computations. Further, we explore the utility of linearization in areas of phase space that are not true fixed points but merely points of very slow movement. We present a simple optimization technique that is applied to trained RNNs to find the fixed and slow points of their dynamics. Linearization around these slow regions can be used to explore, or reverse-engineer, the behavior of the RNN. We describe the technique, illustrate it using simple examples, and finally showcase it on three high-dimensional RNN examples: a 3-bit flip-flop device, an input-dependent sine wave generator, and a two-point moving average. In all cases, the mechanisms of trained networks could be inferred from the sets of fixed and slow points and the linearized dynamics around them.}}, 
pages = {626--649}, 
number = {3}, 
volume = {25}, 
keywords = {}
}
@article{contreras2023scale, 
year = {2023}, 
title = {{Scale-free avalanches in arrays of FitzHugh–Nagumo oscillators}}, 
author = {Contreras, Max and Medeiros, Everton S. and Zakharova, Anna and Hövel, Philipp and Franović, Igor}, 
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science}, 
issn = {1054-1500}, 
doi = {10.1063/5.0165778}, 
pmid = {37671990}, 
abstract = {{The activity in the brain cortex remarkably shows a simultaneous presence of robust collective oscillations and neuronal avalanches, where intermittent bursts of pseudo-synchronous spiking are interspersed with long periods of quiescence. The mechanisms allowing for such coexistence are still a matter of an intensive debate. Here, we demonstrate that avalanche activity patterns can emerge in a rather simple model of an array of diffusively coupled neural oscillators with multiple timescale local dynamics in the vicinity of a canard transition. The avalanches coexist with the fully synchronous state where the units perform relaxation oscillations. We show that the mechanism behind the avalanches is based on an inhibitory effect of interactions, which may quench the spiking of units due to an interplay with the maximal canard. The avalanche activity bears certain heralds of criticality, including scale-invariant distributions of event sizes. Furthermore, the system shows increased sensitivity to perturbations, manifested as critical slowing down and reduced resilience.}}, 
pages = {093106}, 
number = {9}, 
volume = {33}, 
keywords = {}
}
@article{budzinski2023an, 
year = {2023}, 
title = {{An exact mathematical description of computation with transient spatiotemporal dynamics in a complex-valued neural network}}, 
author = {Budzinski, Roberto C and Busch, Alexandra N and Mestern, Samuel and Martin, Erwan and Liboni, Luisa H B and Pasini, Federico W and Mináč, Ján and Coleman, Todd and Inoue, Wataru and Muller, Lyle E}, 
journal = {arXiv}, 
doi = {10.48550/arxiv.2311.16431}, 
eprint = {2311.16431}, 
abstract = {{We study a complex-valued neural network (cv-NN) with linear, time-delayed interactions. We report the cv-NN displays sophisticated spatiotemporal dynamics, including partially synchronized ``chimera'' states. We then use these spatiotemporal dynamics, in combination with a nonlinear readout, for computation. The cv-NN can instantiate dynamics-based logic gates, encode short-term memories, and mediate secure message passing through a combination of interactions and time delays. The computations in this system can be fully described in an exact, closed-form mathematical expression. Finally, using direct intracellular recordings of neurons in slices from neocortex, we demonstrate that computations in the cv-NN are decodable by living biological neurons. These results demonstrate that complex-valued linear systems can perform sophisticated computations, while also being exactly solvable. Taken together, these results open future avenues for design of highly adaptable, bio-hybrid computing systems that can interface seamlessly with other neural networks.}}, 
keywords = {}
}
@article{liboni2023image, 
year = {2023}, 
title = {{Image segmentation with traveling waves in an exactly solvable recurrent neural network}}, 
author = {Liboni, Luisa H B and Budzinski, Roberto C and Busch, Alexandra N and Löwe, Sindy and Keller, Thomas A and Welling, Max and Muller, Lyle E}, 
journal = {arXiv}, 
doi = {10.48550/arxiv.2311.16943}, 
eprint = {2311.16943}, 
abstract = {{We study image segmentation using spatiotemporal dynamics in a recurrent neural network where the state of each unit is given by a complex number. We show that this network generates sophisticated spatiotemporal dynamics that can effectively divide an image into groups according to a scene's structural characteristics. Using an exact solution of the recurrent network's dynamics, we present a precise description of the mechanism underlying object segmentation in this network, providing a clear mathematical interpretation of how the network performs this task. We then demonstrate a simple algorithm for object segmentation that generalizes across inputs ranging from simple geometric objects in grayscale images to natural images. Object segmentation across all images is accomplished with one recurrent neural network that has a single, fixed set of weights. This demonstrates the expressive potential of recurrent neural networks when constructed using a mathematical approach that brings together their structure, dynamics, and computation.}}, 
keywords = {}
}
@article{grebogi1987critical, 
year = {1987}, 
title = {{Critical exponents for crisis-induced intermittency}}, 
author = {Grebogi, Celso and Ott, Edward and Romeiras, Filipe and Yorke, James A.}, 
journal = {Physical Review A}, 
issn = {1050-2947}, 
doi = {10.1103/physreva.36.5365}, 
pmid = {9898807}, 
abstract = {{We consider three types of changes that attractors can undergo as a system parameter is varied. The first type leads to the sudden destruction of a chaotic attractor. The second type leads to the sudden widening of a chaotic attractor. In the third type of change, which applies for many systems with symmetries, two (or more) chaotic attractors merge to form a single chaotic attractor and the merged attractor can be larger in phase-space extent than the union of the attractors before the change. All three of these types of changes are termed crises and are accompanied by a characteristic temporal behavior of orbits after the crisis. For the case where the chaotic attractor is destroyed, this characteristic behavior is the existence of chaotic transients. For the case where the chaotic attractor suddenly widens, the characteristic behavior is an intermittent bursting out of the phase-space region within which the attractor was confined before the crisis. For the case where the attractors suddenly merge, the characteristic behavior is an intermittent switching between behaviors characteristic of the attractors before merging. In all cases a time scale τ can be defined which quantifies the observed post-crisis behavior: for attractor destruction, τ is the average chaotic transient lifetime; for intermittent bursting, it is the mean time between bursts; for intermittent switching, it is the mean time between switches. The purpose of this paper is to examine the dependence of τ on a system parameter (call it p) as this parameter passes through its crisis value p=pc. Our main result is that for an important class of systems the dependence of τ on p is τ∼‖p-pc‖-γ for p close to pc, and we develop a quantitative theory for the determination of the critical exponent γ. Illustrative numerical examples are given. In addition, applications to experimental situations, as well as generalizations to higher-dimensional cases, are discussed. Since the case of attractor destruction followed by chaotic transients has previously been illustrated with examples [C. Grebogi, E. Ott, and J. A. Yorke, Phys. Rev. Lett. 57, 1284 (1986)], the numerical experiments reported in this paper will be for crisis-induced intermittency (i.e., intermittent bursting and switching).}}, 
pages = {5365--5380}, 
number = {11}, 
volume = {36}, 
keywords = {}
}
@article{ullner2007multistability, 
year = {2007}, 
title = {{Multistability and Clustering in a Population of Synthetic Genetic Oscillators via Phase-Repulsive Cell-to-Cell Communication}}, 
author = {Ullner, Ekkehard and Zaikin, Alexei and Volkov, Evgenii I. and García-Ojalvo, Jordi}, 
journal = {Physical Review Letters}, 
issn = {0031-9007}, 
doi = {10.1103/physrevlett.99.148103}, 
pmid = {17930726}, 
abstract = {{We show that phase-repulsive coupling eliminates oscillations in a population of synthetic genetic clocks. For this, we propose an experimentally feasible synthetic genetic network that contains phase repulsively coupled repressilators with broken temporal symmetry. As the coupling strength increases, silencing of oscillations is found to occur via the appearance of an inhomogeneous limit cycle, followed by oscillation death. Two types of oscillation death are observed: For lower couplings, the cells cluster in one of two stationary states of protein expression; for larger couplings, all cells end up in a single (stationary) cellular state. Several multistable regimes are observed along this route to oscillation death.}}, 
pages = {148103}, 
number = {14}, 
volume = {99}, 
keywords = {}
}
@article{arecchi1985generalized, 
year = {1985}, 
title = {{Generalized multistability and noise-induced jumps in a nonlinear dynamical system}}, 
author = {Arecchi, F. T. and Badii, R. and Politi, A.}, 
journal = {Physical Review A}, 
issn = {1050-2947}, 
doi = {10.1103/physreva.32.402}, 
pmid = {9896062}, 
abstract = {{A study of the forced Duffing equation is reported, with particular reference to a region of the parameter space where five different attractors coexist. This coexistence, reported in some recent experiments, is called generalized multistability. The role of external noise in bridging the otherwise disjoint basins is explored. Noise-induced couplings are shown to be ruled by simple kinetic equations under a general assumption for the geometry of the boundaries. These kinetic equations yield low-frequency power spectra in qualitative agreement with the experimental results.}}, 
pages = {402--408}, 
number = {1}, 
volume = {32}, 
keywords = {}
}
@article{pisarchik2014control, 
year = {2014}, 
title = {{Control of multistability}}, 
author = {Pisarchik, Alexander N. and Feudel, Ulrike}, 
journal = {Physics Reports}, 
issn = {0370-1573}, 
pages = {167--218}, 
number = {4}, 
volume = {540}, 
keywords = {}
}
@article{10.1016/j.ecocom.2005.11.001, 
year = {2006}, 
title = {{Bloom dynamics in a seasonally forced phytoplankton–zooplankton model: Trigger mechanisms and timing effects}}, 
author = {Freund, Jan A. and Mieruch, Sebastian and Scholze, Bettina and Wiltshire, Karen and Feudel, Ulrike}, 
journal = {Ecological Complexity}, 
issn = {1476-945X}, 
doi = {10.1016/j.ecocom.2005.11.001}, 
abstract = {{With the aim of describing annually recurring phytoplankton blooms we discuss an extension of the phytoplankton–zooplankton model introduced by [Truscott, J.E., Brindley, J., 1994. Ocean plankton populations as excitable media. Bull. Math. Biol. 56, 981–998]. The extension is a seasonal forcing of the phytoplankton growth rate driven by an oscillating temperature via a Q10 law. We observe bistable long-term behaviour of the ecological system, i.e. a bloom and non-bloom mode, the importance of timing, and noise-induced switchings between the bloom and non-bloom mode. We link the model results to existing Helgoland Roads long-term data series by analysing the latter using the novel method of bloom-triggered averaging, a tool borrowed from signal analysis of neurophysiological recordings. We find that on an average blooms are correlated with rapid upward temperature fluctuations and speculate on their possible role as trigger mechanisms.}}, 
pages = {129--139}, 
number = {2}, 
volume = {3}, 
keywords = {}
}
@article{10.1016/j.ecocom.2014.10.003, 
year = {2014}, 
title = {{Plankton blooms and patchiness generated by heterogeneous physical environments}}, 
author = {Bengfort, Michael and Feudel, Ulrike and Hilker, Frank M. and Malchow, Horst}, 
journal = {Ecological Complexity}, 
issn = {1476-945X}, 
doi = {10.1016/j.ecocom.2014.10.003}, 
abstract = {{Microscopic turbulent motions of water have been shown to influence the dynamics of microscopic species living in that habitat. The number, stability, and excitability of stationary states in a predator–prey model of plankton species can therefore change when the strength of turbulent motions varies. In a spatial system these microscopic turbulent motions are naturally of different strength and form a heterogeneous physical environment. Spatially neighboring plankton communities with different physical conditions can impact each other due to diffusive coupling. We show that local variations in the physical conditions can influence the global system in form of propagating pulses of high population densities. For this we consider three different local predator–prey models with different local responses to variations in the physical environment. The degree of spatial heterogeneity can, depending on the model, promote or reduce the number of propagating pulses, which can be interpreted as patchy plankton distributions and recurrent blooms.}}, 
pages = {185--194}, 
volume = {20}, 
keywords = {}
}
@article{undefined, 
title = {{HOMOCLINIC BIFURCATIONS}}, 
keywords = {}
}
@article{undefined, 
title = {{homoclinic-fowler-ndim.pdf}}, 
keywords = {}
}
@article{10.1016/s1874-575x(10)00316-4, 
year = {2010}, 
title = {{Chapter 8 Homoclinic and Heteroclinic Bifurcations in Vector Fields}}, 
author = {Homburg, Ale Jan and Sandstede, Björn}, 
journal = {Handbook of Dynamical Systems}, 
issn = {1874-575X}, 
doi = {10.1016/s1874-575x(10)00316-4}, 
pages = {379--524}, 
volume = {3}, 
keywords = {}
}
@article{10.1038/ncomms8709, 
year = {2015}, 
title = {{Restoration of rhythmicity in diffusively coupled dynamical networks}}, 
author = {Zou, Wei and Senthilkumar, D. V. and Nagao, Raphael and Kiss, István Z. and Tang, Yang and Koseska, Aneta and Duan, Jinqiao and Kurths, Jürgen}, 
journal = {Nature Communications}, 
doi = {10.1038/ncomms8709}, 
pmid = {26173555}, 
pmcid = {PMC4518287}, 
abstract = {{Oscillatory behaviour is essential for proper functioning of various physical and biological processes. However, diffusive coupling is capable of suppressing intrinsic oscillations due to the manifestation of the phenomena of amplitude and oscillation deaths. Here we present a scheme to revoke these quenching states in diffusively coupled dynamical networks, and demonstrate the approach in experiments with an oscillatory chemical reaction. By introducing a simple feedback factor in the diffusive coupling, we show that the stable (in)homogeneous steady states can be effectively destabilized to restore dynamic behaviours of coupled systems. Even a feeble deviation from the normal diffusive coupling drastically shrinks the death regions in the parameter space. The generality of our method is corroborated in diverse non-linear systems of diffusively coupled paradigmatic models with various death scenarios. Our study provides a general framework to strengthen the robustness of dynamic activity in diffusively coupled dynamical networks. Oscillatory behaviour is essential for proper functioning of several processes, yet quenching phenomena can lead to steady states with suppressed oscillations. Here the authors present a scheme to revoke these states in diffusively coupled networks, and demonstrate their approach on a chemical oscillator.}}, 
pages = {7709}, 
number = {1}, 
volume = {6}, 
keywords = {}
}
@article{ullner2008multistability, 
year = {2008}, 
title = {{Multistability of synthetic genetic networks with repressive cell-to-cell communication}}, 
author = {Ullner, Ekkehard and Koseska, Aneta and Kurths, Jürgen and Volkov, Evgenii and Kantz, Holger and García-Ojalvo, Jordi}, 
journal = {Physical Review E}, 
issn = {1539-3755}, 
doi = {10.1103/physreve.78.031904}, 
pmid = {18851062}, 
abstract = {{We investigate an experimentally feasible synthetic genetic network consisting of two phase repulsively coupled repressilators, which evokes multiple coexisting stable attractors with different features. We perform a bifurcation analysis to determine and classify the dynamical structure of the system. Moreover, some of the dynamical regimes found, such as inhomogeneous steady states and inhomogeneous limit cycles can further be associated with artificial cell differentiation. We also report and characterize the emergence of chaotic dynamics resulting from the intercell coupling.}}, 
pages = {031904}, 
number = {3}, 
volume = {78}, 
keywords = {}
}
@article{koseska2013oscillation, 
year = {2013}, 
title = {{Oscillation quenching mechanisms: Amplitude vs. oscillation death}}, 
author = {Koseska, Aneta and Volkov, Evgeny and Kurths, Jürgen}, 
journal = {Physics Reports}, 
issn = {0370-1573}, 
doi = {10.1016/j.physrep.2013.06.001}, 
abstract = {{Oscillation quenching constitutes a fundamental emergent phenomenon in systems of coupled nonlinear oscillators. Its importance for various natural and man-made systems, ranging from climate, lasers, chemistry and a wide range of biological oscillators can be projected from two main aspects: (i) suppression of oscillations as a regulator of certain pathological cases and (ii) a general control mechanism for technical systems. We distinguish two structurally distinct oscillation quenching types: oscillation (OD) and amplitude death (AD) phenomena. In this review we aim to set clear boundaries between these two very different oscillation quenching manifestations and demonstrate the importance for their correct identification from the aspect of theory as well as of applications. Moreover, we pay special attention to the physiological interpretation of OD and AD in a large class of biological systems, further underlying their different properties. Several open issues and challenges that await further resolving are also highlighted.}}, 
pages = {173--199}, 
number = {4}, 
volume = {531}, 
keywords = {}
}
@article{yanagita2005pair, 
year = {2005}, 
title = {{Pair of excitable FitzHugh-Nagumo elements: Synchronization, multistability, and chaos}}, 
author = {Yanagita, T. and Ichinomiya, T. and Oyama, Y.}, 
journal = {Physical Review E}, 
issn = {1539-3755}, 
doi = {10.1103/physreve.72.056218}, 
pmid = {16383738}, 
abstract = {{We analyze a pair of excitable FitzHugh-Nagumo elements, each of which is coupled repulsively. While the rest state for each element is globally stable for a phase-attractive coupling, various firing patterns, including cyclic and chaotic firing patterns, exist in an phase-repulsive coupling region. Although the rest state becomes linearly unstable via a Hopf bifurcation, periodic solutions associated to the firing patterns is not connected to the Hopf bifurcation. This means that the solution branch emanating from the Hopf bifurcation is subcritical and unstable for any coupling strength. Various types of cyclic firing patterns emerge suddenly through saddle-node bifurcations. The parameter region in which different periodic solutions coexist is also found.}}, 
pages = {056218}, 
number = {5}, 
volume = {72}, 
keywords = {}
}
@article{tyson1975control, 
year = {1975}, 
title = {{Control of mitosis by a continuous biochemical oscillation: Synchronization; spatially inhomogeneous oscillations}}, 
author = {Tyson, J. and Kauffman, S.}, 
journal = {Journal of Mathematical Biology}, 
issn = {0303-6812}, 
doi = {10.1007/bf00279848}, 
abstract = {{Assuming continuous biochemical control of the mitotic cycle in the acellular slime mold Physarum polycephalum the authors model the results of phase synchronization experiments using a hypothetical chemical oscillator confined to two boxes coupled by diffusion through a semipermeable membrane. The oscillator chosen, which corresponds closely to a division protein or mitogen model proposed by others, is well defined mathematically so that detailed calculations can be performed. The modeling of phase synchronization and heat shock experiments is successful, and the system also admits inhomogeneous limit cycle oscillations which are of interest both theoretically and biologically.}}, 
pages = {289--310}, 
number = {4}, 
volume = {1}, 
keywords = {}
}
@article{schulen2022solitary, 
year = {2022}, 
title = {{Solitary states in complex networks: impact of topology}}, 
author = {Schülen, Leonhard and Mikhailenko, Maria and Medeiros, Everton S. and Zakharova, Anna}, 
journal = {The European Physical Journal Special Topics}, 
issn = {1951-6355}, 
doi = {10.1140/epjs/s11734-022-00713-4}, 
eprint = {2208.14911}, 
abstract = {{The dynamical behavior of networked systems is expected to reflect the properties of their coupling structure. Yet, symmetry-broken solutions often occur in symmetrically coupled networks. An example are so-called solitary states where the dynamics of one network node is different from the synchronized rest. Here, we investigate the structural constraints of networks for the appearance of solitary states. By performing a large number of numerical simulations, we find that such states occur with high probability in asymmetric networks, among them scale-free ones. We analyze the structural properties of the networks that support solitary states. We demonstrate that the minimum neighbor node degree of a solitary node is crucial for the appearance of solitary states. Finally, we perform bifurcation analysis of dimension-reduced systems, which confirm the importance of the connectivity of the neighboring nodes.}}, 
pages = {4123--4130}, 
number = {22-23}, 
volume = {231}, 
keywords = {}
}
@book{ermentrout2002simulating, 
year = {2002}, 
title = {{Simulating, Analyzing, and Animating Dynamical Systems}}, 
author = {Ermentrout, Bard}, 
url = {https://epubs.siam.org/doi/abs/10.1137/1.9780898718195}, 
publisher = {Society for Industrial and Applied Mathematics}, 
keywords = {}, 
doi = {10.1137/1.9780898718195}
}
@article{mehrabbeik2023synchronization, 
year = {2023}, 
title = {{Synchronization and multistability in a network of diffusively coupled laser models}}, 
author = {Mehrabbeik, Mahtab and Jafari, Sajad and Meucci, Riccardo and Perc, Matjaž}, 
journal = {Communications in Nonlinear Science and Numerical Simulation}, 
issn = {1007-5704}, 
doi = {10.1016/j.cnsns.2023.107380}, 
abstract = {{Synchronization phenomena refer to the emergence of common temporal patterns among clusters of interacting units in a complex network. In information transmission, lasers’ synchronization plays a key role in facilitating information communication. This paper is devoted to studying the synchronization of globally coupled identical laser models via the linear and nonlinear forms of diffusive couplings. In this regard, the master stability function and time-averaged synchronization error are employed as the analytical and numerical approaches to examine complete synchronization. Apart from the complete synchrony, the constructed networks are explored to find other synchronization patterns and multistability. The results obtained from the master stability function analysis, which are further approved by the numerical outcomes, show that when coupled through the linear diffusive function, the interacting laser models achieve complete synchrony in a small value of the coupling parameter. However, in the nonlinear case, complete synchronization cannot be attained. Moreover, multistability can be observed in different network states, including cluster synchronization, chimera, and solitary states.}}, 
pages = {107380}, 
volume = {125}, 
keywords = {}
}
@article{10.1016/j.physa.2023.128750, 
year = {2023}, 
title = {{Dependence on the local dynamics of a network phase synchronization process}}, 
author = {Cambraia, E.B.S.A. and Flauzino, J.V.V. and Prado, T.L. and Lopes, S.R.}, 
journal = {Physica A: Statistical Mechanics and its Applications}, 
issn = {0378-4371}, 
doi = {10.1016/j.physa.2023.128750}, 
abstract = {{Partial phase synchronization, also reported as neuron cooperation, is a pivotal behavior of the brain and related to its main features, such as memory. The excess or even the lack of phase synchronization are associated with brain disorders like epilepsy and Parkinson’s disease. These diseases may be related to malfunctioning of the synchronization process of the neurons, triggered by changes of the local dynamics of the neurons influenced by parameters such as the ion-channel conductance. In fact, it is common to change the local neuron dynamics, using drugs to block or activate specific channels, changing the conductance and bringing the synchronization process to some desired behavior. Here we show that there are two distinct mechanisms leading to network phase synchronized states. The first one is strongly affected by the individual neuron dynamics. In this case, the synchronous state of the network may occur for low values of the coupling, regardless of the network topology. The second synchronized state is induced by the network coupling, in this case the network coupling strength promotes synchronized global states, we say it is a network driver synchronization. We report here how individual characteristics of the local dynamics of the neurons, such as their linear stability, when coupled in a network may be a fundamental player in the phase synchronization process as a function of the coupling strength. Global and small-world topologies are considered for a Hindmarsh–Rose-neuron network. For both coupling schemes, the effects of the local dynamics are clear, inducing early or retarding the occurrence of partial phase synchronization of the network when the coupling strength is varied. In this scenario, we discuss the effect of the local dynamics of the neuron, showing it may be of fundamental importance to understand and control the process of the network phase synchronization. The study also brings useful information to the general understanding of network-phase-synchronization processes.}}, 
pages = {128750}, 
volume = {619}, 
keywords = {}
}
@article{mondal2021spatiotemporal, 
year = {2021}, 
title = {{Spatiotemporal characteristics in systems of diffusively coupled excitable slow–fast FitzHugh–Rinzel dynamical neurons}}, 
author = {Mondal, Arnab and Mondal, Argha and Sharma, Sanjeev Kumar and Upadhyay, Ranjit Kumar and Antonopoulos, Chris G.}, 
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science}, 
issn = {1054-1500}, 
doi = {10.1063/5.0055389}, 
pmid = {34717324}, 
eprint = {2110.01122}, 
abstract = {{In this paper, we study an excitable, biophysical system that supports wave propagation of nerve impulses. We consider a slow–fast, FitzHugh–Rinzel neuron model where only the membrane voltage interacts diffusively, giving rise to the formation of spatiotemporal patterns. We focus on local, nonlinear excitations and diverse neural responses in an excitable one- and two-dimensional configuration of diffusively coupled FitzHugh–Rinzel neurons. The study of the emerging spatiotemporal patterns is essential in understanding the working mechanism in different brain areas. We derive analytically the coefficients of the amplitude equations in the vicinity of Hopf bifurcations and characterize various patterns, including spirals exhibiting complex geometric substructures. Furthermore, we derive analytically the condition for the development of antispirals in the neighborhood of the bifurcation point. The emergence of broken target waves can be observed to form spiral-like profiles. The spatial dynamics of the excitable system exhibits two- and multi-arm spirals for small diffusive couplings. Our results reveal a multitude of neural excitabilities and possible conditions for the emergence of spiral-wave formation. Finally, we show that the coupled excitable systems with different firing characteristics participate in a collective behavior that may contribute significantly to irregular neural dynamics.}}, 
pages = {103122}, 
number = {10}, 
volume = {31}, 
keywords = {}
}
@article{crowley1989experimental, 
year = {1989}, 
title = {{Experimental and theoretical studies of a coupled chemical oscillator: phase death, multistability and in-phase and out-of-phase entrainment}}, 
author = {Crowley, Michael F and Epstein, Irving R}, 
journal = {The Journal of Physical Chemistry}, 
issn = {0022-3654}, 
doi = {10.1021/j100343a052}, 
pages = {2496--2502}, 
number = {6}, 
volume = {93}, 
keywords = {}
}
@article{aronson1987an, 
year = {1987}, 
title = {{An analytical and numerical study of the bifurcations in a system of linearly-coupled oscillators}}, 
author = {Aronson, D.G. and Doedel, E.J. and Othmer, H.G.}, 
journal = {Physica D: Nonlinear Phenomena}, 
issn = {0167-2789}, 
doi = {10.1016/0167-2789(87)90095-9}, 
abstract = {{We study a two-parameter family of ordinary differential equations in R4 that governs the dynamics of two coupled planar oscillators. Each oscillator has a unique periodic solution that is attracting and the uncoupled product system has a unique invariant torus that is attracting. The torus persists for weak coupling and contains two periodic solutions when the coupling is linear and conservative. One of these, in which the oscillators are synchronized, persists and is stable for all coupling strengths. The other, in which the oscillators are π radiant out of phase, disappears either in a Hopf bifurcation or when fixed points appear on the orbit at a critical ratio of the coupling strength to the frequency. The out-of-phase oscillation is unstable except on an open set in the frequency-coupling-strength plane which contains moderate values of both parameters. Furthermore, there are tori bifurcating from the out-of-phase solution, which means, according to the Arnol'd theory for Hopf bifurcations in maps, that there may be periodic solutions of arbitrarily large period and chaotic solutions as well. Numerous other bifurcations occur, and there are a number of higher codimension singularities. In a large region of the frequency-coupling parameter plane stable steady states coexist with stable periodic solutions.}}, 
pages = {20--104}, 
number = {1-3}, 
volume = {25}, 
keywords = {}
}
@article{sporns1987chaotic, 
year = {1987}, 
title = {{Chaotic dynamics of two coupled biochemical oscillators}}, 
author = {Sporns, Olaf and Roth, Siegfried and Seelig, Friedrich Franz}, 
journal = {Physica D: Nonlinear Phenomena}, 
issn = {0167-2789}, 
doi = {10.1016/0167-2789(87)90226-0}, 
abstract = {{A two-variable/two-compartment model of enzyme-induction with regulated diffusion produces spatial chaos. In a bichaotic state two symmetrical attractors coexist, each with a constant polarity between the cells. Collision and overlap between the attractors forms a singular attractor which is characterized by an irregularly switching polarity, thereby producing apparently random sequences of time periods. The mean period length obeys a scaling law with the bifurcation parameter. Examination of next-amplitude maps using symbolic representation of the system evolution reveals the existence of a fractal “boundary” inside the attractor. A cubic map analogue of the differentiable system is studied in parallel. A scaling function for the uncertainty exponent of the fractal boundary in the cubic map is proposed.}}, 
pages = {215--224}, 
number = {1-3}, 
volume = {26}, 
keywords = {}
}
@article{wilson1972excitatory, 
year = {1972}, 
title = {{Excitatory and Inhibitory Interactions in Localized Populations of Model Neurons}}, 
author = {Wilson, Hugh R. and Cowan, Jack D.}, 
journal = {Biophysical Journal}, 
issn = {0006-3495}, 
doi = {10.1016/s0006-3495(72)86068-5}, 
pmid = {4332108}, 
pmcid = {PMC1484078}, 
abstract = {{Coupled nonlinear differential equations are derived for the dynamics of spatially localized populations containing both excitatory and inhibitory model neurons. Phase plane methods and numerical solutions are then used to investigate population responses to various types of stimuli. The results obtained show simple and multiple hysteresis phenomena and limit cycle activity. The latter is particularly interesting since the frequency of the limit cycle oscillation is found to be a monotonic function of stimulus intensity. Finally, it is proved that the existence of limit cycle dynamics in response to one class of stimuli implies the existence of multiple stable states and hysteresis in response to a different class of stimuli. The relation between these findings and a number of experiments is discussed.}}, 
pages = {1--24}, 
number = {1}, 
volume = {12}, 
keywords = {}
}
@article{haugland2021the, 
year = {2021}, 
title = {{The changing notion of chimera states, a critical review}}, 
author = {Haugland, Sindre W}, 
journal = {Journal of Physics: Complexity}, 
doi = {10.1088/2632-072x/ac0810}, 
eprint = {2102.05515}, 
abstract = {{Chimera states, states of coexistence of synchronous and asynchronous motion, have been a subject of extensive research since they were first given a name in 2004. Increased interest has lead to their discovery in ever new settings, both theoretical and experimental. Less well-discussed is the fact that successive results have also broadened the notion of what actually constitutes a chimera state. In this article, we critically examine how the results for different model types and coupling schemes, as well as varying implicit interpretations of terms such as coexistence, synchrony and incoherence, have influenced the common understanding of what constitutes a chimera. We cover both theoretical and experimental systems, address various chimera-derived terms that have emerged over the years and finally reflect on the question of chimera states in real-world contexts.}}, 
pages = {032001}, 
number = {3}, 
volume = {2}, 
keywords = {}
}
@article{foss1996multistability, 
year = {1996}, 
title = {{Multistability and Delayed Recurrent Loops}}, 
author = {Foss, Jennifer and Longtin, André and Mensour, Boualem and Milton, John}, 
journal = {Physical Review Letters}, 
issn = {0031-9007}, 
doi = {10.1103/physrevlett.76.708}, 
pmid = {10061527}, 
abstract = {{Multistable dynamical systems have important applications as pattern recognition and memory storage devices. Conditions under which time-delayed recurrent loops of spiking neurons exhibit multistability are presented. Our results are illustrated on both a simple integrate-and-fire neuron and a Hodgkin-Huxley-type neuron, whose recurrent inputs are delayed versions of their output spike trains. Two kinds of multistability with respect to initial spiking functions are found, depending on whether the neuron is excitable or repetitively firing in the absence of feedback.}}, 
pages = {708--711}, 
number = {4}, 
volume = {76}, 
keywords = {}
}
@article{10.11606/t.55.2022.tde-02122022-085455, 
year = {2022}, 
title = {{Chaotic behaviour in diffusively coupled systems}}, 
author = {Queiroz, Fernando Cordeiro de}, 
doi = {10.11606/t.55.2022.tde-02122022-085455}, 
abstract = {{We study emergent oscillatory behaviour in networks of diffusively coupled nonlinear ordinary differential equations. Starting from a situation where the isolated dynamics at each node are the same and...}}, 
keywords = {}
}
@article{10.1007/978-1-4612-6374-6, 
year = {1976}, 
title = {{The Hopf Bifurcation and Its Applications}}, 
author = {Marsden, J. E. and McCracken, M.}, 
journal = {Applied Mathematical Sciences}, 
issn = {0066-5452}, 
doi = {10.1007/978-1-4612-6374-6}, 
keywords = {}
}
@article{kocarev1995on, 
year = {1995}, 
title = {{On Turing instability in two diffusely coupled systems}}, 
author = {Kocarev, L.M. and Janjic, P.A.}, 
journal = {IEEE Transactions on Circuits and Systems I: Fundamental Theory and Applications}, 
issn = {1057-7122}, 
doi = {10.1109/81.473587}, 
abstract = {{This work deals with Turing instability in two diffusely coupled systems. We show that for the certain type of vector fields, diffusive coupling can cause instability of otherwise stable fixed points, and produce chaos. Accompanying numerical examples are obtained using Chua's equation. We discuss possible application of this concept of instability in modeling of biological cell assemblies, as well as some generalizations that would be interesting to attempt.<>}}, 
pages = {779--784}, 
number = {10}, 
volume = {42}, 
keywords = {}
}
@article{pogromsky1999on, 
year = {1999}, 
title = {{On diffusion driven oscillations in coupled dynamical systems}}, 
author = {Pogromsky, Alexander and Glad, Torkel and Numeijer, Henk}, 
journal = {International Journal of Bifurcation and Chaos}, 
issn = {0218-1274}, 
doi = {10.1142/s0218127499000444}, 
abstract = {{The paper deals with the problem of destabilization of diffusively coupled identical systems. Following a question of Smale [1976], it is shown that globally asymptotically stable systems being diffusively coupled, may exhibit oscillatory behavior. It is shown that if the diffusive medium consists of hyperbolically nonminimum phase systems and the diffusive factors exceed some threshold value, the origin of the overall system undergoes a Poincaré–Andronov–Hopf bifurcation resulting in oscillatory behavior.}}, 
pages = {629--644}, 
number = {04}, 
volume = {9}, 
keywords = {}
}
@article{nijholt2023chaotic, 
year = {2023}, 
title = {{Chaotic Behavior in Diffusively Coupled Systems}}, 
author = {Nijholt, Eddie and Pereira, Tiago and Queiroz, Fernando C. and Turaev, Dmitry}, 
journal = {Communications in Mathematical Physics}, 
issn = {0010-3616}, 
doi = {10.1007/s00220-023-04699-5}, 
eprint = {2308.10472}, 
abstract = {{We study emergent oscillatory behavior in networks of diffusively coupled nonlinear ordinary differential equations. Starting from a situation where each isolated node possesses a globally attracting equilibrium point, we give, for an arbitrary network configuration, general conditions for the existence of the diffusive coupling of a homogeneous strength which makes the network dynamics chaotic. The method is based on the theory of local bifurcations we develop for diffusively coupled networks. We, in particular, introduce the class of the so-called versatile network configurations and prove that the Taylor coefficients of the reduction to the center manifold for any versatile network can take any given value.}}, 
pages = {2715--2756}, 
number = {3}, 
volume = {401}, 
keywords = {}
}
@incollection{smale1976a, 
year = {1976}, 
title = {{A Mathematical Model of Two Cells Via Turing's Equation}}, 
author = {Smale, S.}, 
booktitle = {The Hopf Bifurcation and Its Applications}, 
isbn = {978-1-4612-6374-6}, 
url = {https://doi.org/10.1007/978-1-4612-6374-6\_24}, 
abstract = {{Here we describe a mathematical model in the field of cellular biology. It is a model for two similar cells which interact via diffusion past a membrane. Each cell by itself is inert or dead in the sense that the concentrations of its enzymes achieve a constant equilibrium. In interaction however, the cellular system pulses (or expressed perhaps over dramatically, becomes alive!) in the sense that the concentrations of the enzymes in each cell will oscillate indefinitely. Of course we are using an extremely simplified picture of actual cells.}}, 
pages = {354--367}, 
publisher = {Springer New York}, 
keywords = {}, 
doi = {10.1007/978-1-4612-6374-6\_24}
}
@article{stankovski2017coupling, 
year = {2017}, 
title = {{Coupling functions: Universal insights into dynamical interaction mechanisms}}, 
author = {Stankovski, Tomislav and Pereira, Tiago and McClintock, Peter V. E. and Stefanovska, Aneta}, 
journal = {Reviews of Modern Physics}, 
issn = {0034-6861}, 
doi = {10.1103/revmodphys.89.045001}, 
eprint = {1706.01810}, 
abstract = {{The dynamical systems found in nature are rarely isolated. Instead they interact and influence each other. The coupling functions that connect them contain detailed information about the functional mechanisms underlying the interactions and prescribe the physical rule specifying how an interaction occurs. A coherent and comprehensive review is presented encompassing the rapid progress made recently in the analysis, understanding, and applications of coupling functions. The basic concepts and characteristics of coupling functions are presented through demonstrative examples of different domains, revealing the mechanisms and emphasizing their multivariate nature. The theory of coupling functions is discussed through gradually increasing complexity from strong and weak interactions to globally coupled systems and networks. A variety of methods that have been developed for the detection and reconstruction of coupling functions from measured data is described. These methods are based on different statistical techniques for dynamical inference. Stemming from physics, such methods are being applied in diverse areas of science and technology, including chemistry, biology, physiology, neuroscience, social sciences, mechanics, and secure communications. This breadth of application illustrates the universality of coupling functions for studying the interaction mechanisms of coupled dynamical systems.}}, 
pages = {045001}, 
number = {4}, 
volume = {89}, 
keywords = {}
}
@article{koch2024biological, 
year = {2024}, 
rating = {5}, 
title = {{Biological computations: Limitations of attractor-based formalisms and the need for transients}}, 
author = {Koch, Daniel and Nandan, Akhilesh and Ramesan, Gayathri and Koseska, Aneta}, 
journal = {Biochemical and Biophysical Research Communications}, 
issn = {0006-291X}, 
doi = {10.1016/j.bbrc.2024.150069}, 
pmid = {38754165}, 
abstract = {{Living systems, from single cells to higher vertebrates, receive a continuous stream of non-stationary inputs that they sense, for e.g. via cell surface receptors or sensory organs. By integrating these time-varying, multi-sensory, and often noisy information with memory using complex molecular or neuronal networks, they generate a variety of responses beyond simple stimulus-response association, including avoidance behavior, life-long-learning or social interactions. In a broad sense, these processes can be understood as a type of biological computation. Taking as a basis generic features of biological computations, such as real-time responsiveness or robustness and flexibility of the computation, we highlight the limitations of the current attractor-based framework for understanding computations in biological systems. We argue that frameworks based on transient dynamics away from attractors are better suited for the description of computations performed by neuronal and signaling networks. In particular, we discuss how quasi-stable transient dynamics from ghost states that emerge at criticality have a promising potential for developing an integrated framework of computations, that can help us understand how living system actively process information and learn from their continuously changing environment.}}, 
pages = {150069}, 
volume = {720}, 
keywords = {}
}
@article{koch2024ghost, 
year = {2024}, 
title = {{Ghost Channels and Ghost Cycles Guiding Long Transients in Dynamical Systems}}, 
author = {Koch, D. and Nandan, A. and Ramesan, G. and Tyukin, I. and Gorban, A. and Koseska, A.}, 
journal = {Physical Review Letters}, 
issn = {0031-9007}, 
doi = {10.1103/physrevlett.133.047202}, 
abstract = {{Dynamical descriptions and modeling of natural systems have generally focused on fixed points, with saddles and saddle-based phase-space objects such as heteroclinic channels or cycles being central concepts behind the emergence of quasistable long transients. Reliable and robust transient dynamics observed for real, inherently noisy systems is, however, not met by saddle-based dynamics, as demonstrated here. Generalizing the notion of ghost states, we provide a complementary framework that does not rely on the precise knowledge or existence of (un)stable fixed points, but rather on slow directed flows organized by ghost sets in ghost channels and ghost cycles. Moreover, we show that the appearance of these novel objects is an emergent property of a broad class of models typically used for description of natural systems.}}, 
pages = {047202}, 
number = {4}, 
volume = {133}, 
keywords = {}
}
@article{postlethwaite2024a, 
year = {2024}, 
title = {{A Continuous Time Dynamical Turing Machine}}, 
author = {Postlethwaite, Claire M. and Ashwin, Peter and Egbert, Matthew}, 
journal = {IEEE Transactions on Neural Networks and Learning Systems}, 
issn = {2162-237X}, 
doi = {10.1109/tnnls.2024.3397995}, 
pmid = {38753481}, 
abstract = {{Continuous time recurrent neural networks (CTRNNs) are systems of coupled ordinary differential equations (ODEs) inspired by the structure of neural networks in the brain. CTRNNs are known to be universal dynamical approximators: given a large enough system, the parameters of a CTRNN can be tuned to produce output that is arbitrarily close to that of any other dynamical system. However, in practice, both designing systems of CTRNN to have a certain output, and the reverse—understanding the dynamics of a given system of CTRNN—can be nontrivial. In this article, we describe a method for embedding any specified Turing machine in its entirety into a CTRNN. As such, we describe in detail a continuous time dynamical system that performs arbitrary discrete-state computations. We suggest that in acting as both a continuous time dynamical system and as a computer, the study of such systems can help refine and advance the debate concerning the Computational Hypothesis that cognition is a form of computation and the Dynamical Hypothesis that cognitive systems are dynamical systems.}}, 
pages = {1--13}, 
number = {99}, 
volume = {PP}, 
keywords = {}
}
@article{budzinski2024exact, 
year = {2024}, 
title = {{An exact mathematical description of computation with transient spatiotemporal dynamics in a complex-valued neural network}}, 
author = {Budzinski, Roberto C. and Busch, Alexandra N. and Mestern, Samuel and Martin, Erwan and Liboni, Luisa H. B. and Pasini, Federico W. and Mináč, Ján and Coleman, Todd and Inoue, Wataru and Muller, Lyle E.}, 
journal = {Communications Physics}, 
doi = {10.1038/s42005-024-01728-0}, 
abstract = {{Networks throughout physics and biology leverage spatiotemporal dynamics for computation. However, the connection between structure and computation remains unclear. Here, we study a complex-valued neural network (cv-NN) with linear interactions and phase-delays. We report the cv-NN displays sophisticated spatiotemporal dynamics, which we then use, in combination with a nonlinear readout, for computation. The cv-NN can instantiate dynamics-based logic gates, encode short-term memories, and mediate secure message passing through a combination of interactions and phase-delays. The computations in this system can be fully described in an exact, closed-form mathematical expression. Finally, using direct intracellular recordings of neurons in slices from neocortex, we demonstrate that computations in the cv-NN are decodable by living biological neurons as the nonlinear readout. These results demonstrate that complex-valued linear systems can perform sophisticated computations, while also being exactly solvable. Taken together, these results open future avenues for design of highly adaptable, bio-hybrid computing systems that can interface seamlessly with other neural networks. Neural networks perform computations through finely tuned patterns of connections, but it remains unclear how these connections lead to specific computations. Here, the authors introduce a neural network that can perform computations while also being mathematically solvable, providing new insights into the link from connections to computation.}}, 
pages = {239}, 
number = {1}, 
volume = {7}, 
keywords = {}
}
@article{loppini2015mathematical, 
year = {2015}, 
title = {{Mathematical modeling of gap junction coupling and electrical activity in human β-cells}}, 
author = {Loppini, Alessandro and Braun, Matthias and Filippi, Simonetta and Pedersen, Morten Gram}, 
journal = {Physical Biology}, 
issn = {1478-3975}, 
doi = {10.1088/1478-3975/12/6/066002}, 
pmid = {26403477}, 
abstract = {{Coordinated insulin secretion is controlled by electrical coupling of pancreatic β-cells due to connexin-36 gap junctions. Gap junction coupling not only synchronizes the heterogeneous β-cell population, but can also modify the electrical behavior of the cells. These phenomena have been widely studied with mathematical models based on data from mouse β-cells. However, it is now known that human β-cell electrophysiology shows important differences to its rodent counterpart, and although human pancreatic islets express connexin-36 and show evidence of β-cell coupling, these aspects have been little investigated in human β-cells. Here we investigate theoretically, the gap junction coupling strength required for synchronizing electrical activity in a small cluster of cells simulated with a recent mathematical model of human β-cell electrophysiology. We find a lower limit for the coupling strength of approximately 20 pS (i.e., normalized to cell size, \textbackslashtextasciitilde2 pS pF−1) below which spiking electrical activity is asynchronous. To confront this theoretical lower bound with data, we use our model to estimate from an experimental patch clamp recording that the coupling strength is approximately 100–200 pS (10–20 pS pF−1), similar to previous estimates in mouse β-cells. We then investigate the role of gap junction coupling in synchronizing and modifying other forms of electrical activity in human β-cell clusters. We find that electrical coupling can prolong the period of rapid bursting electrical activity, and synchronize metabolically driven slow bursting, in particular when the metabolic oscillators are in phase. Our results show that realistic coupling conductances are sufficient to promote synchrony in small clusters of human β-cells as observed experimentally, and provide motivation for further detailed studies of electrical coupling in human pancreatic islets.}}, 
pages = {066002}, 
number = {6}, 
volume = {12}, 
keywords = {}
}
@article{10.1016/j.bbamem.2003.10.023, 
year = {2004}, 
title = {{Electrical synapses: a dynamic signaling system that shapes the activity of neuronal networks}}, 
author = {Hormuzdi, Sheriar G. and Filippov, Mikhail A. and Mitropoulou, Georgia and Monyer, Hannah and Bruzzone, Roberto}, 
journal = {Biochimica et Biophysica Acta (BBA) - Biomembranes}, 
issn = {0005-2736}, 
doi = {10.1016/j.bbamem.2003.10.023}, 
pmid = {15033583}, 
abstract = {{Gap junctions consist of intercellular channels dedicated to providing a direct pathway for ionic and biochemical communication between contacting cells. After an initial burst of publications describing electrical coupling in the brain, gap junctions progressively became less fashionable among neurobiologists, as the consensus was that this form of synaptic transmission would play a minimal role in shaping neuronal activity in higher vertebrates. Several new findings over the last decade (e.g. the implication of connexins in genetic diseases of the nervous system, in processing sensory information and in synchronizing the activity of neuronal networks) have brought gap junctions back into the spotlight. The appearance of gap junctional coupling in the nervous system is developmentally regulated, restricted to distinct cell types and persists after the establishment of chemical synapses, thus suggesting that this form of cell–cell signaling may be functionally interrelated with, rather than alternative to chemical transmission. This review focuses on gap junctions between neurons and summarizes the available data, derived from molecular, biological, electrophysiological, and genetic approaches, that are contributing to a new appreciation of their role in brain function.}}, 
pages = {113--137}, 
number = {1-2}, 
volume = {1662}, 
keywords = {}
}
@article{benett2004electrical, 
year = {2004}, 
title = {{Electrical Coupling and Neuronal Synchronization in the Mammalian Brain}}, 
author = {Bennett, Michael V.L and Zukin, R.Suzanne}, 
journal = {Neuron}, 
issn = {0896-6273}, 
doi = {10.1016/s0896-6273(04)00043-1}, 
pmid = {14980200}, 
abstract = {{Certain neurons in the mammalian brain have long been known to be joined by gap junctions, which are the most common type of electrical synapse. More recently, cloning of neuron-specific connexins, increased capability of visualizing cells within brain tissue, labeling of cell types by transgenic methods, and generation of connexin knockouts have spurred a rapid increase in our knowledge of the role of gap junctions in neural activity. This article reviews the many subtleties of transmission mediated by gap junctions and the mechanisms whereby these junctions contribute to synchronous firing.}}, 
pages = {495--511}, 
number = {4}, 
volume = {41}, 
keywords = {}
}
@article{sohl2005expression, 
year = {2005}, 
title = {{Expression and functions of neuronal gap junctions}}, 
author = {Söhl, Goran and Maxeiner, Stephan and Willecke, Klaus}, 
journal = {Nature Reviews Neuroscience}, 
issn = {1471-003X}, 
doi = {10.1038/nrn1627}, 
pmid = {15738956}, 
abstract = {{Gap-junctional communication between neurons was first described several decades ago in crayfish, and was later studied by electrophysiological means in mammals. This field of research gained new momentum when the connexin 36 (Cx36) gene was discovered and its neuronal expression characterized.It is now clear that gap junctions between neurons (also called electrical synapses) are abundant postnatally and are even expressed in certain areas of the adult brain, including the retina. They seem to fulfil distinct functions that are independent of, but possibly modulated by, chemical synapses.In addition to Cx36, Cx45 and Cx57 expression have also been shown in certain types of mouse neuron. Recently, pannexin 1 and 2 were also shown to be expressed in certain types of central neuron in rodents and to form gap junction channels — at least after exogenous expression — in Xenopus laevis oocytes.Identification of the expression pattern of connexins in neurons was greatly eased by analysis with reporter genes, which can be expressed in trangenic mice instead of the corresponding connexin gene.During recent years, neuronal gap junctions have been characterized or postulated to be expressed in several adult brain regions, including the neocortex, thalamus, inferior olive, cerebellum and retina.The characterization of transgenic mouse mutants deficient in CX36 showed that gamma frequency network oscilliations between hippocampal interneurons were disrupted in such mutants and that night vision was compromised. The same decrease in the b-wave in the electroretinogram was found in CX36-deficient mice and in neuronally CX45-deficient mice, which, together with immunochemical evidence, indicates that these connexins form heterotypic gap junction channels between AII amacrine cells and ON-cone bipolar cells. Gap-junctional communication between neurons was first described several decades ago in crayfish, and was later studied by electrophysiological means in mammals. This field of research gained new momentum when the connexin 36 (Cx36) gene was discovered and its neuronal expression characterized. It is now clear that gap junctions between neurons (also called electrical synapses) are abundant postnatally and are even expressed in certain areas of the adult brain, including the retina. They seem to fulfil distinct functions that are independent of, but possibly modulated by, chemical synapses. In addition to Cx36, Cx45 and Cx57 expression have also been shown in certain types of mouse neuron. Recently, pannexin 1 and 2 were also shown to be expressed in certain types of central neuron in rodents and to form gap junction channels — at least after exogenous expression — in Xenopus laevis oocytes. Identification of the expression pattern of connexins in neurons was greatly eased by analysis with reporter genes, which can be expressed in trangenic mice instead of the corresponding connexin gene. During recent years, neuronal gap junctions have been characterized or postulated to be expressed in several adult brain regions, including the neocortex, thalamus, inferior olive, cerebellum and retina. The characterization of transgenic mouse mutants deficient in CX36 showed that gamma frequency network oscilliations between hippocampal interneurons were disrupted in such mutants and that night vision was compromised. The same decrease in the b-wave in the electroretinogram was found in CX36-deficient mice and in neuronally CX45-deficient mice, which, together with immunochemical evidence, indicates that these connexins form heterotypic gap junction channels between AII amacrine cells and ON-cone bipolar cells. Gap junctions are channel-forming structures in contacting plasma membranes that allow direct metabolic and electrical communication between almost all cell types in the mammalian brain. At least 20 connexin genes and 3 pannexin genes probably code for gap junction proteins in mice and humans. Gap junctions between murine neurons (also known as electrical synapses) can be composed of connexin 36, connexin 45 or connexin 57 proteins, depending on the type of neuron. Furthermore, pannexin 1 and 2 are likely to form electrical synapses. Here, we discuss the roles of connexin and pannexin genes in the formation of neuronal gap junctions, and evaluate recent functional analyses of electrical synapses that became possible through the characterization of mouse mutants that show targeted defects in connexin genes.}}, 
pages = {191--200}, 
number = {3}, 
volume = {6}, 
keywords = {}
}
@article{hurkey2023gap, 
year = {2023}, 
title = {{Gap junctions desynchronize a neural circuit to stabilize insect flight}}, 
author = {Hürkey, Silvan and Niemeyer, Nelson and Schleimer, Jan-Hendrik and Ryglewski, Stefanie and Schreiber, Susanne and Duch, Carsten}, 
journal = {Nature}, 
issn = {0028-0836}, 
doi = {10.1038/s41586-023-06099-0}, 
pmid = {37225999}, 
pmcid = {PMC10232364}, 
abstract = {{Insect asynchronous flight is one of the most prevalent forms of animal locomotion used by more than 600,000 species. Despite profound insights into the motor patterns1, biomechanics2,3 and aerodynamics underlying asynchronous flight4,5, the architecture and function of the central-pattern-generating (CPG) neural network remain unclear. Here, on the basis of an experiment–theory approach including electrophysiology, optophysiology, Drosophila genetics and mathematical modelling, we identify a miniaturized circuit solution with unexpected properties. The CPG network consists of motoneurons interconnected by electrical synapses that, in contrast to doctrine, produce network activity splayed out in time instead of synchronized across neurons. Experimental and mathematical evidence support a generic mechanism for network desynchronization that relies on weak electrical synapses and specific excitability dynamics of the coupled neurons. In small networks, electrical synapses can synchronize or desynchronize network activity, depending on the neuron-intrinsic dynamics and ion channel composition. In the asynchronous flight CPG, this mechanism translates unpatterned premotor input into stereotyped neuronal firing with fixed sequences of cell activation that ensure stable wingbeat power and, as we show, is conserved across multiple species. Our findings prove a wider functional versatility of electrical synapses in the dynamic control of neural circuits and highlight the relevance of detecting electrical synapses in connectomics. In the Drosophila central-pattern-generating neural network, a mechanism for network desynchronization relying on weak electrical synapses and specific excitability dynamics of the coupled neurons translates unpatterned premotor input into stereotyped neuronal firing with fixed sequences of cell activation, ensuring stable wingbeat power.}}, 
pages = {118--125}, 
number = {7963}, 
volume = {618}, 
keywords = {}
}
@article{undefined, 
title = {{Axonal Gap Junctions Between Principal Neurons: A Novel Source of Network Oscillations, and Perhaps Epileptogenesis}}, 
keywords = {}
}
@article{kepler1990the, 
year = {1990}, 
title = {{The Effect of Electrical Coupling on the Frequency of Model Neuronal Oscillators}}, 
author = {Kepler, Thomas B. and Marder, Eve and Abbott, L. F.}, 
journal = {Science}, 
issn = {0036-8075}, 
doi = {10.1126/science.2321028}, 
pmid = {2321028}, 
abstract = {{Neurons with oscillatory properties are a common feature of the nervous system, but little is known about how neural oscillators shape the behavior of neuronal networks or how network interactions influence the properties of neural oscillators. Mathematical models are used to examine the effect of electrically coupling an oscillatory neuron to a second neuron that is either silent or tonically firing. Models of oscillatory neurons with varying degrees of complexity show that this coupling can either increase or decrease the frequency of an oscillator, depending on its membrane potential wave form, the state of the neuron to which it is coupled, and the strength of the coupling. Thus, electrical coupling provides a flexible mechanism for modifying the behavior of an oscillatory neural network.}}, 
pages = {83--85}, 
number = {4951}, 
volume = {248}, 
keywords = {}
}
@article{sadykov2021model, 
year = {2021}, 
title = {{Model of two competing populations in two habitats with migration: Application to optimal marine protected area size}}, 
author = {Sadykov, Alexander and Farnsworth, Keith D.}, 
journal = {Theoretical Population Biology}, 
issn = {0040-5809}, 
doi = {10.1016/j.tpb.2021.10.002}, 
pmid = {34762901}, 
abstract = {{The standard model of a single population fragmented into two patches connected by migration, was first introduced in the 1970s by Freedman and Waltman, since generating long-term research interest, though its full analysis for arbitrary values of migration rate has only been completed relatively recently. Here, we present a model of two competing species in a two-patch habitat with migrations between patches. We derive equilibrium solutions of this model for three cases of migration rate resulting in isolated, well-mixed and semi-isolated habitats. We evaluate the full range of effects of habitat, life-history and migration parameters on population sizes. Finally, we add harvesting mortality and define conditions under which introduction of a no-harvesting (protected) area may lead to increased maximum sustainable yield. The results have applications in mixed fishery management and the design of wildlife protection zones, including marine protected areas (MPAs).}}, 
pages = {114--122}, 
volume = {142}, 
keywords = {}
}
@article{liang2023a, 
year = {2023}, 
title = {{A multi-species approach for protected areas ecological network construction based on landscape connectivity}}, 
author = {Liang, Guofu and Niu, Hanbo and Li, Yan}, 
journal = {Global Ecology and Conservation}, 
issn = {2351-9894}, 
doi = {10.1016/j.gecco.2023.e02569}, 
abstract = {{The establishment of ecological networks is crucial for biodiversity conservation, especially at broad spatial scales. It is still challenging to develop an ecological network construction method based on landscape connectivity for multiple species. The purpose of this study is to propose a multi-species framework approach for constructing ecological networks and determine the restoration priority for four focal mammal species across the protected areas in the western mountains of Henan Province, China. We built ecological networks for each species by using circuit theory and least-cost path models, and integrated the ecological corridors and key barrier areas to determine the restoration priority for multiple species. The results showed that the connectivity of the ecological network was closely related to the species dispersal capacity. For species with higher dispersal capacity, all core areas were interconnected and have multiple alternative paths, and the network of protected areas seemed to be well connected. With the decline of species dispersal ability, ecological networks became more complex and not well connected, and more migration corridors that exceed species dispersal capability have emerged. It was important to consider the needs for species-specific management plans. Key ecological corridors and barrier areas, which have significant impacts on species migration, are mainly land use areas dominated by cropland. Our research indicates that the methods proposed in this study can help determine the restoration priority of key ecological corridors and barrier areas, which may facilitate conservation efforts for multiple species, especially in areas with poor species distribution and movement data.}}, 
pages = {e02569}, 
volume = {46}, 
keywords = {}
}
@article{blasius1999complex, 
year = {1999}, 
title = {{Complex dynamics and phase synchronization in spatially extended ecological systems}}, 
author = {Blasius, Bernd and Huppert, Amit and Stone, Lewi}, 
journal = {Nature}, 
issn = {0028-0836}, 
doi = {10.1038/20676}, 
pmid = {10360572}, 
abstract = {{Population cycles that persist in time and are synchronized over space pervade ecological systems, but their underlying causes remain a long-standing enigma1,2,3,4,5,6,7,8,9,10,11. Here we examine the synchronization of complex population oscillations in networks of model communities and in natural systems, where phenomena such as unusual ‘4- and 10-year cycle’ of wildlife are often found. In the proposed spatial model, each local patch sustains a three-level trophic system composed of interacting predators, consumers and vegetation. Populations oscillate regularly and periodically in phase, but with irregular and chaotic peaks together in abundance—twin realistic features that are not found in standard ecological models. In a spatial lattice of patches, only small amounts of local migration are required to induce broad-scale ‘phase synchronization’12,13, with all populations in the lattice phase-locking to the same collective rhythm. Peak population abundances, however, remain chaotic and largely uncorrelated. Although synchronization is often perceived as being detrimental to spatially structured populations14, phase synchronization leads to the emergence of complex chaotic travelling-wave structures which may be crucial for species persistence.}}, 
pages = {354--359}, 
number = {6734}, 
volume = {399}, 
keywords = {}
}
@article{medeiros2021asymmetry, 
year = {2021}, 
title = {{Asymmetry-induced order in multilayer networks}}, 
author = {Medeiros, Everton S. and Feudel, Ulrike and Zakharova, Anna}, 
journal = {Physical Review E}, 
issn = {2470-0045}, 
doi = {10.1103/physreve.104.024302}, 
pmid = {34525566}, 
eprint = {2104.09613}, 
abstract = {{Symmetries naturally occur in real-world networks and can significantly influence the observed dynamics. For instance, many synchronization patterns result from the underlying network symmetries, and high symmetries are known to increase the stability of synchronization. Yet here we find that general macroscopic features of network solutions such as regularity can be induced by breaking their symmetry of interactions. We demonstrate this effect in an ecological multilayer network where the topological asymmetries occur naturally. These asymmetries rescue the system from chaotic oscillations by establishing stable periodic orbits and equilibria. We call this phenomenon asymmetry-induced order and uncover its mechanism by analyzing both analytically and numerically the absence of dynamics on the system's synchronization manifold. Moreover, the bifurcation scenario describing the route from chaos to order is also disclosed. We demonstrate that this result also holds for generic node dynamics by analyzing coupled paradigmatic Rössler and Lorenz systems.}}, 
pages = {024302}, 
number = {2}, 
volume = {104}, 
keywords = {}
}
@article{pilosof2017the, 
year = {2017}, 
title = {{The multilayer nature of ecological networks}}, 
author = {Pilosof, Shai and Porter, Mason A. and Pascual, Mercedes and Kéfi, Sonia}, 
journal = {Nature Ecology \& Evolution}, 
doi = {10.1038/s41559-017-0101}, 
pmid = {28812678}, 
eprint = {1511.04453}, 
abstract = {{Although networks provide a powerful approach to study a large variety of ecological systems, their formulation does not typically account for multiple interaction types, interactions that vary in space and time, and interconnected systems such as networks of networks. The emergent field of ‘multilayer networks’ provides a natural framework for extending analyses of ecological systems to include such multiple layers of complexity, as it specifically allows one to differentiate and model ‘intralayer’ and ‘interlayer’ connectivity. The framework provides a set of concepts and tools that can be adapted and applied to ecology, facilitating research on high-dimensional, heterogeneous systems in nature. Here, we formally define ecological multilayer networks based on a review of previous, related approaches; illustrate their application and potential with analyses of existing data; and discuss limitations, challenges, and future applications. The integration of multilayer network theory into ecology offers largely untapped potential to investigate ecological complexity and provide new theoretical and empirical insights into the architecture and dynamics of ecological systems. Ecological interactions typically vary across both space and time. Here, the authors outline a framework for incorporating multiple layers of complexity into ecological networks, and discuss their potential applications and future challenges.}}, 
pages = {0101}, 
number = {4}, 
volume = {1}, 
keywords = {}
}
@article{medeiros2023transient, 
year = {2023}, 
title = {{Transient chimera states emerging from dynamical trapping in chaotic saddles}}, 
author = {Medeiros, Everton S. and Omel’chenko, Oleh and Feudel, Ulrike}, 
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science}, 
issn = {1054-1500}, 
doi = {10.1063/5.0155857}, 
pmid = {37729099}, 
abstract = {{Nonlinear systems possessing nonattracting chaotic sets, such as chaotic saddles, embedded in their state space may oscillate chaotically for a transient time before eventually transitioning into some stable attractor. We show that these systems, when networked with nonlocal coupling in a ring, are capable of forming chimera states, in which one subset of the units oscillates periodically in a synchronized state forming the coherent domain, while the complementary subset oscillates chaotically in the neighborhood of the chaotic saddle constituting the incoherent domain. We find two distinct transient chimera states distinguished by their abrupt or gradual termination. We analyze the lifetime of both chimera states, unraveling their dependence on coupling range and size. We find an optimal value for the coupling range yielding the longest lifetime for the chimera states. Moreover, we implement transversal stability analysis to demonstrate that the synchronized state is asymptotically stable for network configurations studied here.}}, 
pages = {093130}, 
number = {9}, 
volume = {33}, 
keywords = {}
}
@article{eisenhauer2024plant, 
year = {2024}, 
title = {{Plant diversity effects on soil multistability}}, 
author = {Eisenhauer, Nico and Vogel, Cordula and Horta, Luiz A Domeignoz and Asato, Ana Bonato and Janda, Zarah and Cesarz, Simone and Eisenhauer, Nico and Horta, Luiz A Domeignoz and Janda, Zarah}, 
journal = {Research Ideas and Outcomes}, 
doi = {10.3897/rio.10.e127123}, 
abstract = {{Soil is the basis for life on Earth as we know it. Healthy and stable soil is a prerequisite for well-functioning terrestrial ecosystems and has, thus, been proposed to play a key role in plant diversity–ecosystem functioning relationships. The overall objective of this sub-project is to study multidimensional soil stability as affected by plant diversity in a long-term plant diversity experiment. We designed three coordinated work packages (WPs) to comprehensively assess soil multistability to environmental fluctuations and climate extremes by considering the biological, chemical and physical dimensions that are key for soil functioning. We will use all unique facilities and approaches of the Jena Experiment Research Unit by combining synthesis of long-term data in the Main Experiment and the ΔBEF Experiment with performing new soil analyses in the DrY Experiment, the ResCUE Experiment and a joint CoMic Experiment, to gain a better mechanistic understanding of plant diversity–ecosystem functioning relationships. In close collaboration with other sub-projects, we will assess biological, chemical and physical soil properties and stability indicators that will be used to calculate soil multifunctionality and multistability indices. In WP1, we will build on three unique datasets to explore short-term and long-term effects of plant diversity on the stability of soil (microbial) properties. In WP2, we will combine different datasets and approaches to explore if plant diversity effects on the magnitude and stability of soil properties increase with abiotic and biotic stresses. In WP3, we will combine measurements of the above-mentioned dimensions of soil stability to explore if plant diversity increases the stability of multiple soil properties under hot drought. This sub-project is at the heart of the Research Unit by testing the overarching hypotheses outlined in the Coordination Proposal of the Jena Experiment, contributing to all main experiments, sharing data and performing joint sampling campaigns with all sub-projects and, at the same time, introducing a novel concept of soil multistability as affected by plant diversity and climate extremes. We propose to use a combination of simple, high-throughput (e.g. bait-lamina test) and more sophisticated methods (e.g. extracellular polymeric substances analyses) to be able to investigate temporal dynamics of soil processes and their mechanistic basis. Taken together, the results of the three WPs will provide new insights into the stabilising mechanisms of soil properties in the long term and in relation to climate extremes through plant diversity.}}, 
pages = {e127123}, 
volume = {10}, 
keywords = {}
}
@article{suzuki2021energy, 
year = {2021}, 
title = {{Energy landscape analysis elucidates the multistability of ecological communities across environmental gradients}}, 
author = {Suzuki, Kenta and Nakaoka, Shinji and Fukuda, Shinji and Masuya, Hiroshi}, 
journal = {Ecological Monographs}, 
issn = {0012-9615}, 
doi = {10.1002/ecm.1469}, 
abstract = {{Compositional multistability is widely observed in multispecies ecological communities. Since differences in community composition often lead to differences in community function, understanding compositional multistability is essential to comprehend the role of biodiversity in maintaining ecosystems. In community assembly studies, it has long been recognized that the order and timing of species migration and extinction influence structure and function of communities. The study of multistability in ecology has focused on the change in dynamical stability across environmental gradients, and was developed mainly for low‐dimensional systems. As a result, methodologies for studying the compositional stability of empirical multispecies communities are not well developed. Here, we show that models previously used in ecology can be analyzed from a new perspective, the energy landscape, to unveil compositional stability in observational data. To show that our method can be applicable to real‐world ecological communities, we simulated assembly dynamics driven by population‐level processes, and show that results were mostly robust to different simulation assumptions. Our method reliably captured the change in the overall compositional stability of multispecies communities over environmental change, and indicated a small fraction of community compositions that may be channels for transitions between stable states. When applied to murine gut microbiota, our method showed the presence of two alternative states whose relationship changes with age, and suggested mechanisms by which aging affects the compositional stability of the murine gut microbiota. Our method provides a practical tool to study the compositional stability of communities in a changing world, and will facilitate empirical studies that integrate the concept of multistability from different fields.}}, 
number = {3}, 
volume = {91}, 
keywords = {}
}
@article{meng2022the, 
year = {2022}, 
title = {{The fundamental benefits of multiplexity in ecological networks}}, 
author = {Meng, Yu and Lai, Ying-Cheng and Grebogi, Celso}, 
journal = {Journal of the Royal Society Interface}, 
doi = {10.1098/rsif.2022.0438}, 
pmid = {36167085}, 
pmcid = {PMC9514891}, 
abstract = {{A tipping point presents perhaps the single most significant threat to an ecological system as it can lead to abrupt species extinction on a massive scale. Climate changes leading to the species decay parameter drifts can drive various ecological systems towards a tipping point. We investigate the tipping-point dynamics in multi-layer ecological networks supported by mutualism. We unveil a natural mechanism by which the occurrence of tipping points can be delayed by multiplexity that broadly describes the diversity of the species abundances, the complexity of the interspecific relationships, and the topology of linkages in ecological networks. For a double-layer system of pollinators and plants, coupling between the network layers occurs when there is dispersal of pollinator species. Multiplexity emerges as the dispersing species establish their presence in the destination layer and have a simultaneous presence in both. We demonstrate that the new mutualistic links induced by the dispersing species with the residence species have fundamental benefits to the well-being of the ecosystem in delaying the tipping point and facilitating species recovery. Articulating and implementing control mechanisms to induce multiplexity can thus help sustain certain types of ecosystems that are in danger of extinction as the result of environmental changes.}}, 
pages = {20220438}, 
number = {194}, 
volume = {19}, 
keywords = {}
}
@article{truscott1984ocean, 
year = {1994}, 
title = {{Ocean Plankton Populations As Excitable Media}}, 
author = {Truscott, J. E. and Brindley, J.}, 
journal = {Bulletin of Mathematical Biology}, 
pages = {981--998}, 
number = {5}, 
volume = {56}, 
keywords = {}
}
@article{10.1137/18m1186617, 
year = {2018}, 
title = {{A New Frame for an Old (Phase) Portrait: Finding Rivers and Other Flow Features in the Plane}}, 
author = {Letson, Benjamin and Rubin, Jonathan E}, 
journal = {SIAM Journal on Applied Dynamical Systems}, 
doi = {10.1137/18m1186617}, 
pages = {2414--2445}, 
number = {4}, 
volume = {17}, 
keywords = {}
}
@article{10.1137/20m1354970, 
year = {2021}, 
title = {{Type III Responses to Transient Inputs in Hybrid Nonlinear Neuron Models}}, 
author = {Rubin, Jonathan E and Signerska-Rynkowska, Justyna and Touboul, Jonathan D}, 
journal = {SIAM Journal on Applied Dynamical Systems}, 
doi = {10.1137/20m1354970}, 
pages = {953--980}, 
number = {2}, 
volume = {20}, 
keywords = {}
}
@book{broer2011dynamical, 
year = {2011}, 
title = {{Dynamical Systems and Chaos}}, 
author = {Broer, Henk and Takens, Floris}, 
isbn = {9781441968692}, 
series = {Applied Mathematical Sciences}, 
keywords = {}, 
doi = {10.1007/978-1-4419-6870-8}
}
@article{shukla2014a, 
year = {2014}, 
title = {{A new analytical approach for limit cycles and quasi-periodic solutions of nonlinear oscillators: the example of the forced Van der Pol Duffing oscillator}}, 
author = {Shukla, Anant Kant and Ramamohan, T R and Srinivas, S}, 
journal = {Physica Scripta}, 
issn = {0031-8949}, 
doi = {10.1088/0031-8949/89/7/075202}, 
pages = {075202}, 
number = {7}, 
volume = {89}, 
keywords = {}
}
@book{saletan, 
year = {1998}, 
title = {{Classical Dynamics: A Contemporary Approach}}, 
author = {José, Jorge V. and Saletan, Eugene J.}, 
publisher = {Cambridge University Press}, 
address = {Cambridge}, 
keywords = {}
}
@article{sandstede1997constructing, 
year = {1997}, 
title = {{Constructing dynamical systems having homoclinic bifurcation points of codimension two}}, 
author = {Sandstede, Björn}, 
journal = {Journal of Dynamics and Differential Equations}, 
issn = {1040-7294}, 
doi = {10.1007/bf02219223}, 
abstract = {{A procedure is derived which allows for a systematic construction of three-dimensional ordinary differential equations having homoclinic solutions. The equations are proved to exhibit codimension-two homoclinic bifurcation points. Examples include the non-orientable resonant bifurcation, the inclination-flip, and the orbit-flip. In addition, an equation is constructed which has a homoclinic orbit converging to a saddle-focus satisfying Shilnikov's condition. The vector fields are polynomial and non-stiff in that the eigenvalues are of moderate size.}}, 
pages = {269--288}, 
number = {2}, 
volume = {9}, 
keywords = {}
}
@article{bullmore2009complex, 
year = {2009}, 
title = {{Complex brain networks: graph theoretical analysis of structural and functional systems}}, 
author = {Bullmore, Ed and Sporns, Olaf}, 
journal = {Nature Reviews Neuroscience}, 
issn = {1471-003X}, 
doi = {10.1038/nrn2575}, 
pmid = {19190637}, 
abstract = {{Understanding the network organization of the brain has been a long-standing challenge for neuroscience. In the past decade, developments in graph theory have provided many new methods for topologically analysing complex networks, some of which have already been translated to the characterization of anatomical and functional brain networks.Anatomical networks at whole-brain and cellular scales in several species consistently demonstrate conservation of wiring costs and small-world topology (high clustering and short path length). Human brain anatomical networks, derived from MRI or diffusion tensor imaging data, have high-degree cortical 'hubs' and modular and hierarchical properties.Functional networks also demonstrate small-world properties at whole-brain and cellular spatial scales. Additionally, complex network properties including small-worldness and the existence of hubs are conserved over different frequency scales in functional MRI and electrophysiological data.Convergent experimental and computational data suggest that there is interdependence in the organization of structural and functional networks. The topology, synchronizability and other dynamic properties of functional networks are strongly affected by small-world and other metrics of structural connectivity. Conversely, over a slower timescale the dynamics can modulate structural network topology.Neuropsychiatric disorders can be thought of as dysconnectivity syndromes, and graph theory has already been used to quantify abnormality of structural and functional network properties in schizophrenia, Alzheimer's disease and other disorders. Graph theory can help us to understand the vulnerability of brain networks to lesions and could in future be used to provide markers of genetic risk for disorders or to measure therapeutic effects of drug treatments on functional networks.The network organization of the brain, as it is beginning to be revealed by graph theory, is compatible with the hypothesis that the brain, perhaps in common with other complex networks, has evolved both to maximize the efficiency of information transfer and to minimize connection cost, at all scales of space and time. Key issues for future work include clarifying the relationship between the brain's network properties and its emergent cognitive behaviours in health and disease. Understanding the network organization of the brain has been a long-standing challenge for neuroscience. In the past decade, developments in graph theory have provided many new methods for topologically analysing complex networks, some of which have already been translated to the characterization of anatomical and functional brain networks. Anatomical networks at whole-brain and cellular scales in several species consistently demonstrate conservation of wiring costs and small-world topology (high clustering and short path length). Human brain anatomical networks, derived from MRI or diffusion tensor imaging data, have high-degree cortical 'hubs' and modular and hierarchical properties. Functional networks also demonstrate small-world properties at whole-brain and cellular spatial scales. Additionally, complex network properties including small-worldness and the existence of hubs are conserved over different frequency scales in functional MRI and electrophysiological data. Convergent experimental and computational data suggest that there is interdependence in the organization of structural and functional networks. The topology, synchronizability and other dynamic properties of functional networks are strongly affected by small-world and other metrics of structural connectivity. Conversely, over a slower timescale the dynamics can modulate structural network topology. Neuropsychiatric disorders can be thought of as dysconnectivity syndromes, and graph theory has already been used to quantify abnormality of structural and functional network properties in schizophrenia, Alzheimer's disease and other disorders. Graph theory can help us to understand the vulnerability of brain networks to lesions and could in future be used to provide markers of genetic risk for disorders or to measure therapeutic effects of drug treatments on functional networks. The network organization of the brain, as it is beginning to be revealed by graph theory, is compatible with the hypothesis that the brain, perhaps in common with other complex networks, has evolved both to maximize the efficiency of information transfer and to minimize connection cost, at all scales of space and time. Key issues for future work include clarifying the relationship between the brain's network properties and its emergent cognitive behaviours in health and disease. In recent years, the principles of network science have increasingly been applied to the study of the brain's structural and functional organization. Bullmore and Sporns review this growing field of research and discuss its contributions to our understanding of brain function. Recent developments in the quantitative analysis of complex networks, based largely on graph theory, have been rapidly translated to studies of brain network organization. The brain's structural and functional systems have features of complex networks — such as small-world topology, highly connected hubs and modularity — both at the whole-brain scale of human neuroimaging and at a cellular scale in non-human animals. In this article, we review studies investigating complex brain networks in diverse experimental modalities (including structural and functional MRI, diffusion tensor imaging, magnetoencephalography and electroencephalography in humans) and provide an accessible introduction to the basic principles of graph theory. We also highlight some of the technical challenges and key questions to be addressed by future developments in this rapidly moving field.}}, 
pages = {186--198}, 
number = {3}, 
volume = {10}, 
keywords = {}
}
@article{landi2018complexity, 
year = {2018}, 
title = {{Complexity and stability of ecological networks: a review of the theory}}, 
author = {Landi, Pietro and Minoarivelo, Henintsoa O. and Brännström, Åke and Hui, Cang and Dieckmann, Ulf}, 
journal = {Population Ecology}, 
issn = {1438-3896}, 
doi = {10.1007/s10144-018-0628-3}, 
abstract = {{Our planet is changing at paces never observed before. Species extinction is happening at faster rates than ever, greatly exceeding the five mass extinctions in the fossil record. Nevertheless, our lives are strongly based on services provided by ecosystems, thus the responses to global change of our natural heritage are of immediate concern. Understanding the relationship between complexity and stability of ecosystems is of key importance for the maintenance of the balance of human growth and the conservation of all the natural services that ecosystems provide. Mathematical network models can be used to simplify the vast complexity of the real world, to formally describe and investigate ecological phenomena, and to understand ecosystems propensity of returning to its functioning regime after a stress or a perturbation. The use of ecological‐network models to study the relationship between complexity and stability of natural ecosystems is the focus of this review. The concept of ecological networks and their characteristics are first introduced, followed by central and occasionally contrasting definitions of complexity and stability. The literature on the relationship between complexity and stability in different types of models and in real ecosystems is then reviewed, highlighting the theoretical debate and the lack of consensual agreement. The summary of the importance of this line of research for the successful management and conservation of biodiversity and ecosystem services concludes the review.}}, 
pages = {319--345}, 
number = {4}, 
volume = {60}, 
keywords = {}
}
@article{potratzki2024synchronization, 
year = {2024}, 
title = {{Synchronization dynamics of phase oscillators on power grid models}}, 
author = {Potratzki, Max and Bröhl, Timo and Rings, Thorsten and Lehnertz, Klaus}, 
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science}, 
issn = {1054-1500}, 
doi = {10.1063/5.0197930}, 
pmid = {38598675}, 
abstract = {{We investigate topological and spectral properties of models of European and US-American power grids and of paradigmatic network models as well as their implications for the synchronization dynamics of phase oscillators with heterogeneous natural frequencies. We employ the complex-valued order parameter—a widely used indicator for phase ordering—to assess the synchronization dynamics and observe the order parameter to exhibit either constant or periodic or non-periodic, possibly chaotic temporal evolutions for a given coupling strength but depending on initial conditions and the systems’ disorder. Interestingly, both topological and spectral characteristics of the power grids point to a diminished capability of these networks to support a temporarily stable synchronization dynamics. We find non-trivial commonalities between the synchronization dynamics of oscillators on seemingly opposing topologies.}}, 
pages = {043131}, 
number = {4}, 
volume = {34}, 
keywords = {}
}
