\chapter{Small changes at single nodes can shift global network dynamics}

\begin{center}
    % {\Large \textbf{Small changes at single nodes can shift global network dynamic}} \\[1em]
    {\large Kalel L. Rossi$^{1}$, Roberto C. Budzinski $^{2,3,4}$, Bruno R. R. Boaretto $^{5}$, Lyle E. Muller $^{2,3,4}$, Ulrike Feudel$^{1}$ } \\[1em]
    {\small $^1$ Theoretical Physics/Complex Systems, ICBM, Carl von Ossietzky University of Oldenburg, Oldenburg, Lower Saxony, Germany \\ $^2$ Department of Mathematics, Western University, London, Ontario, Canada, \\ $^3$ Brain and Mind Institute, Western University, London, Ontario, Canada, \\ $^4$ Western Academy for Advanced Research, Western University, London, Ontario, Canada, \\ $^5$ Institute of Science and Technology, Federal University of São Paulo, São José dos Campos, São Paulo, Brazil}
\end{center}


\vspace{1.5em}
\noindent
\textbf{Abstract.} 
Understanding the sensitivity of a system's behavior with respect to parameter changes is essential for many applications. This sensitivity may be desired - for instance, in the brain, where a large repertoire of different dynamics, particularly different synchronization patterns, is crucial - or may be undesired - for instance, in power grids, where disruptions to synchronization may lead to blackouts. In this work, we show that networks of coupled phase oscillators with nonlinear interactions can acquire a very large and complicated sensitivity to changes made in either their units' parameters or in their connections. Even modifications made to a parameter of a single unit can radically alter the global dynamics of the network in an unpredictable manner. This occurs over a wide parameter region, around the network's transitions to phase synchronization. We argue that this is a widespread phenomenon that can be expected in real-world systems, extending even beyond networks of oscillators. 
\vspace{1.5em}

\section{Introduction}\label{sec:intro}
Several systems of practical and theoretical importance are composed of, or can be modeled as, networks of interacting units. Examples from different research areas include power grids (networks of producers and consumers of electrical energy) \cite{motter2013spontaneous}, food webs \cite{dunne2002foodweb}, networks of electronic elements \cite{crotty2010josephson}, coupled lasers \cite{nixon2011synchronized}, and neurons in the brain \cite{varela2001brainweb}. An important question is how the dynamics of single units impact the network's overall dynamics, and what happens if these units are modified. What happens to the dynamics if the units' parameters change? For instance, in ecological systems, what happens if the reproduction rate of a prey increases? In power grids, can a change in the parameters of a single generator cause a large disruption, such as a blackout? Also, what happens if the units' dynamical states are modified, e.g. by shocking the units into a different state? In the brain, how can an epileptic seizure be stopped by employing a current pulse in one particular brain region? These questions highlight the idea that a regime in which single-unit-changes can alter the whole network's behavior can be either dangerous or advantageous, and is an important topic of research which we address in this work.

In both power grids and the brain, an important phenomenon is synchronization, i.e. the coherence of frequencies or even phases of oscillations. For example, it is crucial for power grids to have their elements synchronized in the $50-60$ \SI{}{\hertz} regime \cite{witthaut2022collective}. Moreover, several functional roles have been ascribed to synchronization in the brain \cite{fries2015rhythms, varela2001brainweb, singer1999neuronal}.  For systems in which synchronization is an essential process for functioning, the question of sensitivity with respect to perturbations becomes particularly important. This has been recognized in the literature, and various types of perturbations have been considered to study the vulnerability either of the synchronized state itself or of the transition to synchronization \cite{pikovsky2001synchronization, arenas2008synchronization}.
% In both power grids and the brain, an important phenomenon is synchronization, i.e. the coherence of frequencies or even phases of oscillations. For example, it is crucial for power grids to have their elements synchronized in the \SI{50}{\hertz}-\SI{60}{\hertz} regime \cite{witthaut2022collective}. Moreover, several functional roles have been ascribed to synchronization in the brain \cite{fries2015rhythms, varela2001brainweb, singer1999neuronal}.  For systems in which synchronization is an essential process for functioning, the question of sensitivity with respect to perturbations becomes particularly important. This has been recognized in the literature, and various types of perturbations have been considered to study the vulnerability either of the synchronized state itself or of the transition to synchronization \cite{pikovsky2001synchronization, arenas2008synchronization}.

In this work, we show that systems become very sensitive to changes in parameters during transitions to synchronization, such that even changes to parameters of single units can radically alter the dynamics of the whole system.
We call this phenomenon \textit{dynamical malleability} \cite{budzinski2020synchronization}, characterized by the fluctuations in network behavior caused by changes in the units' parameters or connections. Dynamical malleability can cause problems in real-world systems in two major ways: (i) the fluctuations in the dynamics can have a large magnitude, which can lead to drastic changes in the system's spatiotemporal dynamics and (ii) fluctuations are complicated and hard to predict, so that it is unclear which units or new parameter values can keep the networks in a similar synchronization state, and which others can not. Indeed, no method available in the literature to describe phase synchronization worked satisfactorily to predict the fluctuations we observe. This clearly important issue for the design and control of systems motivates our study to analyze the mechanisms that lead to these large fluctuations. 

To address it concretely, we study networks of Kuramoto oscillators organized in ring lattices. They constitute a paradigmatic model for synchronization \cite{kuramoto1975self,acebron2005kuramoto,rodrigues2016the} and have been established as a model for real-world systems like the brain \cite{poncealvarez2015restingstate, cabral2011role, rodrigues2016the}, Josephson junctions \cite{josephson1964coupled, crotty2010josephson}, and chemical oscillators \cite{marek1975synchronization, neu1979chemical}.  The Kuramoto oscillators are phase oscillators coupled through a sine function of their phase differences. Networks with these units are well-known to have a transition from desynchronization (incoherent phases) to frequency synchronization (i.e. phase-locking, meaning constant phase differences \cite{pikovsky2001synchronization}) and to phase synchronization (small phase differences) \cite{rosenblum1996phase} as the coupling strength between units increases \cite{rodrigues2016the, acebron2005kuramoto}. 

In this work, we connect the oscillators in either of two classes of network topologies, which are of theoretical and practical importance \cite{albert2002statistical}: Watts-Strogatz \cite{watts1998collective, humphries2008network, telesford2011the} and distance-dependent \cite{rogers1996phasetransitions, rubinov2015wiring}. They have very distinct properties, but in both a change in the topology from short-range to long-range connections leads to a transition to phase synchronization in the networks \cite{hong2002synchronization, rogers1996phasetransitions}. During the transitions to phase synchronization, when the systems are only partially phase synchronized, they become dynamically malleable (i.e., sensitive to parameter changes), as illustrated in Fig. \ref{fig:sketchmalleability}. 
%
\begin{figure}[htb!]
    \centering
    \includegraphics[width=0.9\columnwidth]{figure1.png}
    \caption{\textbf{Sketch to illustrate the dynamical malleability in a typical transition to phase synchronization}. Each realization of the system's parameters leads to a different transition to synchronization, i.e. a different curve in the figure. Realizations may differ from the others, for instance, in the parameter of a single unit. We see that the transitions to synchronization are different, as both the critical value of the coupling strength and the profile of the transitions differ, with the magnitude of malleability peaking during the transitions. Fixing the coupling strength, we can also look at the distribution of the degree of phase synchronization across samples (purple inset).}
  \label{fig:sketchmalleability}
\end{figure}

Furthermore, we also show that the number of attractors of the Watts-Strogatz networks increases during their transitions to phase synchronization, meaning that these systems also become especially sensitive to perturbations made to their units' states. This goes in line with recent studies for Kuramoto oscillators with identical frequencies \cite{taylor2012there, zhang2021basins, townsend2020dense} and for Kuramoto oscillators with inertia \cite{gelbrecht2020monte}. This increased multistability acts as a dynamical mechanism that can further increase the dynamical malleability. 

Therefore, despite the wide literature and importance of synchronization, this phenomenon we describe of increased sensitivity to parameter changes, with complicated, hard-to-predict consequences to the synchronization, and which can be accompanied by multistability, has so been under-explored in the literature. Although reported sporadically in some recent works \cite{peter2018transition, taylor2016synchronization, fernandez2022emergence, budzinski2019synchronous}, it has not been the focus, and thus has not been fully explored, until now. This becomes especially relevant when we note that the behavior is widespread, extending well beyond the Kuramoto networks studied here, as supported by our observations in a variety of topologies, by similar observations in spiking \cite{budzinski2020synchronization} and bursting \cite{budzinski2019synchronous} neural networks, in cellular automata (which we exemplify in the Supplemental Material), and, importantly, by the statistical physics theory of finite-size effects on phase transitions, which we discuss later in the paper. 

We therefore hope to demonstrate the importance of dynamical malleability, and to encourage further theoretical advancements in this area, which are needed to properly describe the wide range of behaviors and to offer tools for practical applications.  

\section{Methodology}\label{sec:methodology}

In the Kuramoto model \cite{kuramoto1975self, kuramoto1984chemical}, each oscillator is described by a phase which evolves in time according to
%
\begin{equation}
    \Dot{\theta_{i}} = \omega_{i} + \epsilon \sum\limits_{j=1}^{N} A_{ij} \sin{(\theta_{j} - \theta_{i})},
    \label{eq:main_kuramoto}
\end{equation}
%
where $\theta_{i}(t)$ is the phase of the $i$-th oscillator at time $t$, $\omega_{i}$ is its natural frequency, $\epsilon$ is the coupling strength, $N$ is the number of oscillators, and $A_{ij}$ is the $(i,j)$-th element of the adjacency matrix $\bm{A}$. Throughout this work, we initially draw each frequency randomly from a Gaussian distribution with mean $\mu = 0.0$ and standard deviation $\sigma = 1.0$, generating a sequence $\{\omega_{i}\}, i=1,\cdots,N$. Then, different realizations can (i) shuffle these frequencies, generating another sequence $\{\omega_{i}\}_{\mathrm{shuffled}} = \mathrm{shuffle}(\{\omega_{i}\})$; or (ii) switch the frequency of one selected unit to another value $\omega_{\mathrm{new}}$. 

The networks in this work are coupled in a ring lattice of $N=501$ units with periodic boundary conditions, and follow one of two classes of topology. 
The first class is the Watts-Strogatz (WS) \cite{watts1998collective}, which interpolates between regular and random topologies with a parameter $p$, the rewiring probability: at one extreme ($p = 0$), the topology is a $k$-nearest-neighbor lattice. From it, connections are randomly chosen according to the probability $p$ and rewired to another randomly chosen connection. In doing this, the networks have a significant decrease in the mean distance between nodes, but remain very clustered, generating small-world topologies. The other extreme ($p = 1$) is then a random topology. These networks are unweighted, so their adjacency matrix's elements are $A_{ij} = 1$ if $i$ and $j$ are connected, and $0$ otherwise.

The second class of networks follows a distance-dependent (DD) powerlaw scheme, in which any given node receives connections with weights decaying based on the distance to it. Each element of the adjacency matrix is $A_{ij} =\frac{1}{\eta(\alpha) (d_{ij})^\alpha}$, where $d_{ij}$ is the edge distance between oscillators $i$ and $j$, defined as $d_{ij} = \mathrm{min}(|i - j|, N - |i - j|)$, and $\eta(\alpha)$ is a normalization term given by: $\eta(\alpha) = \sum\limits_{j=1}^{N^\prime}\dfrac{2}{j^{\alpha}}$, such that the temporal evolution of the phases can be written as:
% 
\begin{equation}
    \Dot{\theta_{i}} = \omega_{i} + \frac{\epsilon}{\eta(\alpha)} \sum\limits_{j=1}^{N^\prime} \frac{1}{j^\alpha} \left[ \sin{(\theta_{i+j} - \theta_{i})} + \sin{(\theta_{i-j} - \theta_{i})} \right],
    \label{eq:main_kuramoto_powerlaw}
\end{equation}
where $N^\prime = \frac{N-1}{2}$ denotes half the amount of units to which $i$ is connected to (one half of the ring's length, discounting the unit $i$ itself). The equation explores the symmetry in the network to switch the summation across the network to a summation across only half, multiplied by $2$.
The powerlaw decay is thus controlled by $\alpha$, the locality parameter. For $\alpha = 0$, the network is globally coupled with equal weights between every node. As $\alpha$ increases, the weights are redistributed, so that closer units (in terms of edge-distance) have bigger weights. At the extreme of $\alpha \to \infty$, only first-neighbors are connected.

The two classes have similarities: they have topologies dominated by short-range connections at one extreme and by long-range connections at another \cite{skardal2020higher, hong2013link}. They also have differences: the first class is sparsely connected, the other densely; the first has link-disorder (different rewirings lead to different networks), the second does not.  

Integration was performed using the Tsitouras 5/4 Runge-Kutta (Tsit5) method for Watts-Strogatz networks, and an adaptive order adaptive time Adams Moulton (VCABM) method for distance-dependent networks. The integrator method was chosen for distance-dependent networks for increased simulation speed, and results were robust to different integration schemes. All methods used the DifferentialEquations.jl package \cite{rackauckas2016differential}, written in the Julia language \cite{bezanson2017julia}. Additional computational packages used were PyPlot \cite{hunter2007matplotlib} for plotting and DrWatson.jl \cite{datseris2020drwatson} for code management. The code used for simulations is accessible in the repository \cite{rossi2022github}, with the parameters used in the simulations. In particular, the control parameters we used ($\alpha$, $p$ and $\epsilon$) were generated from a uniform distribution in the range of parameters showing interesting behaviors (e.g. the transitions to synchronization), then rounded to five decimal places and used in the simulations (in the case of $p$, the distribution was uniform in the log scale). These values are reported in all figures and text, and we emphasize that no value was chosen specifically by hand: the behaviors we show in the figures are typical of the systems and can be obtained by randomly generating other values for the parameters.

We quantify the degree of phase synchronization of the network through the standard Kuramoto order parameter \cite{kuramoto1975self, kuramoto1984chemical, acebron2005kuramoto}, which is the circular average of the units' phases 
%
\begin{equation}
    r(t) = \frac{1}{N}\left|\sum\limits_{j=1}^N \exp{(i \theta_j(t))}\right|,
\end{equation} 
with $i = \sqrt{-1}$. The quantifier ranges from $0$ to $1$: if $r(t) = 1$, all the phases are the same, and the system is completely globally phase-synchronized; if $r(t) = 0$, each oscillator has a pair that is completely out-of-phase, and the system can be completely globally phase-desynchronized or in a twisted state with units having distinct but linearly spaced phases. We typically describe networks by the temporal average $R \walrus \frac{1}{T} \sum_t r(t)$  of their phase synchronization, with $T$ being the total simulation time excluding transients.
%For finite systems, this quantifier is given by $R \sim 1/\sqrt{N}$ for random phases. 


\section{Results}\label{sec:results}
\subsection{Introduction to dynamical malleability}
The networks we study here, described in Eq. (\ref{eq:main_kuramoto}), follow the basic phenomenology of transitions to synchronization in Kuramoto networks \cite{kuramoto1975self, acebron2005kuramoto}.
For very small coupling strengths $\epsilon$, the oscillators are effectively uncoupled, and the phases oscillate without any significant correlation. As this $\epsilon$ increases, the instantaneous frequencies $\dot{\theta}_i$ align first, and the units' phases become locked, but not aligned: the system becomes frequency but not phase synchronized \cite{pikovsky2001synchronization}. 

Then, whether the phases can align or not depends on the topology \cite{medvedev2014small, hong2002synchronization}. In a two-nearest neighbor lattice, where only four nearby units are connected (two on each side), there is a topological limitation in the spread of interactions across the network that makes the oscillators arrange themselves in shorter-range patterns (Fig. \ref{fig:spatiotemporal}(a)) (an exception might occur if the coupling strength is extremely high, much bigger than the relevant values studied here).
If the short-range connections are randomly rewired to long-range connections, following for instance the Watts-Strogatz (WS) algorithm, the shorter-range patterns give way to longer-range patterns, and the oscillators start to phase synchronize ((b) and (c)), until eventually a strong (though not complete) phase synchronization (PS) is reached (d). This occurs at different stages for each realization: for instance, panels (c) and (k) reach a high degree of PS, with the longer-range patterns, but panel (g) does not. 

In Fig. \ref{fig:spatiotemporal}, the natural frequencies $\{\omega_i\} (i=1,\cdots, N)$ were kept constant across panels (a)-(d). Changing the frequencies, keeping the initial conditions $\{\theta_i(0)\} (i=1,\cdots, N)$ fixed, leads to a different realization (also called sample), with possibly different dynamics. If the frequency of a single unit $\omega_i$ is changed to an arbitrary new value, for instance $\omega_\mathrm{new} = 3$, the network's behavior can be significantly altered (panels (e)-(h)). This is especially the case for networks with intermediate rewiring probabilities $p$, in which this single unit frequency change can bring the network from high to very low phase synchronization (panels (c) to (g)). The instantaneous frequencies typically remain synchronized, though their values might change. For random networks, phase synchronization is always maintained, though the instantaneous frequency values may also change. 
%
\begin{figure*}[htb!]
    \centering
    \includegraphics[width=0.99\textwidth]{figure2.png}
    \caption{\textbf{Transition to phase synchronization and the effect of a single-unit change}. The figure shows the color-coded phases $\theta$ of all oscillators in the network and the degree of phase synchronization $r(t)$ (green line) across time for Watts-Strogatz networks. The coupling strength $\epsilon$ is fixed at $\epsilon = 4.51282$ and the natural frequencies ${\omega_i}$ in the first row are the same, generated by randomly drawing from a Gaussian distribution with zero mean and unitary standard deviation. Networks in the left column are two-nearest-neighbor lattices (rewiring probability $p = 0$); the short-range connections in these networks are then rewired in the following columns, with probability $p = 0.08733$ in the second column, $p = 0.19684$ in the third, and $p = 1.0$ in the fourth (leading to random networks). Increasing the proportion of long-range connections thus leads generally to more phase-synchronized networks.
    In the second and third rows, the natural frequency $\omega_i$ of a single unit $i$ (indicated by the gray arrows) is changed to a new value $\omega_i \to \omega_\mathrm{new} = 3.0$, with all other parameters being kept fixed. The units shown in the figure were those which led to the smallest (second row) or highest (third row) degree of phase synchronization $\meanR$ out of all $N = 501$ units in the network for each value of $p$. Initial conditions were the same for all simulations, and were randomly drawn between $0$ and $2\pi$.
    }
    \label{fig:spatiotemporal}
\end{figure*}

Figure \ref{fig:spatiotemporal} thus illustrates that the long-term dynamics and phase synchronization differ in each realization. The realizations, created by changing the natural frequency of one unit, are distinct dynamical systems, so it is not surprising to observe distinct long-term dynamics. It is, however, interesting to observe how large these changes in dynamics can be, and how they depend on the topology. For instance, in networks of intermediate $p$ (second and third columns of Fig. \ref{fig:spatiotemporal}, the phase synchronization changes drastically. In random networks ($p = 1$, fourth column), they preserve the phase synchronization but alter the instantaneous frequencies of the oscillators (seen in the figure by the number of vertical lines). We also note that the behavior we describe is typical of the systems, and the values of $p$ and $\epsilon$ used here were generated as described in Section \ref{sec:methodology}. Since the fluctuations in the phase patterns (reflected in the phase synchronization) are clearer and more pronounced than the instantaneous frequency patterns, we now focus on the phase synchronization of the networks.

\subsection{Comprehensive view of dynamical malleability}
To obtain a comprehensive picture we now study an ensemble of samples obtained by shuffling the frequencies ($\{\omega_i\}_\mathrm{original} \to \{\omega_i\}_\mathrm{shuffled} = \mathrm{shuffle} \left( \{\omega_i\}_\mathrm{original} \right))$ or by changing the frequency of only a single unit to a new value ($\omega_{i, \mathrm{original}} \to \omega_\mathrm{\mathrm{new}}$). We show in Fig. \ref{fig:transition_sync} the transitions to phase synchronization with increasing coupling strength or with switching from short-range to long-range connections. As expected from Fig. \ref{fig:spatiotemporal} we also find a large dynamical malleability (sometimes simply called malleability) during the transitions. 

We study two classes of topology, Watts-Strogatz (WS, small-world) and distance-dependent (DD), described in Sec. \ref{sec:methodology}. We consider ensembles as collections of networks with fixed coupling strength $\epsilon$ and topology (fixed rewiring probability $p$ or locality parameter $\alpha$) but distinct realizations of the natural frequencies $\{\omega_i\}$ \cite{carlson2011sample}.  Each ensemble in the figure contains $501$ samples (realizations). We present the results using the mean degree of phase synchronization $R$ for each realization, and the gap $\Delta \walrus R_\mathrm{max} - R_\mathrm{min}$ between the most and least phase synchronized realizations in each ensemble. The gap $\Delta$ is chosen simply to illustrate the wide range of $R$ values clearly, and we remark that very similar curves are observed by using the standard deviation over samples.

In Fig. \ref{fig:transition_sync}, thicker lines represent an ``original" sequence of frequencies $\{\omega\}_\mathrm{original}$, from which other realizations (light lines) are created by shuffling all frequencies or changing the frequency of one unit to a new value $\omega_\mathrm{new} = 3.0$. Each sample is a different dynamical system, and has a different transition to phase synchronization, which occurs at different values of $\epsilon$, $p$, or $\alpha$, and with a different profile (some have a small region of desynchronization while others do not, for instance). 

This means that changing samples can lead to large changes in the behavior of the system, as we see throughout Fig. \ref{fig:transition_sync}. First, we study the transitions induced by increasing the coupling strength $\epsilon$ for four representative types of networks (panels (a)-(d)), characterized by four specific values of rewiring probability $p$ and locality parameter $\alpha$.

In the red curves, networks are dominated by long-range connections, with $p = 1$ (random) and $\alpha = 0$ (all-to-all)  and have a complete transition to phase synchronization (reaching $R \sim 1$), with the dynamical malleability (measured by $\Delta$) increasing during the transition and returning to zero after.
The all-to-all case is the finite-size version of the system originally studied by Kuramoto  \cite{kuramoto1984chemical}, and the critical $\epsilon$ values, when the transition occurs in each sample, are close to the $\epsilon_c = \frac{2}{g(0)\pi} = \frac{2\sqrt{2}}{\sqrt{\pi}} \approx 1.596$ predicted in the thermodynamic (infinite network size) limit. Its finite-size scaling properties and behavior have also been studied in \cite{hong2007entrainment, peter2018transition}. It is worth mentioning that this parallel between random networks and all-to-all networks, which have similar phenomenology, has been described in other works. Both have the same scaling exponents, belonging to the mean-field type \cite{skardal2020higher, hong2013link}. 

In the green curves ($p = 0.19684$ and $\alpha = 1.538463$) some connections have been rewired in the Watts-Strogatz networks, and weights redistributed for distance-dependent networks, from long-range to effectively short-range connections. On average, phase synchronization $R$ decreases, though still remaining high. Some samples of WS networks also start to display regions of desynchronization: after the initial transition to high $R$, a further increase in $\epsilon$ can desynchronize them (visible in panels (a) and (c), for $\epsilon$ roughly in $[6,7]$). Therefore, the huge changes in $R$ ($\Delta \sim 0.99$) due to changing samples can be attributed to two effects: the difference in their critical coupling strength (when the transition begins) \cite{hong2006anomalous}, and also in their different post-transition behaviors (such as the desynchronization gaps that occur at different intervals of $\epsilon$.)

In the purple curves ($p = 0.08733$ and $\alpha=1.76923$), even more short-range connections become present. Phase synchronization $R$ on average decreases, while the fluctuations $\Delta$ remain high and occur more evenly spread across samples.

Finally, for cyan curves ($p = 0$, two-nearest-neighbor chains and $\alpha = 3$, close to nearest-neighbor chains), the connections are short-range. Their phase synchronization is much smaller, and they do not reach a high degree of phase synchronization for any value $\epsilon$ we tested.
These networks with short-range connections still have some degree of malleability, but not as high as the previous two cases. 

Returning to frequency synchronization, we mention that for weak coupling strengths (roughly below $\epsilon \approx 3$), most of the samples in any ensemble are not frequency synchronized (see Fig. S3). Above this value, frequency synchronization becomes more common, especially for networks with more long-range connections, such that for sufficiently high coupling all samples become frequency synchronized. This is not the case for networks with mostly short-range connections ($p \lessapprox 0.01$), in which some samples do not reach frequency synchronization even despite strong coupling. The presence of frequency synchronization in the short-range networks is consistent with the literature \cite{strogatz1988phase, acebron2005kuramoto} showing that frequency synchronization in first-nearest-neighbor chains is possible for sufficiently high $\epsilon$ in strictly finite systems. There are therefore also sample-to-sample fluctuations in the frequency synchronization of Kuramoto networks. They occur similarly to the fluctuations in phase synchronization, but are somewhat harder to visualize and have a less interesting dependence on parameters, justifying our focus on phase synchronization in this paper.

We now move to the topology induced transitions, which occur by switching from short-range to long-range connections (varying $p$ and $\alpha$) while keeping the coupling strength $\epsilon$ fixed (Figs. (e-h)). A similar scenario occurs with a transition to phase synchronization, induced by changing either $p$ or $\alpha$. The dynamical malleability increases during the transitions, reaching significant values for both shuffled realizations and single-unit changes. The nearest-neighbor networks show some malleability, while the long-range dominated ones (random or all-to-all) show no malleability. We note here that the transition for WS occurs at $p \sim 0.1$, so we plot the figures on logarithmic scale to show the full transition to synchronization. This transition was already reported for WS networks in \cite{hong2002synchronization}, but the authors used a linear scale for $p$ and missed the full details of the transition that we see here, especially the sample-to-sample fluctuations; for distance-dependent powerlaw networks, a transition in phase and frequency was reported in \cite{rogers1996phasetransitions}. However, none of these references studied the sample-to-sample fluctuations.

We conclude that either shuffling or changing a single unit can significantly alter the behavior of these systems, leading to a large dynamical malleability, in some cases over a very large range of parameters. This is particularly strong for WS networks, reaching $\Delta \sim 0.99$, close to the maximum possible value of $\Delta = 1.0$. The distance-dependent networks have weaker fluctuations, though still significant, reaching up to $\Delta \sim 0.7$.
%
\begin{figure*}[htb!]
    \centering
    \includegraphics[width=0.99\textwidth]{figure3.png}
    \caption{\textbf{Transitions to phase synchronization and dynamical malleability}. Networks under Watts-Strogatz (WS) and distance-dependent (DD) topologies reach phase synchronization through either an increase in coupling strength $\epsilon$ (given the topology has a sufficient amount of long-range connections) or by switching short-range connections to long-range. Fluctuations in the degree of phase synchronization $\meanR$ between samples increase during the transitions, as can be seen by the differences in the same-colored curves and by $\Delta \coloneqq \meanR_\mathrm{max} - \meanR_\mathrm{min}$. Starting from a natural frequency sequence originally drawn from a Gaussian distribution (thicker lines), the other samples (thinner lines) can be generated by shuffling the natural frequencies or by switching the natural frequency of one unit to $\omega_\mathrm{new} = 3$. For intermediate networks (purple and green curves), the increase in the fluctuations (i.e. in dynamical malleability) extends for a wide range of parameters and becomes considerably large. Each panel contains $501 = N$ realizations, with rewiring probabilities fixed for the coupling transition, with values shown in the legend, and coupling strength fixed in the topology transition at $\epsilon = 4.51282$ for WS and $\epsilon = 6.46154$ for DD. The initial conditions are the same across all realizations, and are randomly distributed from $0$ to $2\pi$. The curves of $\Delta$ are qualitatively similar with other dispersion measures, such as standard deviation, a possible difference being that the curves may be slightly shifted, as the measures can peak at slightly different values of the control parameter. We remark that the parameter values used in the simulations were generated as described in Section \ref{sec:methodology} and correspond to the typical behaviors in the system.}
    \label{fig:transition_sync}
\end{figure*}


Furthermore, we note that the networks with intermediate $p$ or $\alpha$ and the short-range networks have dynamical malleability even for high $\epsilon$. This is consistent with the known increase in the fluctuations near a phase transition \cite{ hong2007entrainment, brankov2000theory, hildebrand2007kinetic} because the networks with these parameters remain close to the topology-induced transition.
This is illustrated for WS networks in Fig. \ref{fig:Rsurface}. It shows, in the $p \text{---} \epsilon$ parameter space, the average phase synchronization across samples $\overline{\meanR}$ on the first panel and the dynamical malleability measured by $\Delta$ on the second panel. Figure \ref{fig:Rsurface} provides a comprehensive view on both the coupling strength and the topology-induced transitions. The samples are realized here as shuffles, though a similar figure would be obtained by changing one unit. There is a single region of phase synchronization for sufficiently high coupling strength $\epsilon$ and rewiring probability $p$ (panel (a)). Around the borders of this region, where the system is transitioning, the dynamical malleability is much higher (panel (b)). It then becomes clear that the intermediate networks (green and purple lines), are near the topology-induced transition (for instance, black line) for all $\epsilon \gtrapprox 1$. As $\epsilon$ increases, the networks remain near this $p$-transition, and so their dynamical malleability does not decrease. 
For the regular networks, we first note that the $p$-axis is shown on a logarithmic scale, such that these networks, with $p = 0$, are still relatively close to the transition at $p_c \approx 0.1$, and thus they also present significant malleability.

Figure \ref{fig:Rsurface} also illustrates the existence of two qualitatively different types of transitions: one induced by increasing coupling strength (for sufficiently high $p$), and another induced by increasing $p$ (for sufficiently high $\epsilon$). The difference between both is in their starting points. Both are globally phase desynchronized, but in the former (red, green, and purple lines), the weak coupling strength regimes have mostly uncorrelated oscillators, with no discernible structures in the phases or even synchronization in the frequencies. In the latter (black line), there are shorter-range structures with frequency synchronization for most samples.
%
\begin{figure*}[htb!]
    \centering
    % \includegraphics[width=1.0\textwidth]{figures/figure_1b.pdf}
    \includegraphics[width=0.99\textwidth]{figure4.png}
    \caption{\textbf{Dynamical malleability increases around the regions of transition to phase synchronization.} The surface on the left shows the average degree of phase synchronization $\overline{R}$ across the ensemble ($1000$ realizations of shuffled natural frequencies). The region of high phase synchronization is clearly seen for sufficiently high coupling strength $\epsilon$ and rewiring probability $p$. The colored lines correspond to the parameter values shown in Fig. \ref{fig:transition_sync}. The right panel displays $\Delta$, the difference between the most and least synchronized realizations for each pair $(p, \epsilon$), and we see that the fluctuations from sample to sample increase during the transitions to phase synchronization. The green and purple curves remain close to the region of transition for all $\epsilon \gtrapprox 1$, such that their fluctuations do not decrease with an increase in $\epsilon$. The figure uses Gouraud interpolation to ease visualization by smoothing the curves with a linear interpolation.}
    \label{fig:Rsurface}
\end{figure*}

\subsection{Unpredictability of dynamical malleability}
For Watts-Strogatz networks, samples can be generated by resampling the topology instead of changing the natural frequencies. Since they are generated by a random rewiring process, different realizations generate different networks (there is link-disorder \cite{hong2013link}). Therefore, different samples can also be generated by resampling the network while keeping the natural frequencies fixed. This generates a profile of dynamical malleability similar to that shown in Fig. \ref{fig:transition_sync}(e), where the network was fixed and the natural frequencies were changed (see Fig. S1 for details). 

Now, we wish to illustrate that no network, or natural frequency sequence, is alone responsible for leading to more, of less, synchronized states. Instead, the samples depend sensitively on both, especially in the region of large STS fluctuations. Figure \ref{fig:complexxsensitivity}(a) shows the degree of phase synchronization for different realizations of the networks and different shuffles of the natural frequencies, all for $\epsilon = 4.51282$ and $p = 0.08733$ with fixed initial conditions. To aid the visualization, red rectangles indicate the network with the largest $R$ for each shuffle. No network synchronizes more (or less) for any sequence of natural frequencies; and no sequence of natural frequencies synchronizes more for any network. Furthermore, if the $\epsilon$, $p$, or initial condition are changed, the whole profile of the figure also changes.
%
\begin{figure*}[htb!]
    \centering
    \includegraphics[width=0.99\textwidth]{figure5.png}
    \caption{\textbf{Fluctuations in dynamically malleable systems are unpredictable}. Panel (a) shows the average phase synchronization $\meanR$ for fixed coupling strength $\epsilon = 4.51282$ and rewiring probability $p = 0.08733$ for different $20$ shuffles of the natural frequencies $\{\omega_i\}$ and samples of networks generated by the Watts-Strogatz algorithm. For ease of visualization, the networks are ordered such that the highest network ids correspond to higher synchronization for $\mathrm{Shuffle\;id} = 1$. For each shuffle, the network with the highest $\meanR$ is marked with a red rectangle. We thus see that no network synchronizes more for all shuffles: $\meanR$ is a function of both the specific frequency and topology samples. Panel (b) shows the changes $\delta R$ in the phase synchronization $R$ when the natural frequency of each unit is changed by an amount $\delta \omega$, such that $\omega_i \to \omega_i + \delta\omega$. Other parameters are fixed, in particular $p = 0.1145$ and $\epsilon = 4.51282$. There is a rough threshold (indicated by the black dashed lines), below which changing $\omega_i$ does not significantly alter $R$ ($\delta R < 0.1$ for the figure). Furthermore, changing the frequency does not have a monotonic impact on the change in $R$: small alterations in $\omega_i$, above the threshold, can have the same impact on $R$ as bigger alterations. 
    }
    \label{fig:complexxsensitivity}
\end{figure*}
Another way to illustrate the complicated sensitivity in the region of high sample-to-sample fluctuations is by now fixing the network, and changing the frequency of a single unit by an amount $\delta \omega$. Fig. \ref{fig:complexxsensitivity}(b) illustrates the change $\delta \meanR$ in the phase synchronization, compared to the synchronization of the "original" ($\delta \omega = 0$) frequency realization. There is a rough threshold, at $| \delta \omega | \gtrapprox 0.1$, below which perturbations in one unit do not significantly affect the network's phase synchronization. Above this threshold, however, large changes occur. They are asymmetric on $\delta\omega$ and occur non-monotonically (increasing $|\delta\omega|$ does not necessarily lead to bigger changes). This complicated pattern we observe could make the design and control of these systems quite difficult in practice.

\subsection{Ratio of short to long-range connections}
As we have seen, the rewiring of connections in WS networks, or the redistribution of weights in DD networks, from short-range to long-range connections leads to a transition towards globally phase-synchronized regimes. During these transitions, the dynamical malleability peaks for some ratio of short-range to long-range connections. To quantify this ratio, we first define the short-range connections to/from a node $i$ as all existing connections to/from other nodes $j$ within an edge distance $d$ (with index $j \in [i-d, i+d]$), with $d$ being the range of short connections ($d = 2$ here). For WS networks, we calculate the average degree (number of connections) for short-range ($K_s)$ and long-range connections ($K_l$). For DD networks, we define an analogous measure of topological influence, which is:
%
\begin{align}
    K_\mathrm{s} & \walrus \frac{2}{\eta(\alpha)} \sum\limits_{j=1}^{d} \frac{1}{j^\alpha} \\
    K_\mathrm{l} & \walrus \frac{2}{\eta(\alpha)} \sum\limits_{j=d+1}^{N^\prime} \frac{1}{j^\alpha} .
\end{align}

Note that due to the symmetry of the DD networks, nodes share the same value of $K_s$ and of $K_l$. The ratio $\kappa$ of short-range to long-range connections is then defined as:
%
\begin{equation}
    \kappa \coloneqq \frac{ K_\mathrm{s} - K_\mathrm{l} }{ K_\mathrm{s} + K_\mathrm{l} },
\end{equation}
so that $\kappa = 1$ if only short-range connections exist, and $\kappa = -1$ if only long-range connections exist, with intermediate cases in between. In WS networks, the number of connections is $K = kN$ ($k$ being the amount of neighbors of each node), with the number of long connections approximately $K_l = pK$ and short-range approximately $K_s = (1-p)K$. Therefore, the ratio $\kappa$ can be easily calculated to be approximately $\kappa = 1 - 2p$. For DD networks, the ratio $\kappa$ is given as 
%
\begin{equation}
    % \kappa = \frac{ \sum_{i=1}^d \frac{1}{i^\alpha} - \sum_{i=d+1}^{N^\prime} \frac{1}{i^\alpha} }{\sum_{i=1}^N{^\prime} \frac{1}{i^{\alpha}}  }
    \kappa = \frac{ \sum_{i=1}^d i^{-\alpha} - \sum_{i=d+1}^{N^\prime} i^{-\alpha} }{\sum_{i=1}^{N^\prime} i^{-\alpha}  }.
\end{equation}


Figure \ref{fig:ratioshortlongrange} shows this ratio $\kappa$ calculated for the same setup of Fig. \ref{fig:transition_sync}(e) and (f), shuffling natural frequencies with fixed coupling strength and changing $p$ or $\alpha$. The dynamical malleability is measured here by standard deviation $\chi$ across the samples, instead of $\Delta$. The former makes the figure clearer, but the same analysis also works using $\Delta$. A remark when comparing with Fig. \ref{fig:transition_sync} is that the two measures may peak at slightly different values of $p$ or $\alpha$.  For both types of networks, the malleability peaks when there is a relatively small number of long-range connections present in a short-range-dominated network. It is more extreme for WS, as the ratios are closer to $1$ than in the DD networks. This discrepancy in the ratios leading to higher malleability shows that $\kappa$ is not an universal feature for any topology, but can still be important to understand their behavior.
%
\begin{figure*}[htb!]
    \centering
    \includegraphics[]{figure6.png}
    \caption{\textbf{Dynamical malleability peaks within a narrow interval in the relation of short-range to long-range connections}. Panel (a) illustrates the short-range (blue) and long-range (red) connections from the yellow unit for $d = 2$. Panel (b) shows the sample-to-sample fluctuations in the phase synchronization measured as the standard deviation $\chi$ of the distribution function of $\meanR$ against the ratio $\kappa$ of short-range to long-range connections calculated for several distinct topologies $p$ and $\alpha$. The green curve corresponds to the distance-dependent networks, with $\epsilon = 6.46154$ and 501 realizations per $\alpha$; purple corresponds to Watts-Strogatz networks, $\epsilon = 4.51282$ and 1501 realizations per $p$. The bottom axis show the values of $p$ and $\alpha$ for the respective ticks in $\kappa$ (note that values of $\alpha$ are not equally spaced). }
    \label{fig:ratioshortlongrange}
\end{figure*}

\subsection{Multistability}
So far, we have changed natural frequencies while keeping initial conditions fixed. Now we invert this, and shuffle initial conditions to study the system's multistability. We continue examining phase synchronization (PS) $\meanR$, although we know that $\meanR$ is only a rough measure of multistability. Being a mean value, the same $\meanR$ could represent different attractors. Therefore, the number of attractors estimated based on $\meanR$ can only be considered as a lower bound. To remedy this, we also verified the findings by comparing several other features of the dynamics. These included the standard deviation of PS in time, the PS between each unit and its neighbors, the PS between sections of $100$ units, the time-averaged instantaneous frequencies $\dot{\theta}_i$ of units, and the standard deviation, inter-quartile interval and gap between the unit's instantaneous frequencies. Realizations with unique values of all these features were considered as a distinct attractor. The number of such attractors agrees qualitatively with the dispersion we see in $\meanR$, increasing during the transition.

The phase synchronization is thus shown in Fig. \ref{fig:multistability}. Random networks ($p = 1$, red) are multistable only during their transition to phase synchronization. Intermediate networks ($p = 0.19684$, green; $p = 0.08733$, purple) have a high degree of multistability, meaning coexistence of several attractors, with very distinct degrees of phase synchronization. No shuffle of the initial conditions leads here to the same attractor, so the system has at least $501$ attractors, the number of different realizations tested.
The 2-nearest-neighbor lattice has significant multistability for $\epsilon \gtrapprox 4$. This is consistent with the literature for 1-nearest-neighbors, in which multistability occurs after the transition to phase-locking \cite{tilles2011multistable}. 
% The degree of phase synchronization $\meanR$ is also more separated in the lattices, compared to shuffling frequencies. We can see this also in the distributions, shown in Fig. \ref{fig:Rdistributions}.
%
\begin{figure}[htb!]
    \centering
    \includegraphics[width=1.0\columnwidth]{figure7.png}
    \caption{\textbf{Multistability in WS networks}. Phase synchronization and its dispersion for $501$ different shuffles (thinner lines) of the initial conditions, taken from the original initial conditions (thicker lines) used throughout the rest of this work. All other parameters are fixed, including the natural frequencies as the original frequency distribution. The coupling strength $\epsilon$ (left panel) and rewiring probabilities $p$ (right panel) are the same ones used for WS networks in Fig. \ref{fig:transition_sync}. The multistable behavior is thus very similar to what we observed before by changing the frequencies (Fig. \ref{fig:transition_sync}(a) and (e)), and so shuffling the initial conditions for this network also leads to large fluctuations in the phase synchronization. }
    \label{fig:multistability}
\end{figure}

This multistability can enhance the sensitivity of the system to parameter changes, and help to explain the large fluctuations we observe. In this case, a parameter change needs only to change the boundaries of the basins of attraction for the same initial condition to land on a completely different attractor. Attractors do not have to be necessarily drastically changed for the large dynamical malleability to be observed.
However, multistability is not in principle required for STS fluctuations; in fact, the distance-dependent networks appear to be monostable (not shown), though they are malleable. %Moreover, keeping in mind that any change of parameters or topology leads to another dynamical system, which in general possesses different attractors.

\subsection{Distributions of samples}
As we have seen, shuffling initial conditions can also generate realizations with widely different dynamics, similarly to shuffling natural frequencies. But the two methods to create an ensemble of samples have different effects, and can generate samples with distinct distributions. As shown in Fig. \ref{fig:Rdistributions} for Watts-Strogatz networks, shuffling frequencies leads usually to a broader, and smoother, distribution of $\meanR$. This increased broadness shows that new attractors are indeed created by shuffling the frequencies, so that multistability itself cannot account for the dynamical malleability we discussed previously. Furthermore, the transitions to phase synchronization occur through an increase in the distribution's average. The accompanying increase in the width of the distribution shows an increase in dynamical malleability, which goes to zero only for long-range networks ($p = 1$). 

Specifically, the distributions for the two-nearest-neighbor lattice ($p = 0$, panels (a)-(e)) are quite different: shuffling frequencies leads to a smooth distribution, whose average shifts to the right as $\epsilon$ is increased; for shuffling initial conditions there is also a slight increase in the distribution's average as $\epsilon$ is increased, but the distribution itself is dominated by several peaks. 
For intermediate networks ($p = 0.08733$ and $p = 0.19684$, panels (f)-(o)), the skewness of the distribution becomes negative, and shuffling initial conditions has a smoother behavior, more similar to shuffling frequencies. Interestingly, the distribution can be bi-modal, with the two modes being separated on either extreme of $\meanR$ (panels (n) and (o)). 
For $p = 1$ (random network), the two first coupling strengths (panels (p)-(q)) occur during the narrow interval of significant malleability, during the transition to phase synchronization. Soon after $\epsilon > \epsilon_c \approx 1.6$, the distribution becomes extremely narrow. 
%
\begin{figure*}[htb!]
    \centering
    \includegraphics[width=0.99\textwidth]{figure8.png}
    \caption{\textbf{Distributions of $\meanR$ due to shuffling frequencies or initial conditions.} Each panel contains the distribution of the mean degree of phase synchronization $\meanR$ across 20000 shuffles of natural frequencies (in purple) or initial conditions (orange) for Watts-Strogatz networks. The rewiring probabilities $p$ are indicated on the right of each row, and are the same as used in Fig. \ref{fig:transition_sync}(a); the coupling strengths $\epsilon$ are indicated on the top of each column. Bin size is $0.005$, and the probability for each bin is calculated as the occupation of the bin divided by the total occupation across all bins, and is shown in logarithmic scale.}
    \label{fig:Rdistributions}
\end{figure*}

It is worth mentioning that very similar distributions are obtained if, instead of shuffling the frequencies or initial conditions, we re-sample them from the distribution (i.e. change the seed in the random number generator).
Interestingly, the distributions are not Gaussian, which is inconsistent with the assumptions made in other works \cite{hong2007entrainment, hong2013link}. In these works, the authors argue that the fluctuations must be normally distributed for sufficiently large networks and many samples due to the central limit theorem. This inconsistency is likely generated by the finite size of the networks studied here. Even in all-to-all networks, in which there is no topological disorder, the distributions are not Gaussian for $N=501$. Results (not shown) indicate that the distributions approach Gaussian distributions as $N$ is increased to $5000$. 

\section{Discussions and conclusions}\label{sec:discussion_conclusion}
\subsection{Summary}
In this work, we have studied the sensitivity of networks to changes in their units' parameters or connections, which we call their dynamical malleability, and showed that, near transitions to phase synchronization, this behavior acquires (i) a large magnitude, as changes to single units can radically alter the spatiotemporal dynamics, and (ii) a complicated sensitivity, as no analytical method we have tried was able to satisfactorily describe the changes to the dynamics. Parts of this behavior have been observed in isolation previously \cite{budzinski2020synchronization, taylor2016synchronization, hong2002synchronization, peter2018transition, fernandez2022emergence, budzinski2019synchronous} but this is, to the best of our knowledge, the first work to focus specifically on it and show its full phenomenology. 

To study this concretely, we have chosen ring networks of Kuramoto phase oscillators and connected the units in two distinct classes of topology, Watts-Strogatz (WS) and distance-dependent (DD). We have either changed the frequency of a single unit or changed the frequencies of all units by shuffling (i.e., redistributing) the values of the frequencies across units. The first has allowed us to verify the impact of relatively small changes, which are still not small enough to be described in the linear regime; the latter allowed us to verify the impact of redistributing the values in the network while keeping the distribution of parameters exactly the same, which is helpful for identifying mechanisms for the fluctuations. 

\subsection{Mechanisms for dynamical malleability}
The two classes of topology we used have different characteristics (see Sec. \ref{sec:methodology}) but are similar in that they lead to networks that have two distinct types of transition to phase synchronization: one induced by increasing the coupling strength and another by increasing the dominance of long-range connections. They also have differences, mostly notably that (i) the WS networks acquire a large number of attractors during their transitions to phase synchronization (i.e. become highly multistable), while the DD networks remain with one main attractor (and possible other attractors that would have very small basins of attraction), and that (ii) the WS networks have a larger magnitude of dynamical malleability. We believe that this larger magnitude is caused by two effects: the increased number of attractors and the topology's link-disorder.

Firstly, we remark that the dynamical malleability is manifested in the networks' transitions to phase synchronization in two distinct ways. The first is through diverse onsets of the transition, as different realizations start their transitions at different values of the control parameter. This is the well-known blurriness of phase transitions described in studies of finite-size effects \cite{brankov2000theory, binder1987finite}. This effect is clearly present in both networks (see, e.g., Fig. \ref{fig:transition_sync}(a) and (b)). The second manifestation of malleability is in the post-transition fluctuations, i.e., in the sudden changes of synchronization that occur after the network has seemingly transitioned to synchronization (see, e.g. Figs. \ref{fig:transition_sync}(a) and (c)). This effect is present here mostly in the WS networks, but is also known in other systems of finite size (see, e.g. Figs. S5(b) and (d) for the case of cellular automata). It is caused at least partly by the system's multistability, as increasing the parameter can change the shape of the attractors' basins of attraction, making the same initial condition suddenly go to another attractor. So the WS networks, which have a much larger number of attractors, exhibit this additional effect that increases their malleability, while the DD networks do not.

We further remark that multistability could have an even more pronounced impact on malleability if the basins of attraction were complexly interwoven. Then, even very small changes could lead to significant fluctuations. But this does not appear to be the case in any of the networks we studied, all of which seem to have smooth basin boundaries (Fig. S4) - it is thus noteworthy that the already high dynamical malleability we have described can occur even with smooth basin boundaries. It can even occur in the absence of multistability, as seen in the DD networks.

The second mechanism for the increased malleability in WS networks is their link-disorder \cite{hong2013link}: different realizations lead to different topologies for a same parameter, and we observe a very similar phenomenology by comparing different realizations of these topologies (Fig. S1). This is a source of disorder, and thus, of fluctuations, that is not present in the DD networks. 


\subsection{Mechanisms for the fluctuations}
As we have mentioned, the fluctuations in the malleable networks are also hard to predict. The behavior of the systems is clearly a complicated function that involves the coupling strength, topology, natural frequencies, and initial conditions all together. For instance, we have not found a sequence of frequencies, or a specific network realization, that always leads to more (or less) synchronized networks (Fig. \ref{fig:complexxsensitivity}(a)). Even for fixed frequencies and topology, the most phase synchronized realization changes depend on the initial condition or the coupling strength. Changes in the natural frequency of single units also lead to non-monotonic changes in the network's phase synchronization: the change in frequency can either increase or decrease the synchronization level, depending on the chosen unit, coupling strength, and topology (Fig. \ref{fig:complexxsensitivity}(b)).

As a consequence, we are unable to identify a specific unit, or magnitude of perturbation, that is always responsible for the greatest disruption. That is, no available theory in the literature that we have tried revealed a mechanism for the fluctuations capable of predicting them. This is a surprising result, considering the quality of the available theories, the amount of research and important advancements in the description of networks similar to the ones studied here \cite{peter2018transition, skardal2014optimal, brede2008synchrony, carareto2009optimized}. We believe that this is mainly caused by the networks' multistability, which cannot be handled by some theories, and by the wide range of synchronization patterns. 

The first theory we tried is the synchrony alignment function, which depends on the topology and natural frequencies and was shown analytically to be related to the degree of phase synchronization in the limit of strong synchrony \cite{skardal2014optimal}. It does not work satisfactorily for any dynamically malleable network that we tested. One reason for this is the weak phase synchronization in some realizations, which breaks the assumption of the method. Another, even stronger, reason is that our networks are multistable, such that the relation between the synchrony alignment function and the degree of phase synchronization given by the method cannot be satisfied for all attractors of the system. Indeed, it only worked perfectly in the strongly phase synchronized regime, which is also monostable.

The second theory we tried is due to Peter and Pikovsky \cite{peter2018transition}, who showed in all-to-all networks that different realizations of the natural frequencies synchronize differently depending on the kurtosis of the distribution. This mechanism cannot even be expected to work for the shuffling scenarios we study since they conserve the frequency distributions and thus the kurtosis as well, but we have verified that it also does not work when the units' frequencies are changed. An additional reason why this does not seem to apply in our systems may be in the topologies, which are not all-to-all.

Thirdly, we have tested other measures that have been observed in the literature to correlate to phase synchronization, and they do not work in the malleable networks. These are: (i) the proportion $p_-$ of links connecting nodes with natural frequencies of different signs \cite{brede2008synchrony};  (ii) the correlation $c_\omega$ between the oscillators' natural frequencies, taking into account the connectivity of the network \cite{brede2008synchrony, carareto2009optimized}; (iii) the correlation between natural frequencies and the node's number of connections \cite{skardal2014optimal}; and (iv) the correlation between the average frequency between neighbors of a node and the node's own frequency \cite{buzna2009synchronization, skardal2014optimal}. These results also cannot be expected to work in multistable networks, and indeed did not work in our networks. 


\subsection{Relation to statistical physics and scaling}
As noted previously, there is a relation between our dynamical study here and studies on the statistical physics of networks. The transitions to phase synchronization that we see correspond to non-equilibrium phase transitions \cite{kuramoto1984chemical, peter2018transition}, such that we can connect the dynamical malleability we analyze with the well-known sample-to-sample (STS) fluctuations in statistical physics. These are usually described in finite systems, in which different samples have different statistical properties that lead to distinct phase transitions - the transitions are usually said to be shifted between samples \cite{sornette2006critical, hong2007finitesizescalingpre, hong2007entrainment}, which is one of the mechanisms we described for the malleability.
As seen in these studies, the size $N$ of the system (i.e. the number of nodes) influences the magnitude of the dynamical malleability as well as the interval of parameters in which it occurs. The networks we have presented in the results have $N = 501$ oscillators, and scaling analysis (Fig. S2) reveals that the intervals of high malleability decrease with the size $N$, as expected from other studies. For instance, authors in \cite{hong2007entrainment} describe the range of $\epsilon$ for high malleability as scaling with $N^{-2/5}$ for all-to-all networks. 

For the WS networks, malleability is still significant for even up $N = 5000$ oscillators. Moreover, the maximum magnitude of the fluctuations does not decrease significantly, and networks with $N = 5000$ can still reach $\Delta = 0.9$. This suggests that the malleability gets restricted to a smaller region in parameter space, but might not decrease significantly in magnitude for bigger networks. In the limit of infinite-size networks, it would get restricted to a single line, defining the two types of transitions to phase synchronization, and remain non-zero there. This is consistent with a study in all-to-all networks of Kuramoto oscillators, where this behavior was observed \cite{hong2006anomalous}. In fact, this behavior is well-known for phase transitions with quenched disorder (heterogeneous parameters), when systems are said to be non-self-averaging \cite{wiseman1995lack}.  
In any case, networks of $N = 5000$ units can be regarded as rather large in several real-world applications \cite{peter2018transition}, so the STS fluctuations we describe here occur for a significant range of system sizes.

\subsection{Generality of the behavior}
Additionally, we show that the increase in dynamical malleability is widespread in the parameter space of the systems. Looking at this space, spanned by coupling strength and the parameter controlling the topology, the dynamical malleability remains high over a wide parameter range around the two types of transitions to phase synchronization. In particular, networks with an intermediate amount of long-range connections are highly malleable for any coupling strength $\epsilon$ we tested (e.g. green and purple lines in Fig. \ref{fig:transition_sync}). This is because the topology is fixed, so the networks remain close to the topology-induced-transition even though they are far from the coupling-strength-induced-transition. 

We also remark that the phenomenology we describe also occurs for wide ranges of topology and coupling strength values, for distinct frequency distributions, such as Cauchy-Lorenz (not shown), and for other dynamical models. For instance, previous works on spiking \cite{budzinski2020synchronization} and bursting \cite{budzinski2019synchronous} neural networks have revealed a very similar phenomenology. We also show similar behavior for cellular automata (see Fig. S5). We have observed (not shown) similar behavior in small-world networks generated by adding long-range connections and keeping the short-range ones \cite{newman1999scaling}. Other works have also observed dynamical malleability in Kuramoto oscillators coupled under both human-connectome structural networks and hierarchical-modular networks \cite{buendia2022the, villegas2014frustrated}. 
Additionally, of course, the theory of phase transitions and, consequently, of sample-to-sample fluctuations is known to apply for a variety of distinct systems. 

\subsection{Practical importance of malleability}
The discussions lead to an interesting question: is dynamical malleability good or bad?  On the one hand, large fluctuations can be undesired. For instance, a large fluctuation could take power grids from a phase synchronized regime to a desynchronized one, and lead to blackouts. On the other hand, fluctuations can be desired due to the increased flexibility in the systems. They could be a useful mechanism for adaptation, learning or memory formation in neural circuits. More specifically, an important property of the brain is that it can separately process information from different types of input in segregated areas, and then integrate them all into a unified representation \cite{tononi1994a, tononi1998consciousness, deco2015rethinking}. For this reason, Tononi and colleagues conjectured that the brain needs to have an optimal balance between segregation and integration of areas \cite{tononi1994a}. In this optimal balance, the synchronization between different brain regions needs to fluctuate from low synchronization to high synchronization \cite{fingelkurts2006timing}. Therefore, having a large dynamical malleability can be an advantageous feature, allowing for this high variability to be achieved through small changes in the neurons, e.g. their firing rate, or their connections. There is also interesting evidence for this in \cite{li2009burst}, which reported that high-frequency firing of neurons can drive changes in the global brain state. 

\subsection{Future research and conclusions}
An interesting line of research opened here is to understand ways to quench or to explore the fluctuations between realizations, using the framework we establish here, for practical applications. Another interesting line of research is to consider the effects of noise or time-dependent forcing on malleable systems: since they have a wider range of dynamical states available by changing parameters, a time-dependent change in the parameters, induced by the noise or forcing, can lead to transitions between several different states. The complicated and sensitive dependence on the parameters would mean that even small amplitude changes could lead to drastic fluctuations. 
For the Watts-Strogatz networks, multistability can complicate the dependence on external inputs, and make the effects dependent on the timing of perturbations, as different states, all of which coexist, can react differently to the parameter changes. Understanding these behaviors is important, for instance, in the context of neural systems, where external influences are common and where temporal fluctuations are essential.

Future research is also needed to fully describe the mechanism for the fluctuations between realizations. An interesting possibility could be to extend the synchrony alignment function \cite{skardal2014optimal} to weakly synchronized regimes or to multistable systems. Another promising approach would also be to apply the formalism introduced in \cite{muller2021algebraic,budzinski2022geometry}. A third possibility would also be to use the model reduction method by \cite{hancock2018model}. These would be important theoretical contributions for the understanding of phase synchronization in oscillator networks and for the role of each unit in a network.

To summarize, the increased magnitude and complexity of dynamical malleability shown here is a general phenomenon in finite-size systems that can be expected to occur in real-world systems. 


\section*{Acknowledgments}
We would like to thank Jan Freund and Arkady Pikovsky for helpful discussions. K.L.R. was supported by the German Academic Exchange Service (DAAD). R.C.B. and L.E.M. acknowledge the support by BrainsCAN at Western University through the Canada First Research Excellence Fund (CFREF), the NSF through a NeuroNex award (\#2015276), SPIRITS 2020 of Kyoto University, Compute Ontario (computeontario.ca), Compute Canada (computecanada.ca), and the Western Academy for Advanced Research. R.C.B gratefully acknowledges the Western Institute for Neuroscience Clinical Research Postdoctoral Fellowship. B. R. R. B. acknowledges the financial support of the São Paulo Research Foundation (FAPESP, Brazil) Grants Nos. 2018/03211-6 and 2021/09839-0. The simulations were performed at the HPC Cluster CARL, located at the University of Oldenburg (Germany) and funded by the DFG through its Major Research Instrumentation Program (INST 184/157-1 FUGG) and the Ministry of Science and Culture (MWK) of the Lower Saxony State, Germany.

