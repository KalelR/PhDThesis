\chapter{Introduction}
Consider the unfortunate situation of falling down a mountain. Subject to the inexorable effect of gravity and friction, the hiker will roll down until they reach a certain valley, a spot at which they will finally terminate their unlucky dynamics. This final state is called an attractor of this system's dynamics. Now, consider a landscape like the one in \figref{fig:intro:landscape}. The mountain here has several valleys, separated by peaks. Consider then the even more unfortunate situation of two people falling down a mountain. If they start very close together, on the same side of a peak, they will fall down to the same valley. If, however, they were separated by a peak when the fall started, then they will fall into distinct valleys. Again, each valley is an attrator of the dynamics. The valley of the accident is chosen by the initial condition, where the person was - and how fast they were moving - when they started to fall. All of the initial conditions that lead to the same attractor form a set called the basin of attraction of that attractor. Basins of attraction are typically separated by peaks in the landscape.
%
\begin{figure}
    \centering
    \label{Landscape with valleys and peaks constitutes an example of multistability for an unfortunate falling person.}
\end{figure}


The example of the hiking disaster serves as a good introduction to the notion of multistability - the simultaneous coexistence of different ending states, different attractors, in a dynamical system with constant parameters (note: the mountain landscape does not change in time in the example). This phenomenon is present in a wide variety of notable systems, with potentially important real-world consequences \cite{}. Examples.

The examples in neural networks, epilepsy and power grids highlight the ubiquitous presence of multistability in networked systems - systems formed by the interactions of smaller subunits, such as neurons or electric generators.  Another phenomenon that can coexist with multistability is synchronization \cite{}. In a synchronized network, the different subunits have similar activity - for instance, when individual oscillators with different natural frequencies spontaneously lock into a common frequency \cite{strogtaz2000from}. A famous spectacle is that of synchronized butterflies (or whatever XX). A perhaps more technically relevant example occurs in power grids, in which all the units must have their frequencies synchronized at the same level, such as 50 Hz. Synchronization has also been proposed as an important mechanism in brain circuits, such as for XX. Another example can be found in the flight pattern of fruit flies XX. 

The real-world relevance of such systems has stimulated a lot of research into their dynamics, including multistability and synchronization \cite{}. An approach taken by lots of works has been to study simple models that capture some essential properties of real world systems. A particularly important example, which has become paradigmatic in the synchronization literature, is that of Kuramoto oscillators (see Sec.\ref{method:kuramoto}). They constitute quite a beautiful example of how units with very simple dynamics can generate complex behavior when interacting together. Each unit in the model is described by a phase (angle) variable that by itself just varies linearly according to its own natural frequency. The interesting dynamics comes from the nonlinear coupling, done via the sin of the phase difference between couple units, cf. \eqref{eq:kuramoto}. The model is simple enough to allow for analytic treatments \cite{} but still complex enough to show relevant dynamics. In particular, it displays a continuous phase transition from desynchronization to synchronization - roughly, if the natural frequencies are spread too widely compared to the coupling between them, the units oscillate incoherently; if instead the coupling becomes large enough, the units start to oscillate with the same frequency - they become phase locked. 

The Kuramoto model is also generic in the sense that it can be derived as an approximation of general limit cycle oscillators under weak coupling. In this case, one considers units that oscillate on limit cycle, which are isolated periodic orbits (cf. secXX). Then, one considers that the coupling between the units is weak enough that their amplitude is not significantly affected, only the phase along the limit cycle. Then, the interplay between the differences in frequency and the coupling determines the time evolution of the phases. The Kuramoto model is a somewhat more specific case of this phase reduction, in that one chooses a purely sinusoidal coupling \cite{}. Still, the combination of simplicity and complexity leading to a synchronization transition, and this argument of genericity, incited a lot of research \cite{} and inspired new concepts.

This inspired us to translate results we had from spiking neural netorks \cite{budzinski2023malleability}. In those networks we described a phenomenon we called \textit{dynamical malleability}: the sensitivity of a whole network's dynamics to changes in parameters of single components, usually changes in parameters of single units. Similarly to the Kuramoto oscillator networks, the spiking neural networks we studied also presented a transition to synchronization, in particular to phase synchronization, when the coupling strength was increased. They also presented a transition to synchronization as the topology changed: as the network topology was altered from $k$-nearest neighbors to random, the neurons also started to synchronize their phases. In both of these transitions, we showed that the network's dynamical malleability increased considerably. Going then to Kuramoto networks with heterogeneous frequencies, we showed that not only does this phenomenology generalize, but that it also occurs very strongly in those networks. Changing the parameter of a single unit can drastically alter the behavior of the whole network in a very sensitive manner \cite{}. 

In the literature for Kuramoto oscillators we found some works related to this. In a series of papers, Hong and colleagues studied this phenomenon from the point of view of statistical mechanics, where dynamical malleability is often called sample-to-sample (STS) fluctuations; there, they say that the STS fluctuations increase near a phase transition. Changing the parameters of a single unit leads to a different network, which is termed to be a different sample. In this case, one shows that the finite size of the networks leads to only to an approximate phase transition, whose critical parameter varies depending on the sample. These studies however, did not look closely at the dynamics of these finite networks. One work that looks at this more closely for all-to-all topologies was \refref{peter}, where they propose that the kurtosis of the natural frequency distribution correlates with the critical coupling strength of the transition - so changing frequency of units changes the kurtosis and thus changes this critical coupling strength. However, they did not explore how this also interacted with more complex topologies. As we then showed in our work, their mechanism alone does not explain the malleability we describe. One can compare networks with shuffled natural frequencies, which keeps the kurtosis constant, but still leads to high malleability. This malleability does come in part from the sample-to-sample fluctuations described for instance in works by Hong et al. \cite{hong2007prl}. But it also comes from multistability, which is another behavior we then analyzed. 

The emergence of multistability as a function of the coupling strength and topology for these networks was another contribution from our work. We showed a coexistence of a large number of attractors at the transition to phase synchronization, which collaborated to increase the malleability, which, to our knowledge, was new in the literature. Gelbrecht et al. had shown this behavior for second-order Kuramoto oscillators under a random topology, but did not study it in depth, and did not look at its dependence with the topology \cite{}. Multistability has been studied in detail under difference circumstances for Kuramoto oscillators, however. One important example occurs when the oscillators are identical (homogeneous frequencies) and are coupled in $k$-nearest-neighbor topologies. In these cases, the networks can have multipled stable equilibria, each being characterized by neighboring units having a fixed and constant phase relationship $\delta \theta = 2\pi/N$. These equilibria are called twisted states \cite{}, and their stability depends on the relationship between the number of nearest neighbors $k$ and the size $N$ of the network \cite{wiley}.

Also results on changing the topology in this case \cite{sparseonesthatdo}. These results also rely on nice properties of these systems, in particular that they can be written as gradient. If we make the frequencies heterogeneous again the problem becomes harder, as attractors can be more complicated than equilibria. There have been studies on multistability for a related Kuramoto model, which has an inertial term \cite{gelbrecht2020monte, multistabilitythorughlossycouplinghellman}. There are studies on effect of topology for first order on the dynamics (paper by klaus). But we are unaware of any systematic study on the emergence of multistability and effect of changing topology, in particular for first order Kuramoto.

Their emergence is understood but even in this simple case there are still open questions, such as dealing with the properties of these attractor's basins. The attractors in networks we study, with heterogeneous frequencies and complex topologies, are not only equilibria; they also can display quasiperiodic and chaotic dynamics XX. Inspired by this, we started to work more deeply into understanding how exactly these attractors emerge and how they share the state space. This is subject for future work, but its basis is found in our study on malleability. In general, therefore, our work served to bridge two gaps in the Kuramoto literature: the dynamics of malleability, and how sensitive networks can be, and that of multistability. 


Multistability is also present in other types of networks. In particular, during my PhD we started to study multistability in a network of coupled bursting neurons. Hindmarsh-rose, chaotic saddle. With this, we boiled the behavior down to a simpler system of excitable neurons coupled diffusively. To this line of investigation on multistability there is also a confluence of another line of research, into diffusive coupling in excitable systems. Starting with Turing XX. Then go to explain our results on . These types of studies require efficient and reliable algorithms to  identify the coexisting attractors of a system. To this end, I teamed up with XX to multistability chaos paper.


The multistability in excitable neurons is remarkable because stable states arise from the interaction with transient behavior (the excitations). Often in the literature we are too preocupied with the final state of the system - usually justifiably so - but anyone who asks the falling hikers in our initial example will probably find out that transients are not so easy to disregard. The excitability case is one example of this, but there are more. Trapping in chaotic saddle. Transients for computations. Multistable perception, binocular rivalry: transients in multistable system. An example of a phenomenon known as metastability. Highly studied, poor conceptual framework. Mechanisms important but sparse in literature. General conceptual framework lacking. To address this, we have organized metastability paper. 


Taking all of this together, my PhD has been a journey into studying the long-term and the transient dynamics of networked systems - how multistability can emerge and how it affects their robustness - and how long transients (metastability) can arise. Along the way I also collaborated to provide open-source code to the community. And also have left several possible paths to be explored in the future. In particular, multistabiltiyi in Kuramoto, paper on HR, burying attractors with Ulrike, effect of topology on excitable networks. And metastability, ghost states, computations. This thesis describes this journey and will hopefully reflect the excitement of doing the research - and hopefully maybe hide some of the eventual frustrations normal to research. In \chapref{chap:methodology} I introduce in greater depth the fundamental concepts needed for the studies performed here. These will then follow in Chaps 3-5 in the same order introduced here. Finally, I will take all of these results together and reflect on what we learned, what our contributions have been to the literature, and the open questions that lie ahead in the future in \chapref{chap:conclusions}. 
