\chapter{Methodology}\label{chap:methodology}

\section{Basics of dynamical systems theory}

\subsection{Dynamical systems and the uniqueness and existence of their solutions}
In this thesis we study dynamical systems described by a state variable $x = (x_1, x_2, \ldots, x_n)^T \in M $, where $M \subseteq \mathbb{R}^n$ is the state space, and $T$ denotes the transpose operation. The state variable is a point in this n-dimensional state space. In a continuous-time dynamical system, the state evolves according to the equation:
%
\begin{align}
    \dot{x}(t) = f(x(t)),
    \label{eq:general-ds}
\end{align}
%
% where $f:M\to M$. Systems obeying Eq.~\ref{eq:general-ds} are deterministic: there is no randomness, no stochasticity, no noise. This means that, starting from one single state at time $t$, we can in principle describe the whole past and future evolution of the system. Furthermore, there is a lack of an explicit time dependence in $f$ - i.e., $\frac{\partial f_i}{\partial x_j} = 0 \; i,j=1, \ldots, n$. In this case, the dynamical system is said to be autonomous. 
where $f:M\to M$. Systems obeying Eq.~\ref{eq:general-ds} are deterministic: there is no randomness, no stochasticity, no noise. This means that, starting from one single state at time $t$, we can in principle describe the whole past and future evolution of the system. Furthermore, there is a lack of an explicit time dependence in $f$ - i.e., ${\partial f_i}/{\partial t} = 0$ for $i=1, \ldots, n$. In this case, the dynamical system is said to be autonomous. 

To obtain solutions to system \ref{eq:general-ds} we need to provide one state, which we typically call an initial condition $x_0 = x(0) \in M$. The combination of $\dot{x} = f(x)$ with $x(0) = x_0$ defines an initial value problem. A fundamental theorem makes our lives studying this problem much easier. This is the theorem of existence and uniqueness of solutions. For $x \in \mathbb{R}^n$ and $f:\mathbb{R}^n\to\mathbb{R}^n$, it requires that $f$ is continuous and that all of its partial derivatives $\partial f_i / \partial x_j$, for $i, j = 1\ldots n$ are continuous in some open connected set $D \subset \mathbb{R}^n$. This basically means that it requires our function $f$ to be sufficiently smooth. Then, for initial conditions $x_0 \in D$, the initial value problem has a solution $x(t)$ on some time interval $(-\tau, \tau)$ about $t=0$, and the solution is unique! \cite{strogatz2002nonlinear} 

In state space, each solution describes a trajectory, a path, that goes through its initial condition $x_0$. The uniqueness of solutions implies that, within this time interval $(-\tau, \tau)$, different trajectories do not intersect in state space. This is a crucial property underlying all systems we study. 

A useful notation for the evolution of a continuous dynamical system is through the evolution operator $\Phi^t(x)$, which, informally defined, evolves the point $x$ forward $t$ time units. That is, $\Phi^t(x(0)) = x(t)$.

\subsection{The fate of linear dynamical systems}\label{method:linear-system}
Although trajectories do not cross, they can share the same fate, meaning they can converge to the same region in state space. We can introduce this notion with a very simple mathematical example of a linear system. It has the form
% 
\begin{align}
    \dot{x}(t) = A x(t),
    \label{eq:linear}
\end{align}
%
with $A$ a constant $(n \times n)$ matrix. If the eigenvalues $\lambda_i \in \mathbb{C}$ of $A$ are all unique ($i = 1, \cdots, n$), its eigenvectors $v_i \in \mathbb{R}^n$ are linearly independent. Then, the general solution to this system can be written as Ref.~\cite{strogatz2002nonlinear}:
%
\begin{align}\label{eq:solution-linear}
    x(t) = \sum_{i=1}^n C_i e^{\lambda_i t} v_i.
\end{align}
%
Each initial condition determines the constant coefficients $C_i \in \mathbb{R}$. 
From \eqnref{eq:solution-linear} we can already notice that the origin of the system, $ o = (0, \ldots, 0)^T$, is a solution. In fact, it is an equilibrium: $\dot{x} = f(o) = o$. A trajectory on the origin does not change over time.

As we see from \eqnref{eq:solution-linear}, the behavior of trajectories depends on the eigenvalues $\lambda_i$ of the matrix $A$. We can classify the equilibrium at the origin based on these eigenvalues, as shown in \figref{fig:method:equilibria-linear}. If the real parts of all the eigenvalues are negative, then all trajectories in state space converge to the origin as $t \to \infty$. In this case, the origin is said to be a stable equilibrium (Figs.~\ref{fig:method:equilibria-linear}A-B). If at least one eigenvalue is positive, the trajectories diverge from the origin, which is then an unstable equilibrium (Figs.~\ref{fig:method:equilibria-linear}C-E). Stability here refers to the behavior of trajectories near the equilibrium. If it is stable, nearby trajectories converge to the equilibrium - or, equivalently, small perturbations that take a trajectory away from the equilibrium will eventually go back to the equilibrium. If it is unstable, then nearby trajectories diverge from it.


Stable equilibria are the only attracting solutions, or attractors, of linear systems. In this case, although different trajectories cannot not intersect, they all converge to the origin as $t \to \infty$. %This origin itself has no dynamics: the trajectory starting at the origin does not move. For this reason we say that the origin, the attractor in this system, is invariant: the set $\{o\}$ flows onto itself.  
In summary, the ultimate fate of linear systems is kind of boring: either trajectories end up at the origin or they diverge off to infinity. But the journey, the path that trajectories take before the end, the \textit{transient dynamics}, is more interesting. As shown in Fig. \ref{fig:method:equilibria-linear}, this is dictated by the constellation of eigenvalues $\lambda_i$. For more details, the reader can refer to standard books on linear/nonlinear dynamics, such as Ref.~\cite{strogatz2002nonlinear}. 
%
\begin{figure*}
    \centering 
    \includegraphics[width=\textwidth]{equilibria-linear/hyperbolic-eq-2d.png}
    \caption{\textbf{Hyperbolic equilibria in 2D linear systems}. The title specifies the number of eigenvalues that are purely real negative $r_-$ or positive $r_+$, or that are complex with real part negative $c_-$ or positive $c_+$. The first row shows equilibria whose eigenvalues are purely real, while the second one shows equilibria with complex eigenvalues. In the first column, the equilibria are stable - they are the two possible attractors in linear systems. In the second column, we have a saddle-point for purely real eigenvalues. In the third column, the equilibria are completely unstable, known as repellers.  }
    \label{fig:method:equilibria-linear}
\end{figure*}




\subsection{The fate of nonlinear dynamical systems I: attractors}\label{method:nonlinear-I}
As just seen, stable equilibria are the only possible attractors in linear systems. Going beyond \eqnref{eq:linear}, nonlinear systems can have more interesting and complicated long-term dynamics (Fig.~\ref{fig:method:attractors-nonlinear}). Stable equilibria are still possible, as shown in Figs.~\ref{fig:method:attractors-nonlinear}A-B. We use for those figures the conductance-based neuronal model we use in \chapref{chap:multistability}, following equations \cite{izhikevichbook}
%
\begin{align}
    &\dot{x} = \big(I - g_L (x_i - E_L)  
    - g_{Na} m_\infty(x_i) (x_i - E_{Na}) 
    -g_K y_i (x_i - E_K) \big)/C, \notag\\
    &\dot{y} = (n_\infty(x) - y_i) / \tau,
    \label{eq:inapk}
\end{align}
%
with all parameters and functions defined in detail in \chapref{chap:multistability}. The input current $I$ is chosen to be $I=2.0$, so that the system has excitable dynamics. Its state space is composed of a stable equilibrium, the only attractor, and two unstable equilibria, which create the excitability in this case. Excitability is a type of transient different from that seen for linear systems. Some trajectories are forced to go on long excursions (excitations) before converging to the stable equilibrium. We study more about this again in Chapter \ref{chap:multistability}.

Besides equilibria, nonlinear systems can also have periodic solutions. These orbits oscillate in time and repeat after a certain period $T$ (Fig.~\ref{fig:method:attractors-nonlinear}D) and correspond to closed curves in state space (Fig.~ \ref{fig:method:attractors-nonlinear}C). In several cases these periodic solutions are isolated, in the sense that there are no other periodic orbits in some neighborhood around them. In that case, they are called limit cycles.
The system used in this example is still the neuronal model of \eqnref{eq:inapk}, but with a different parameter $I=6.0$, which leads to the system now having a stable limit cycle. We see in this figure again an example of a long transient, with the trajectory initially going on a long excursion before converging to the limit cycle.
%
\begin{figure*}[htb!]
    \centering 
    \includegraphics[width=\textwidth]{attractors-nonlinear/attractors-nonlinear.png}
    \caption{\textbf{Basic types of attractors in nonlinear dynamical systems}. Each column shows respectively the state space and a time-series of a typical trajectory converging to a type of attractor. The first column corresponds to the neuronal model of \eqnref{eq:inapk} with $I=2.0$, which has excitable dynamics, converging to a stable equilibrium. The second column shows again the neuronal system of \eqnref{eq:inapk} but with $I=6.0$, when the attractor is now a stable limit cycle. The third column shows the system defined in Eqs.~\ref{eq:vanderpol}, with a quasiperiodic attractor. Finally, column four has an example of a chaotic trajectory on the Lorenz system (\eqnref{eq:lorenz}).}
    \label{fig:method:attractors-nonlinear}    
\end{figure*}

Not all curves in state space are closed, however. One can have quasiperiodic dynamics, in which trajectories never repeat exactly, although they might almost repeat. This is seen in Figs.~\ref{fig:method:attractors-nonlinear}E-F. Simulating the trajectory for longer times would fill up the figure more and more. Further, note the varying amplitude of the time series. The system in this example is the forced Van der Pol oscillator
%
\begin{align}
    &\dot{x} = v \notag\\ 
    &\dot{v} = \mu (1-x^2)v - \alpha x + g \cos(\omega_f t),
    \label{eq:vanderpol}
\end{align}
with parameters $\mu=0.1$, $\alpha=1.0$, $g=0.5$, $\omega_f=\sqrt{3}$ taken from \refref{shukla2014a}.

Finally, one can also have chaotic attractors (Figs.~\ref{fig:method:attractors-nonlinear}G-H). These solutions have a wild behavior that nearby trajectories tend to diverge at an exponential rate \cite{argyrisbook}. Despite this local divergence, however, the solutions remain bounded in space. 
In other words, systems with chaotic attractors are very sensitive to the initial conditions - small changes in initial conditions lead to trajectories that can look very different.  
% % Moreover, a chaotic attractor typically has a dense set of unstable periodic orbits embedded within it. These periodic orbits form the skeleton of the chaotic dynamics \cite{scholarppedia}
% The geometric structure of the solutions is very complicated, so proper rigorous analysis are often too difficult to perform. One important result, following the Poincaré-Bendixon Theorem, is that chaos is only possible in flows of dimension $3$ upwards (for maps, dimension $1$ already suffices) \cite{glendinning_1994, strogatz_2018}.
The system used to generate the example is known as the Lorenz system, with equations 
%
\begin{align}
    &\dot{x} = \sigma (y-x) \notag\\ 
    &\dot{y} = x(\rho-z) - y  \label{eq:lorenz} \\
    &\dot{z} = xy -\beta z, \notag
\end{align}
and $\sigma = 10$, $\rho = 28$, $\beta = 8/3$. This chaotic attractor in particular has a shape that resembles a butterfly, with trajectories spending some time on one wing before switching to the other wing \cite{argyrisbook}. 

Given now these examples, let us now define the terms we have used a bit more properly. 

% 
\subsection{Formalizing attractors and basins}\label{method:attractors-formal}
We have just presented examples of attractors, sets of points in state space to which trajectories eventually converge, and their basins of attraction, the regions containing those converging trajectories. Since in this thesis we will deal a lot with these concepts, we formalize them better. The idea is to have the concepts clear in mind for later. In particular, the definition of an attractor can vary considerably in the literature. Without attempting to claim any superiority, we attempt here to provide a definition that suits our studies.  

% As mentioned before, there are regions in state space wherein trajectories converge to a single common attractor. These are known as the basin of attraction $\mathcal{B}(A)$ of that attractor $A$. A common and intuitive mathematical definition of a basin is given in Ref.~\cite{milnor1985on}, which depends on the concept of the omega limit set $w(x)$ of a point $x$. The $\omega$-limit set of a point $x_0 \in M$ is defined as 
First, we define an $\omega$-limit set $\omega(x)$ of a point $x_0 \in M$ as \cite{milnor1985on}: 
% 
\begin{equation}
    \omega(x_0) = \{x: \forall\,T \;\forall \epsilon > 0\; \text{there exists } t > T \text{ such that } |\Phi^t(x_0) - x| < \epsilon    \}.
\end{equation}

Consider a point $x \in\omega(x_0)$ in the $\omega$-limit set of $x_0$. Then, by definition, a trajectory that passes through $x_0$ comes arbitrarily close to $x$ infinitely often as $t$ increases. 

From this, we can define the \textit{basin of attraction} of a set $A$ as $\mathcal{B}(A) = \{x \in M: \omega(x) \subset A\}$. This only looks at the long-term behavior of trajectories; the transient dynamics could be anything, including the case that trajectories go very far from $A$, as long as they go back to it. 
% If $\rho(A)$ is a smooth manifold but its dimension is smaller than the dimension of the state space $M$, then it simply the stable manifold of $A$ \cite{milnor1985on}.


% \subsection{Milnor attractor}\label{fundam:ssec:milnor-attractor}
Now to define an attractor, we first define a weaker (or, on the more optimistic side, a more general) version, called the \textit{Milnor attractor}. A set $A$ is a Milnor attractor if:
\begin{enumerate}
    \item Its basin of attraction $\mathcal{B}(A)$ has strictly positive measure (i.e., if $m(\mathcal{B}(A)) > 0$ ), where $m(S)$ denotes a measure equivalent to the Lebesgue measure of set $S$ \cite{milnor1985on}. This condition says that there is some probability that a randomly chosen point will be attracted to $A$ \cite{milnor1985on}.
    \item For any closed proper subset $A^\prime \subset A$, the set difference $\mathcal{B}(A) \setminus \mathcal{B}(A^\prime)$ also has strictly positive measure. This ensures that every part of $A$ plays an essential role - one cannot decompose $A$ into an attracting part and another part that does not attract \cite{milnor1985on, taylor2011attractors}. A closed set here means that it contains all its limit points. And proper means its non-empty.
\end{enumerate}

Furthermore, the Milnor attractor does not have to attract all the points in its neighborhood, and there can also be orbits that transiently go very far from the attractor, even if initially close, before eventually getting close to it. Further, it can in principle be composed into the union of two smaller Milnor attractors. To avoid these cases, we call a set $A$ an \textit{attractor} if
%
\begin{enumerate}
    \item $A$ is a Milnor attractor.
    \item $A$ contains an orbit that is dense in $A$. Basically, this means that the there is an orbit in $A$ that passes arbitrarily close to every point in $A$. This condition ensures that the attractor is not the union of two smaller attracting sets \cite{taylor2011attractors}. %It also ensures that orbits cannot escape from the attractor once they are in.
    \item There are arbitrarily small neighborhoods $U$ of $A$ such that $\forall x \in U$ one has $\Phi^t(x) \subset U  \; \forall t>0$ and such that $\forall y \in U$ one has $\omega(y) \subset A$. That is, there are arbitrarily small neighborhoods around the attractor in which points inside stay inside and converge to $A$. This criterion is given in Ref.~\cite{broer2011dynamical}.
\end{enumerate}

\subsection{Invariant manifolds: structures that organize state space}\label{method:invariant-manifolds}

In Sec.~\ref{method:linear-system} we only saw how the eigenvalues of the matrix $A$ in the linear system $\dot{x} = A x$ shape the dynamics of the system. If one eigenvalue $\lambda_k$ is positive, then trajectories will diverge to infinity following the corresponding eigenvector $v_k$. When some eigenvalues are positive and some are negative, the origin is a saddle-point. If all eigenvalues are positive, it is called a repeller.
Figure \ref{fig:method:equilibria-linear} shows examples of equilibria in 2D linear systems. Note how, in panel C, typical trajectories approach the saddle-point along the $x$-axis and then diverge along the $y$-axis. That is, for $t \to -\infty$, trajectories converge to the $x$-axis and for $t \to \infty$ they converge to the $y$-axis. The $x$-axis is called the stable manifold $\mathbb{W}^s(o)$ of the origin $o$ and the $y$-axis is the unstable manifold $\mathbb{W}^u(o)$ of the origin. We can define these manifolds
\begin{align}
&\mathbb{W}^s(o) = \{x \in M: \Phi^t(x) \to o \;\mathrm{as}\; t\to\infty\}, 
&\mathbb{W}^u(o) = \{x \in M: \Phi^t(x) \to o \;\mathrm{as }\; t\to -\infty\}.
\end{align}

Let us separate the eigenvectors $v_i$ into two parts: the ones with negative eigenvalues $v^-_1, \ldots, v^-_{n_s}$ and the ones with positive eigenvalues $v^+_1, \ldots, v^+_{n_u}$ . Then we can define the stable and unstable subspaces, respectively, as 
%
\begin{align}
    &\mathbb{E}^s = \mathrm{span}(v^-_1, \ldots, v^-_{n_s})
    &\mathbb{E}^u = \mathrm{span}(v^+_1, \ldots, v^+_{n_u}).
\end{align}

For a linear system, the stable manifold of the origin coincides with the stable space $\mathbb{E}^s$ and the unstable manifold coincides with the unstable space.  In general, as in the example of the saddle-point, these manifolds act to organize the behavior of trajectories in state space.


These concepts can be extended for nonlinear systems. To do this, the first step is to think about the linearization of the nonlinear system. Suppose our nonlinear system of interest has an equilibrium $x^\star \in M$. It turns out that the behavior sufficiently close to this equilibrium is linear, despite the system globally being nonlinear \cite{saletan, glendinning}! To see this, we first move the origin of our system to $x^\star$ by defining a new variable $y(t) = x(t) - x^\star$. Then, 
%
\begin{align}
    \dot{y} = \dot{x} = f(y+x^\star) \equiv g(y)
\end{align}

where we define a convenience function $g(y)$. Expanding $g(y)$ around $y=0$ (i.e., around the equilibrium $x(t) = x^\star$) gives us 
%
\begin{align}
    \dot{y} = g(0) + J_g(0) y + \mathcal{O}(y^2),
\end{align}

where $J_g(y) = \frac{\partial g_i(y)}{\partial y_j}$ is the Jacobian of $g$. It is related to the Jacobian of $f$ by $J_g(y) = J_f(x)$, so $J_g(y=0) = J_f(x=x^\star)$. Since $g(0) = f(x^\star) = 0$, then if we are sufficiently close to the origin we can also ignore the terms $\mathcal{O}(y^2)$ and therefore we get 
%
\begin{align}
    \dot{y} = J_g(0) y.
\end{align}

That is, the behavior of the nonlinear system sufficiently close to the equilibrium is linear, with the constant matrix function being the Jacobian evaluated at the equilibrium! 

But the good news don't stop here! There is the Hartman-Grobman theorem, which states that the state space near a hyperbolic equilibrium in the nonlinear system is topologically equivalent to the state space of the linearized system. An equilibrium is hyperbolic if the eigenvalues of the Jacobian evaluated on it are all nonzero, i.e., if $\lambda_i \neq 0 \forall i=1,\ldots,n$. \textit{Topologically equivalent} means that the linearized state space and the local state space near the equilibrium are distorted versions of each other. They can be bent and warped, but not ripped. In particular, closed orbits have to remain closed, and connections between saddle points have to remain \cite{strogatz2002nonlinear}. Mathematically, topologically equivalent means there is a \textit{homeomorphism} (continuous deformation with continuous inverse) from one state space into the other; trajectories can be mapped from one to the other, and the direction of time is the same \cite{strogatz2002nonlinear}. 

Stating the theorem more formally, suppose a hyperbolic equilibrium $x^\star \in M$ such that $f(x^\star) = 0$ and such that all its eigenvalues are nonzero. Then, there is a neighborhood $N$ of $x^\star$ and a homeomorphism $h: N\to M$ such that \cite{argyrisbook}
\begin{itemize}
    \item $h(x^\star) = 0$,
    \item the flow $\dot{x} = f(x)$ in $N$ is topologically conjugate to the flow of the linearization $\dot{y} = A y$ by the continuous map $y = h(x)$. Topologically conjugate basically meaning a change of coordinates.
\end{itemize}

This guarantees that the stability of the equilibrium is the same in both cases, so we can use the linearization to gain important insights about the stability of equilibria in the nonlinear system! 

What about the stable and unstable manifolds? In analogy to the linear case, we can define local stable and unstable sets near a neighborhood $U$ of an equilibrium $x^\star$ for the nonlinear system \cite{argyrisbook}:
% 
\begin{align}
&\mathbb{W}^s_\mathrm{loc}(x^\star) = \{x \in M: \Phi^t(x) \to x^\star \;\mathrm{as}\; t\to+\infty\  \mathrm{and}\; \Phi^t(x) \in U \;\forall t \geq 0\}, \\
&\mathbb{W}^u_\mathrm{loc}(x^\star) = \{x \in M: \Phi^t(x) \to x^\star \;\mathrm{as }\; t\to -\infty\ \mathrm{and}\; \Phi^t(x) \in U \;\forall t\leq 0 \}.
\end{align}

Herein comes the stable manifold theorem. It states that, for a hyperbolic equilibrium $x^\star$:
\begin{itemize}
    \item The local stable set $\mathbb{W}^s_\mathrm{loc}(x^\star)$ is a smooth manifold whose tangent space has the same dimension $n_s$ as the stable space $\mathbb{E}^s$ of the linearization of $f$ at $x^\star$. $\mathbb{W}^s_\mathrm{loc}(x^\star)$ is also tangent to $\mathbb{E}^s$ at $x^\star$.
    \item The local unstable set $\mathbb{W}^u_\mathrm{loc}(x^\star)$ is a smooth manifold whose tangent space has the same dimension $n_u$ as the unstable space $\mathbb{E}^u$ of the linearization of $f$ at $x^\star$. $\mathbb{W}^u_\mathrm{loc}(x^\star)$ is also tangent to $\mathbb{E}^u$ at $x^\star$.
\end{itemize}

The homeomorphism guaranteed by the Hartman-Grobman theorem maps $\mathbb{W}^s_\mathrm{loc}(x^\star)$ into $\mathbb{E}^s$ and $\mathbb{W}^u_\mathrm{loc}(x^\star)$ into $\mathbb{E}^u$ one-to-one, as shown in \figref{fig:method:invariantmanifolds}. Further, the stable manifold theorem guarantees that $\mathbb{E}^s$ and $\mathbb{E}^u$ actually approximate the local manifolds $\mathbb{W}^s_\mathrm{loc}(x^\star)$ and $\mathbb{W}^u_\mathrm{loc}(x^\star)$, respectively \cite{argyrisbook}. As a consequence, we get the behavior illustrated in \figref{fig:method:invariantmanifolds}

The manifolds we just looked at are defined for a local neighborhood $U$ around the equilibrium. We can extend them towards the whole of state space by defining global manifolds as:
\begin{align}
    \mathbb{W}^s(x^\star) = \bigcup_{t\leq 0} \Phi^t(\mathbb{W}^s_\mathrm{loc}(x^\star)) \\
    \mathbb{W}^u(x^\star) = \bigcup_{t\geq 0} \Phi^t(\mathbb{W}^u_\mathrm{loc}(x^\star)).
    \label{eq:global-manifolds}
\end{align}

That is, the global stable manifold is obtained by integrating the local stable manifold backwards, looking at where the trajectories on it came from. For the unstable manifold, we integrate the local unstable manifold forwards, to see where it goes to. 
%
\begin{figure}
    \centering
    \includegraphics[width=0.6\textwidth]{global-manifolds/global-manifolds.png}
    \caption{\textbf{Invariant manifolds of saddle point $x^\star$}. The local stable $\mathbb{W}^s_\mathrm{loc}(x^\star)$ and unstable $\mathbb{W}^u_\mathrm{loc}(x^\star)$ manifolds of the saddle point $x^\star$ respectively can be associated with the stable $\mathbb{E}^s$ and unstable $\mathbb{E}^u$ subspaces and become tangent to them near the saddle. This follows from the Hartman-Grobman and the stable manifold theorems. The global stable $\mathbb{W}^s(x^\star)$ and unstable $\mathbb{W}^u(x^\star)$ manifolds extend the definition of the local manifolds beyond the neighborhood $U$.  Figure is inspired by Fig.~6.2.4 from Ref.~\cite{argyrisbook}.}
    \label{fig:method:invariantmanifolds}
\end{figure}

An important fact about the local and global manifolds that follows from their definitions is that they are invariant: trajectories starting on these manifolds stay on them forever \cite{argyrisbook}.
Furthermore, the uniqueness of solutions prohibits certain crossings of manifolds: stable manifolds of two distinct equilibria cannot cross, unstable manifolds of two distinct equilibria also cannot, and the same manifold cannot cross itself - otherwise, where the crossing points would have to obey two distinct paths! Meanwhile, stable and unstable manifolds, either of the same equilibrium or of two different equilibria can cross. 

As mentioned before, these manifolds usually play a big role in organizing state space. As we will see in Chapter \ref{chap:multistability}, they can organize the transient dynamics of systems. There, we study a dynamical system wherein certain trajectories are forced to go on long excursions before converging to the stable equilibrium, the only attractor in state space (see Figs.\ref{fig:method:attractors-nonlinear}A-B). As explained there, this long excursion is generated by the arrangement of the invariant manifolds of the saddle-point that exists in state space. The invariant manifolds can also organize the long-term behavior of systems: the next section briefly shows how stable manifolds of unstable equilibria can act as the boundary separating two basins of attraction.

\subsection{The fate of nonlinear dynamical systems II: multistability and basins of attraction}
% Linear system are monostable: they can have only one attractor. If we now move to nonlinear systems, the situation is different. Now, trajectories can have multiple distinct fates, multiple attractors. To which attractor a trajectory goes to depends on where it starts. In a multistable system, the state space is then divided into distinct regions, wherein trajectories starting on each region go to their corresponding attractor. A simple and intuitive example is that of a ball on a certain landscape with hills and valleys. The ball of course rolls downhill and, due to friction, it eventually stops at one of the valleys.
In Sec.~\ref{method:nonlinear-I} we saw that the ultimate fate of nonlinear systems, their attractors, can be much more complicated than that of linear ones. Not only are the attractors themselves complicated, but they can also coexist in state space. If there are two coexisting attractors, this means that the state space will be separated into three regions: the basin of attraction of attractor one, the basin of attractor two, and the boundary between them. Usually, the basin boundary is formed by stable manifolds of saddle-type objects: saddle-points, saddle-limit-cycles, and even chaotic saddles! \cite{pisarchik2022multistability}. Figure~\ref{fig:bistability-duffing} illustrates this for a relatively simple system with two stable equilibria, where the basin boundary is the stable manifold of the saddle-point in the middle. This system is known as the Duffing oscillator: 
%
\begin{align}
    &\dot{x} = v\\
    &\dot{v} = -(-kx + cv + lx^3)/m,
\end{align}
%
with $k = 1$, $c=0.5$, $l=1$, $m=1$. This system represents a ball of mass $m$ rolling downhill at position $x$ and velocity $v$ on a quartic potential landscape of the form $U(x) = -lx^4/4 - kx^2/2$ with a friction term $-cv$. Following the definition of global manifolds in \eqnref{eq:global-manifolds}, these global manifolds are essentially obtained by integrating trajectories starting on the local manifolds of the saddle-point. 
%
\begin{figure}[htb!]
    \centering 
    \includegraphics[width=0.6\columnwidth]{duffing-bistability.png}
    \caption{\textbf{Bistability in Duffing model}. Two stable equilibria (white square and circle) are shown with their respective basins of attraction in two shades of purple. The global stable and unstable manifolds of the saddle-point (black point) in the middle are also shown as green and red lines respectively. The global stable manifold of the saddle coincides with the boundary between the basins, obtained independently.}
    \label{fig:bistability-duffing}
\end{figure}


In this thesis we study two examples of multistability occurring in networked systems. In Chapter \ref{chap:malleability} we study networks of Kuramoto units, and see there the coexistence of multiple attractors depending on how strongly the units are interacting. We also see how this multistability impacts the sensitivity of the system to small changes in parameters of the units. Later, in Chapter \ref{chap:multistability} we study how multistability arises when two excitable neurons are coupled together diffusively. Both studies require that we find the attractors in the systems. This is what we deal with in the next section.

\subsection{How to find attractors}\label{method:sec:finding-atts}
Finding all the attractors of a given dynamical system is not necessarily a trivial task. For equilibria, one can find all the roots of the system function, i.e., $f(x^\star) = 0$ and then check their stability through the eigenvalues of the Jacobian evaluated on them. However, the problem becomes more complicated for other types of attractors.
To start off, simply proving that a set is an attractor, following the criteria given in \secref{method:attractors-formal}, is usually not possible. Instead, in practice we use the looser definition of an attractor simply as the long-term dynamics of trajectories. Numerically, this means a brute-force approach of simulating several trajectories in state space for long integration times and seeing where they converge to.

This comes with two problems. First, it does not rule out the possibility that a certain set is just a very long transient. To remedy this, we usually integrate trajectories on the set for very long and check if there is any escape. Second, some attractors might have very small basins of attraction, such that randomly chosen initial conditions are unlikely to end on them, so it is unlikely that we find those attractors. So far, however, this brute force approach is the best we have for general systems \cite{datseris2022effortless, datseris2023framework}. Within this approach, there are two main methods in the literature for finding attractors. They differ in how they check convergence to attractors.

The first approach was proposed in \refref{nusse1994dynamics} and implemented with improvements in \refref{datseris2022effortless}. It parcellates state space into boxes. The idea then is that a typical trajectory, initialized in a certain box in state space, will evolve and visit other boxes until it converges to the attractor. It will then stay on the attractor, repeatedly visiting the same state space boxes. Using this idea, the algorithm integrates trajectories and looks for recurrences. When boxes are visited repeatedly for a certain prescribed amount of time, the algorithm considers that these boxes constitute the attractor. It is also smart in that it keeps track of the state of each box. So it knows that the boxes visited by the trajectory before converging to the attractor - the transient section of the trajectory - belongs to the basin of attraction of that attractor. This algorithm works well for steady-state, periodic, quasiperiodic, and chaotic attractors in low-dimensional systems. For chaotic attractors in high-dimensional systems it does not work well, because the time that trajectories take to recur on a chaotic attractor becomes too long to simulate numerically. 

The second method does not rely on discretizing state space, and is designed to work well for high-dimensional systems. In this case, one spreads a number $\mathcal{N}$ of initial conditions in state space and integrates them to obtain $\mathcal{N}$ trajectories. Each trajectory $x(t)$ is then converted to a vector of features $\mathcal{F} \in \mathbb{R}^n$ of $n$ numbers that all collectively describe the trajectory. This is done by the featurizing function $\phi : M \times \mathbb{R} \to \mathbb{R}^n$, such that $\mathcal{F} = \phi(x(t), t)$. Each attractor should correspond to a unique $\mathcal{F}$. Then, the $\mathcal{N}$ vectors of features are grouped together via any of several possible grouping or clustering algorithms, and each grouping corresponds to one attractor. This approach can work very well, but it relies on pre-existing knowledge about the system to find a suitable featurizer function $\phi$. To be confident about the results, one also has to verify that the total integration time is long enough, and that the transients of all trajectories were removed. This relies on experimentation. This method has been proposed in \refref{gelbrecht2020monte} and soon thereafter also in \refref{stender2021bstab}. Together with colleagues, I implemented efficient and open-source code for this method with improvements in the \textit{Attractors.jl} package \refref{datseris2023framework}.

Both methods can be applied across a parameter range and used in a continuation fashion, as illustrated in \figref{fig:method:continuation}A. For the first parameter, one selects $\mathcal{N}$ initial conditions and identifies from those the attractors of the system using any of the two methods just described. Then, one samples points on these attractors and adds them to the pool of initial conditions for the next parameter value. The originally prescribed initial conditions, together with the original ones, are then used to find attractors in the subsequent parameter value. This process of seeding initial conditions from the previously found attractors is repeated for the whole parameter range. Then, one has all the attractors for each parameter value, and the remaining problem is to link attractors from one parameter to the next.
%
\begin{figure}[b!]
    \centering
    \includegraphics[width=\textwidth]{paper-multistability-george/overview_figure.png}
    \label{fig:method:continuation}
    \caption{\textbf{Schematic illustration of the continuation method used to find and match attractors across a parameter range}. The first row illustrates the single-parameter attractor finding algorithms. The second row illustrates how they can be combined across parameters to perform a continuation analysis. Figure taken from \refref{datseris2023framework}.}
\end{figure}

The matching procedure between attractors is crucial for a continuation procedure. Often in linear continuation analysis one just matches the next point along a continuation curve to the previous point. This works well for infinitesimal perturbations of fixed points but becomes a problem in global stability analysis, where the steps are not necessarily infinitesimal and the attractors may be spatially extended and chaotic \cite{datseris2023framework}. Matching in our algorithm is designed to be very flexible, and can be adapted to the user's needs \cite{datseris2023framework}. There are two main methods for matching attractors. The first is based on distances between the attractors in state space.
First, the algorithm computes the distances between attractors at some parameter $p_i$ and some subsequent parameter $p_{i+1}$. Distance here is any positive semi-definite function. The default used is the Euclidean distance between the centroids of the attractors. Another good option is the Hausdorff distance \cite{datseris2023framework}. With the distances, a new attractor is matched to the previous one with the smallest distance, prioritizing pairs with the smallest distance. This matching respects uniqueness, so that once an attractor from the previous parameter has been matched, it is removed from the matching pool. This method is called matching by state space distance.

The other matching method is based on whether the basin of attraction of a new attractor encloses the basin of attraction of a previous attractor. To be concrete, suppose we find a certain number of attractors at a parameter $p_i$. Each ``previous'' attractor occupies a certain region of state space (which can be a single point if it is an equilibrium). Its basin of attraction occupies also a certain region, and enclosures the attractor itself. At the subsequent parameter $p_{i+1}$, ``new attractors'' are found. Their basins may be different in shape or size. But one can consider that if the basin of a new attractor encloses a previous attractor (i.e., if the previous attractor is inside the basin of the new attractor), then they are the ``same attractor'' - i.e., they should be matched. It may happen that the basin of a new attractor encloses two or more previous attractors. Then, one can choose the new and previous attractors that are closest in terms of a state space distance. This method works well for systems with several attractors and complicated basin structures. It is called the basin enclosure method, and we use it for results in \chapref{chap:malleability}.

After matching, the continuation is done. The user may also decide to group attractors based on some features of interest. For instance, to group attractors with a certain degree of synchronization \cite{datseris2023framework}.

The development and implementation of the attractor-finding algorithms and the continuation procedure in efficient and open-source code led to a joint publication in \refref{datseris2023framework}. The package is continuously updated with improvements and new features. The latest updates and documentation can be found in the \textit{Attractors.jl} GitHub page.


\section{Basics of bifurcations}\label{method:bifurcations}
What happens to the attractors - and, in general, to the state space structures - of a dynamical system when we vary its parameters? In terms of the qualitative properties, there are two possibilities: either they stay similar or they change drastically. We can be a bit more rigorous. Two systems are qualitatively similar if they are topologically equivalent. The notion of topological equivalence was already mentioned in \secref{method:invariant-manifolds}. As a reminder, two systems are topologically equivalent if the state space of one can be obtained by a continuous transformation of the other \cite{kuznetsov}. Mathematically, this means that they are topologically equivalent if there is a homeomorphism $h:M \to M$ mapping orbits of the first system onto orbits of the second, preserving the direction of time. 

As the parameters of a system are varied, we obtain different dynamical systems that are usually topologically equivalent. The attractors, for instance, may move, but they retain their stability. At some point, however, there may be a drastic change, and the new system may no longer be equivalent. The attractor may have disappeared, or lost its stability. Or a new attractor may have emerged. These drastic qualitative changes in the behavior of a dynamical system are called bifurcations. A bit more rigorously, a bifurcation is a change in the topological type of a system as its parameters pass through a critical (bifurcation) value \cite{kuznetsov}.
There are many types of bifurcations, and one can literally write a whole book about this \cite{kuznetsov}. For this thesis we focus briefly on just a few bifurcations that will be relevant for later. For simplicity, we focus also on the simplest version of these bifurcations. 

\subsection{Saddle-node bifurcation of equilibria}
In a saddle-node bifurcation of equilibria we see the emergence, or destruction, of a stable (node) and an unstable (saddle) equilibrium. Starting from the side of the bifurcation in which the equilibria exist and approaching the bifurcation parameter, we see the equilibria approaching each other, coalescing at the critical parameter, and annihilating each other thereafter (\figref{fig:method:bifurcations}A-D). The simplest form of this bifurcation occurs in one dimension in the system 
%
\begin{align}
    \dot{x} = f(x) = \alpha + x^2,
    \label{eq:sn-normal-form}
\end{align}
%
with the critical value of the bifurcation being $\alpha = 0$. As shown in Figs.~\ref{fig:method:bifurcations}A, for $\alpha < 0$ we see that the parabola $f(x)$ has two roots, so the system has two equilibria, in positions $x^\star = \pm \sqrt{-\alpha}$. From the figure directly we can already see that the equilibrium on the left is stable and the equilibrium on right is unstable. We can confirm this with a linearization analysis - the Jacobian here is simply $df/dx = 2x$, so the eigenvalue of the left and right equilibrium are $-2\sqrt{-\alpha}$ and $+2\sqrt{-\alpha}$.   As $\alpha$ increases towards $0$ the parabola moves up, the equilibria approach each other, their eigenvalues approach zero, and at $\alpha=0$ they all coalesce into one single equilibrium. At this point, the eigenvalue of the system is zero: this equilibrium is non-hyperbolic! For $\alpha > 0$ there are no more equilibria. Equation \ref{eq:sn-normal-form} is called the normal form of the saddle-node bifurcation, because any generic system obeying some conditions will be topologically equivalent to it locally, near the equilibrium.
% For a system $\dot{x} = f(x,p)$, with $x \in \mathbb{R}$ and $\alpha \in \mathbb{R}$, $\partial f(0,0) / \partial x = 0$, an equilibrium $x = 0$ at the critical parameter $\alpha = 0$, the conditions are \cite{kuznetsov}:
% %
% \begin{align}
%     &\frac{\partial^2 f(0, 0)}{\partial x^2} \neq 0 \\ 
%     &\frac{\partial f(0, 0)}{\partial \alpha} \neq 0.
% \end{align}
% 
% They guarantee that the system $\dot{x} = f(x,p)$ can be transformed into \eqnref{eq:sn-normal-form} or into $\dot{x} = \alpha - x^2$, which just inverts the direction of $\alpha$. 

% After the two equilibria are destroyed, the system does not have an
Just after the bifurcation, the region previously occupied by the two equilibria is still quite slow. Note how $\dot{x}$ is very close to zero near $x=0$ in \figref{fig:method:bifurcations}C. This region of slow flow is called the ghost of the saddle-node \cite{strogatz2002nonlinear}. In a way, it retains properties of the two equilibria - particular, trajectories still flow towards the ghost from the side previously occupied by the stable equilibrium, remain in its neighborhood for a while, but then eventually depart through the side previously occupied by the unstable equilibrium \cite{koch2024ghost}. The ghost is not an invariant set, but is an example of a metastable regime, which we study in greater depth in Chapter \ref{chap:metastability}.


Saddle-node bifurcations can also occur analogously for periodic orbits \cite{kuznetsov} - a stable limit cycle then collides with an unstable limit cycle, and leave behind a ghost of a limit cycle!
%
\begin{figure}
    \centering 
    \includegraphics[width=\textwidth]{methodology/bifurcations/bifurcations.png}
    \caption{\textbf{Some important bifurcations}. The saddle-node bifurcation is shown for the normal form $\dot{x} = x^2 + \alpha$ in panels A-D. A stable and an unstable equilibria, represented respectively by green and red circles (panel A), come together as the bifurcation parameter $\alpha$ is changed. Eventually they coalesce (panel B) and are subsequently destroyed (panel C). The position of these equilibria as a function of $\alpha$ is shown in panel D. The supercritical Hopf bifurcation is shown for \eqnref{eq:hopf} in panels E-H. Before and at the bifurcation there is a stable equilibrium in state space (panels E and F respectively), which becomes unstable when a stable limit cycle emerges (panel G). Panel H shows this behavior as a functon of $\alpha$, taking the maximum and minimum values of $x$ to represent the limit cycle. The homoclinic bifurcation to a saddle point is shown in panels I-L. Before the bifurcation there is a saddle point (panel I). At the bifurcation, an orbit homoclinic to this saddle point appears (represented approximately in panel J). After the bifurcation, a stable limit cycle emerges (panel K). This is also summarized in panel L.}
    \label{fig:method:bifurcations}
\end{figure}

\subsection{Hopf bifurcation}
Keeping with the spirit of describing the simplest cases, let us now imagine a system written in polar coordinates $(\rho, \theta)$:
% 
\begin{align}\label{eq:hopf}
    &\dot{\rho} = f_\rho = \rho(\alpha - \rho^2) \\ 
    &\dot{\phi} = f_\phi = 1.
\end{align}

Because the two equations are decoupled, we can analyze the $\rho$ equation separately first. First, note that its Jacobian $\partial f_\rho / \partial \rho = \alpha - 3\rho^2$. For all values of $\alpha$, $f_\rho$ has an equilibrium at $\rho=0$ - with eigenvalue $\lambda = \alpha$. This is linearly stable for $\alpha<0$ and linearly stable for $\alpha>0$. At $\alpha=0$ it is non-hyperbolic! What happens then? The first equation has another root for $\alpha > 0$ at $\rho = \sqrt{\alpha}$ - so the eigenvalue is $\lambda = -2\alpha$. This equilibrium is then stable. Considered for $f_\rho$ alone, this is an example of a pitchfork bifurcation \cite{kuznetsov}. Considering the full system, with the rotation induced by $\dot{\phi} = 1$, the equilibrium at the origin remains an equilibrium, but the equilibrium at $\sqrt{\alpha}$ becomes a limit cycle with amplitude $\sqrt{\alpha}$. Putting everything together, we have the behavior in \figref{fig:method:bifurcations}G-H. A stable limit cycle becomes unstable at $\alpha = 0$ and from it a stable limit cycle emerges. This is called a supercritical Hopf bifurcation \cite{kuznetsov}.
If we write this system in Cartesian coordinates and compute the eigenvalues of the Jacobian at the origin, we see they are $\lambda_{1,2} = \alpha \pm i$. This gives us another general property of this bifurcation: at the critical point, the eigenvalues at the origin cross the imaginary axis.

Now consider the system
%
\begin{align}
    &\dot{\rho} = f_\rho = \rho(\alpha + \rho^2) \\ 
    &\dot{\phi} = f_\phi = 1.
\end{align}

Now the Jacobian is $\partial f_\rho / \partial \rho = \alpha + 3\rho^2$. There is still an equilibrium at the origin, in which the eigenvalue is still $\alpha$ - its stability is the same as before. However, the other equilibrium, now $\sqrt{-\alpha}$ has the associated eigenvalue as $-2\alpha$. It therefore exists for $\alpha < 0$ when it is unstable. This thus corresponds to an unstable limit cycle, which coexists with a stable equilibrium for $\alpha < 0$. For $\alpha > 0$, the limit cycle disappears and the system is left with only an unstable equilibrium. This is called a subcritical Hopf bifurcation \cite{kuznetsov}. The eigenvalues of the Cartesian Jacobian at the origin behave in the same way as for the supercritical Hopf.





\subsection{Homoclinic bifurcation}
Both the saddle-node and the Hopf bifurcations happen in the neighborhood of equilibria - for this reason, they are called local bifurcations. Now we move to a bifurcation in which this is no longer the case - the state space beyond only the equilibrium is affected, and it is thus called a global bifurcation \cite{kuznetsov}. The formal description of this bifurcation is consequently more involved, and goes beyond the scope of this thesis. For here it is enough to describe the bifurcation more qualitatively. 

In the homoclinic bifurcation we study here, occurring on the plane, we have the emergence of a limit cycle. Before the bifurcation, there is only a saddle point. At the bifurcation, the unstable manifold of the saddle becomes tangential to its own stable manifold - this constitutes a homoclinic orbit. After the bifurcation, the homoclinic orbit becomes a limit cycle whose stability depends on the eigenvalues of the saddle. Defining the saddle quantity $\sigma = \lambda_1 + \lambda_2$, it can be shown that the limit cycle is stable for $\sigma < 0$ and unstable if $\sigma > 0$ \cite{kuznetsov}. 

Varying the bifurcation parameter $\alpha$ close to the homoclinic orbit, the limit cycle approaches more and more the saddle point, and touches it at $\alpha = \alpha_c$. The region of the limit cycle close to the saddle-point has a very slow dynamics, such that the period of the limit cycle diverges to infinity as the critical point is approached. In higher dimensional systems, different types of homoclinic bifurcations are possible, with potentially much more complicated dynamics. The homoclinic bifurcations we deal with in this thesis are always related to simple saddle points, and so are analogous to the planar case shown now. 

An example of a planar system with this bifurcation is due to Sandstede \cite{sandstede1997constructing}
%
\begin{align}
    &\dot{x} = -x + 2y + x^2  \\ 
    &\dot{y} = (2-\alpha)x - y - 3x^2 + (3/2)xy.
    \label{eq:sandstede}
\end{align}

The origin is a saddle which, at $\alpha=0$, has eigenvalues $\lambda_1 =1$ and $\lambda_2 = -3$ - its saddle quantity is therefore $\sigma = 2 < 0$, so the limit cycle that emerges here is stable \cite{kuznetsov}.


\section{Basics of Network Theory}\label{method:sec:network}
An incredibly powerful abstraction about real-world systems can be achieved through the concept of networks, here used as synonyms for graphs, which are composed of nodes that are connected by edges. Networks can represent friendships - with people being the nodes and their friendships being the edges -, brain circuits - neurons are nodes, synapses are edges \cite{bullmore2009complex} -, ecological systems - for instance, ecological regions are nodes, and migrations between them are edges \cite{landi2018complexity}. In this thesis we make use of this abstraction and consider that the nodes are dynamical systems $\dot{x}_i = f(x_i)$, $x_i \in \mathbb{R}^n$ on their own, with certain interactions between them. Together, the whole networked system is a dynamical system of the form:
%
\begin{align}
    \dot{x}_i = f(x_i) + \sum_{j=1}^N A_{ij} g(x_j, x_i),\; i=1,\ldots,N,
    \label{eq:network-general}
\end{align} 
%
with $N$ units, whose interactions are described by the function $g$. The adjacency matrix $A_{ij}$ describes the strength of interactions between the units. Typically, it is a binary matrix, such that $A_{ij} = 1$ if unit $i$ receives a connection from unit $j$ and $A_{ij} = 0$ otherwise. It can also be weighted, in which case the entry $A_{ij} \in \mathbb{R}$ represents the strength of interactions. Usually for binary matrices, we rewrite \eqnref{eq:network-general} as 
%
\begin{align}
    \dot{x}_i = f(x_i) + \sum_{j \in \Omega_i} g(x_j, x_i),\; i=1,\ldots,N,
    \label{eq:network-general-neighborhood}
\end{align} 
%
where $\Omega_i = \{j \in [1, N]: A_{ij} = 1\}$ is called the neighborhood of node i. The number of elements in $\Omega_i$, i.e., the number of connections of unit i, is called the unit's degree.

The adjacency matrix $A$ describes the topology of the network, meaning the architecture of the connections. There are many types of topologies, which describe well different types of systems. One type of topology is the regular ring, also called $k$-nearest-neighbors topology. As the name suggests, one can think of all nodes arranged on a ring, with each node connected to the $k$ nearest nodes on each side. Another type of topology is the random ring, in which connections are chosen at random between the nodes. One consider the regular and random rings as two extremes, and interpolate between them in what is called the Watts-Strogatz algorithm \cite{watts1998collective}. In this case, one starts with a $k$-nearest neighbor ring of nodes. Then, choose connections with a probability $p$. For each chosen connection $(i,j)$, keep the source node $i$, randomly choose a new node $j^\prime$ in the network, and switch $(i,j)$ to $(i,j^\prime)$. This effectively switches short-range connections (between nearest nodes) to long range connections (between nodes that are potentially far away). For this rewiring probability $p$ at $p=0$ one has the regular topology; for $p=1$ one has the random topology. 

Without going into deeper formalizations, a regular network is considerably clustered due to its short-range structures. And the average distance (in terms of numbers of edges) between nodes in the network is considerably high. In a random network, the clustering is very small, and the average distance is also small. One can formalize these concepts and show how this transition occurs as $p$ is changed \cite{watts1998collective}. Here, we mention that, when $p$ is relatively small but nonzero, only a few short-range connections are rewired as long-range. This does not change the clustering characteristics much, but considerably lowers the average distance between nodes - the few long-range connections act as efficient shortcuts between nodes. Networks in this regime are usually called small-world networks \cite{watts1998collective}. 

In \chapref{chap:malleability} we also study distance-dependent networks. The adjacency matrix is then defined as 
%
\begin{align}
    A_{ij} = \frac{1}{\eta(\alpha)(d_{ij})^\alpha},
\end{align}

with $d_{ij} = \min(|i-j|, N-|i-j|)$ is the edge distance along the ring, and $\eta(\alpha) = \sum_{j=1}^{N^\prime} \frac{2}{j^\alpha}$ is a normalization term, with $N^\prime = \frac{N-1}{2}$ denoting half the amount of units to which $i$ is connected to (one half of the ring's length, discounting the unit $i$ itself). All units are thus connected, but the weight of the connections decays with the distance following the $\alpha$ parameter. This parameter can also be called the locality parameter, since $\alpha=0$ leads to an all-to-all equally connected network and $\alpha\to\infty$ leads to a first-nearest-neighbor topology ($k=1$). In between we get distance-dependent weights.
%
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{methodology/networks/wattsstrogatz.png}
    \caption{\textbf{Illustration of networks generated by the Watts-Strogatz procedure}. First, a $k$-nearest neighbor topology is created (Panel A). Then, some connections are randomly rewired, keeping the source node but changing the target node. With a few rewirings, this creates small-world networks (Panel B). By rewiring all the initial short-range connections, the network becomes randomly connected (Panel C).}
    \label{method:fig:topology}
\end{figure}


\section{Basics of Kuramoto oscillators}\label{method:sec:kuramoto}
\subsection{Derivation of the model and transition to synchronization}
The Kuramoto model, written in general as 
\begin{align}
    \dot{\theta}_i = \omega_i + \epsilon \sum_{j=1}^N A_{ij} \sin(\theta_j-\theta_i),
    \label{eq:kuramoto-general}
\end{align}
%
serves as a paradigm for studies on synchronization phenomena \cite{boccaletti2018synchronization}. Its usefulness comes it being simple enough to be mathematically tractable, sufficiently generic, and also complex enough to display interesting dynamics. To reach it, Kuramoto started from generic oscillators near supercritical Hopf bifurcations (also called Stuart-Landau oscillators). Each unit $i$ follows 
\begin{align}
    \dot{Q}_i = (\imath \omega + \alpha) Q_i - \beta|Q_i|^2 Q_i,
\end{align}
%
where $\omega$ is the natural frequency of the oscillator, $\alpha>0$ and $\beta>0$ are parameters and $Q \in \mathbb{C}$. This is the normal form of the Hopf bifurcation we saw in \secref{method:bifurcations} but written in complex numbers. Kuramoto chose a simple and natural way to couple these oscillators: via a common coupling term, that is proportional to the value $Q_i$ of each oscillator: 
%
\begin{align}
    \dot{Q}_i = (\imath \omega + \alpha) Q_i - \beta|Q_i|^2 Q_i + \frac{K}{N} \sum_{j=1}^{N} Q_j,
    \label{eq:stuartlandaucoupled}
\end{align}
%
which corresponds to an all-to-all topology, with $K$ being the coupling strength. Here the natural frequencies are assumed to be drawn from a certain distribution $g(\omega)$, usually unimodal.

One can then rewrite \eqnref{eq:stuartlandaucoupled} in polar coordinates by using $Q_i = e^{\imath \theta_i} \rho_i$. Substituting it one gets the equations 
\begin{align}
    &\dot{\rho}_i = (\alpha - \beta \rho_i^2) + \frac{K}{N} \sum_{j=1}^{N} \rho_j \cos(\theta_j - \theta_k) \\
    &\dot{\theta}_i = \omega_i + \frac{K}{N}\sum_{j=1}^{N} \frac{\rho_j}{\rho_k} \sin(\theta_j - \theta_k).
\end{align}

Kuramoto studied these equations in the limit of $\alpha\to\infty$ and $\beta\to\infty$ with $\alpha/\beta$ constant. Then, one gets that the radial variables $\rho_i$ approach a stable fixed point arbitrarily fast \cite{boccaletti2018synchronization}. The radial variable is therefore just a constant and one just needs to consider the phase variables: 
%
\begin{align}
    \theta_i = \omega_i + \frac{K}{N} \sum_{j=1}^{N}\sin(\theta_j-\theta_i).
    \label{eq:kuramoto-og}
\end{align}

A very useful way to quantify the spread of the phases $\theta_i$ is through the complex order parameter:
\begin{align}
    Z = r e^{\imath \psi} = \frac{1}{N} \sum_{j=1}^{N} e^{\imath \theta_j},
    \label{eq:kuramoto-order-parameter}
\end{align}
%
which corresponds to the centroid of the phases and therefore characterizes well the collective behavior of the system. The radius $r$ measures the phase synchronization of the system: $r$ is close to $0$ if the phases are uniformly spread or clustered in anti-phase clusters and $r$ is close to $1$ if the phases are aligned together. Here we should clarify that phase synchronization denotes the alignment of phases of oscillations - complete phase synchronization corresponds to $r=1$, meaning that the phases are the same (up to $2\pi$ offsets). On the other hand, frequency synchronization denotes the alignment of the frequencies of oscillations - complete frequency synchronization corresponds to $\dot{\theta_i} = \Omega, \; \quad \forall i=1,\ldots, N$. Networks that are frequency synchronized are also said to be phase-locked - the phase differences are constant. But it does not imply phase synchronization, as the phase differences may be non-zero. Figures~\ref{fig:method:kuramoto}A-B exemplify the behavior of $r$ for weak and strong phase synchronization.

The angle $\psi$ corresponds to the average phase of the units. Using this order parameter, the Kuramoto model can be rewritten as
\begin{align}
    \dot{\theta}_i = \omega_i + Kr\sin(\psi - \theta_i), \; i=1,\ldots,N.
\end{align} 

This form highlights the mean-field character of the model \cite{strogatz2000from}. The oscillators now interact through the mean-field quantities $r$ and $\psi$. The phase $\theta_i$ is pulled towards the mean phase $\psi$. And the effective coupling strength becomes $Kr$, so it is modulated by the degree of phase synchronization $r$. This creates a positive feedback loop, wherein as the system phase synchronizes more, the coupling becomes stronger and so the system tends to phase synchronize even more. This is a very clear mechanism for spontaneous synchronization \cite{strogatz2000from}. 


% \subsection{Transition to synchronization in original Kuramoto}
These equations always have a solution for $\theta_i = 0, \; \forall i$. What about other solutions? Kuramoto considered these equations in the infinite size limit $N\to\infty$. By seeking steady-state solutions, with $r$ constant, he noted that oscillators the will split into two groups: (i) with $|\omega_i| < Kr$, which phase-lock together and (ii) with $|\omega_i| > Kr$ which keep rotating with nonuniform velocity $\dot{\theta}_i$.  He then showed that a branch continuously bifurcates from $r=0$ at $K=K_c$, a critical coupling strength, given by:
%
\begin{align}
    K_c = \frac{2}{\pi g(0)}.
\end{align}

Near $K=K_c$, this branch has a square-root behavior: $r \propto \sqrt{K-K_c}$. In particular for $\{\omega_i\}$ following a Lorentzian distribution, one can show that \cite{kuramoto1984chemical, strogatz2000from}
\begin{align}
    r = \sqrt{1 - \frac{K_c}{K}},
    \label{eq:kuramoto-lorentzian}
\end{align}
%
as illustrated in \figref{fig:method:kuramoto}C. One can verify this behavior numerically: \figref{fig:method:kuramoto}D illustrates the results of simulations for a network of $N=1000$ oscillators under a Gaussian distribution with zero mean and unitary standard deviation. The $y$-axis denotes the time-averaged behavior of $r(t)$, since $r(t)$ oscillates in time for these finite networks.
%
\begin{figure}
    \includegraphics[width=\textwidth]{kuramoto/kuramoto-thesis-figure.png}
    \caption{\textbf{Basics of Kuramoto oscillators}. Panels A and B respectively illustrate the concept of weak and strong phase synchronization (PS), captured by the complex order parameter $Z$ (\eqnref{eq:kuramoto-order-parameter}). The radius $r$ denotes the degree of PS and the angle $\psi$ denotes the centroid of the phases - respectively, they correspond to the magnitude and direction of the arrow in the figure. Panel C illustrates the behavior of the order parameter $r$ as a function of coupling strength $K$ (see \eqnref{eq:kuramoto-og}) for a Lorentzian distribution of the frequencies (\eqnref{eq:kuramoto-lorentzian}). The blue line denotes the critical coupling strength for the transition to synchronization. Panel D illustrates a similar behavior obtained from numerical simulations in a network of size $N=1000$ under a Gaussian distribution of the natural frequencies. Only one attractor is ever observed in the simulations. Going now to homogeneous frequencies, panel E illustrates the fraction fs of randomly chosen initial conditions that converge to each $q$ twisted state, in a network with $k=2$ nearest neighbors. Panel F looks at this fraction for the completely synchronized state ($q=0$) only, under different values of $k$. Panels E and F replicate results from \cite{wiley2006the}. }
    \label{fig:method:kuramoto}
\end{figure}


Many open questions remain from the treatment just shown, such as the stability of these branches. There have been many extensions made to this model \cite{acebron2005kuramoto, rodrigues2016the}. In the context of multistability, some basic results come from studying an even simpler configuration, where the units are identical and coupled in a $k$-nearest-neighbor ring.

\subsection{Multistability in homogeneous case: twisted states}\label{method:sec:kuramoto:twisted}
In the case of homogeneous oscillators with $\omega_i = \omega$ coupled in a $k$-nearest-neighbor topology, the equations become 
%
\begin{align}
    \dot{\theta}_i = \omega + \epsilon \sum_{j=i-k}^{j=i+k} \sin(\theta_j - \theta_i).
\end{align}

One can switch to a corotating frame with angular velocity $\omega$ to get rid of the $\omega$ term and appropriately rescale time to get rid of $\epsilon$ and simplify down to 
%
\begin{align}
    \dot{\theta}_i = \sum_{j=i-k}^{j=i+k} \sin(\theta_j - \theta_i).
\end{align}

Note therefore that changing the coupling strength in this system only rescales time, and does not change the state space significantly! This can be written as a gradient system $\dot{\theta} = - \nabla U(\theta)$, where $U(\theta)$ is a scalar differentiable function of $\theta \in \mathbb{R}^n$ \cite{wiley2006the, strogatz2002nonlinear}. As a consequence, the only attractors in this system are equilibria \cite{wiley2006the}. Therefore to find all the attractors in the system one can first find the equilibria and then determine their linear stability. By doing this, one finds that the equilibria obey the relation:
%
\begin{align}
    \theta_i = \omega t + \frac{2\pi q}{N} i + C,
\end{align}
%
where $C \in \mathbb{R}$ is a constant and $q \in \mathbb{Z}$ is the twisting number. If one looks at the phase difference between two adjacent units one sees that it is constant across the ring: $\theta_{i+1} - \theta_i = \frac{2\pi q}{N}$. In particular, the completely synchronized state is included here in the $q=0$ case. Some important stability results are:
%
\begin{itemize}
    \item For small values of $k$ many twisted states can be stable. As $k$ is increased, these twisted states start to lose stability, with higher $q$ values starting earlier.  Eventually, the completely synchronized state ($q=0$) becomes globally stable at $k>k_c \approx 0.34 N$ \cite{wiley2006the}. 
    \item If we fix $k$ and look at estimates of the size of the basins of all stable twisted states we find that they can be parametrized by a Gaussian curve \cite{wiley2006the, zhang2021basins} (\figref{fig:method:kuramoto}E).
    \item Estimates of the size of the basin of attraction for $q=0$ increase monotonically with $k$ (\figref{fig:method:kuramoto}F): the completely synchronized state starts to dominate the state space for denser networks \cite{wiley2006the}. 
    \item The shape of the basins is still a topic under research, but they appear to form octopus-like structures. The twisted state itself (a point) is on the head of the octopus, which has a small volume around it. The majority of the volume of the basin is concentrated on the tentacles, which are structures that spread around in state space \cite{zhang2021basins}.
\end{itemize}


Studies have also been made for other topologies. Some important results have accumulated to show that networks with homogeneous frequencies are guaranteed to globally synchronize if the nodes are sufficiently well-connected (if the networks are sufficiently dense). Taking the least connected node, with degree $k_\mathrm{min}$, and comparing it with the maximum possible degree of the network, $N-1$, one can define the network's connectivity $\mu$ as the ratio $\mu = k_\mathrm{min}/(N-1)$. Then, in networks with $\mu > \mu_c$, the only attractor is the fully synchronized state. Estimates have that $\mu \in [0.6818, 0.7889]$ \cite{taylor2012there, townsend2020dense}. 
